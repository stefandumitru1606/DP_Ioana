{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2dc32433-5e8e-4374-ace5-eb986987b812",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import splitfolders\n",
    "import numpy as np\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization, Dropout, Flatten, Dense\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger\n",
    "from keras_preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d7ba95c-c08e-4f6c-9c4d-ba42886f63e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3141724-020f-46d0-864f-5f942f07207d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = 'dataset_images_03s_128x128'\n",
    "original_labels = (\"Electronic\", \"Experimental\", \"Folk\", \"Hip-Hop\", \"Instrumental\", \"International\", \"Pop\", \"Rock\")\n",
    "\n",
    "image_size = (128,128)\n",
    "color_mode = 'grayscale'\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37dee7fa-0dac-4ff4-a724-687312e0cf97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying files: 79940 files [01:28, 908.14 files/s]\n"
     ]
    }
   ],
   "source": [
    "splitfolders.ratio('dataset_images_03s_128x128', output='dataset_images_03s_128x128_split', seed=1337, ratio=(0.8, 0.15,0.05)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "619abca4-926d-4462-96a5-d7b3ca697208",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 63952 images belonging to 8 classes.\n",
      "Found 11989 images belonging to 8 classes.\n",
      "Found 3999 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "train_path = 'dataset_images_03s_128x128_split/train'\n",
    "validation_path = 'dataset_images_03s_128x128_split/val'\n",
    "test_path = 'dataset_images_03s_128x128_split/test'\n",
    "\n",
    "def generator(path, aug):\n",
    "    if aug == 1:\n",
    "        image_gen = ImageDataGenerator(\n",
    "            rescale=1./255,  \n",
    "            zoom_range=0.1,  \n",
    "            width_shift_range=0.1,  \n",
    "            height_shift_range=0.1,  \n",
    "            fill_mode='nearest'  \n",
    "    )\n",
    "    else:\n",
    "        image_gen = ImageDataGenerator(rescale = 1/255.0)\n",
    "\n",
    "    gen = image_gen.flow_from_directory(\n",
    "        directory = path,\n",
    "        target_size = (128,128),\n",
    "        color_mode = 'grayscale',\n",
    "        batch_size = 16,\n",
    "        class_mode = 'categorical',\n",
    "        shuffle = True,\n",
    "        seed = 42\n",
    "    )\n",
    "    return gen\n",
    "\n",
    "train_gen = generator(train_path, 0) # no augmentation\n",
    "validation_gen = generator(validation_path, 0)\n",
    "test_gen = generator(test_path, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8cd22c4c-fbb4-48a8-a156-6087776341e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initiate_model():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(32, input_shape=(128,128,1), kernel_size=(7,7), activation='relu', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(64, kernel_size=(7,7), activation='relu', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(128, kernel_size=(7,7), activation='relu', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(256, kernel_size=(7,7), activation='relu', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(512, kernel_size=(5,5), activation='relu', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Flatten())\n",
    "              \n",
    "    model.add(Dense(1024,activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(8,activation='softmax'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "536b2682-718d-4608-8e77-1e0cc52b22b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# callbacks\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, min_lr=0.00001, patience=4, verbose=1)\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=20, verbose=1)\n",
    "model_checkpoint = ModelCheckpoint('checkpoints/mdl_wts.h5', save_best_only=True, monitor='val_accuracy', mode='max')\n",
    "csv_logger = CSVLogger('training.log')\n",
    "\n",
    "# optimizers \n",
    "adam = Adam(learning_rate = 0.001)\n",
    "sgd = SGD(learning_rate=0.01, momentum=0.9, nesterov=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0cb93e72-db1e-4418-944c-c61aa70b4633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3997/3997 [==============================] - 140s 34ms/step - loss: 1.8914 - accuracy: 0.3201 - val_loss: 2.5479 - val_accuracy: 0.2398 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "3997/3997 [==============================] - 136s 34ms/step - loss: 1.6267 - accuracy: 0.4131 - val_loss: 2.3774 - val_accuracy: 0.2259 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "3997/3997 [==============================] - 136s 34ms/step - loss: 1.5220 - accuracy: 0.4620 - val_loss: 1.6038 - val_accuracy: 0.4097 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "3997/3997 [==============================] - 135s 34ms/step - loss: 1.4608 - accuracy: 0.4865 - val_loss: 1.5611 - val_accuracy: 0.4639 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "3997/3997 [==============================] - 139s 35ms/step - loss: 1.4008 - accuracy: 0.5113 - val_loss: 1.4554 - val_accuracy: 0.4823 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "3997/3997 [==============================] - 136s 34ms/step - loss: 1.3421 - accuracy: 0.5327 - val_loss: 1.3118 - val_accuracy: 0.5428 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "3997/3997 [==============================] - 136s 34ms/step - loss: 1.2919 - accuracy: 0.5522 - val_loss: 1.4005 - val_accuracy: 0.5103 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "3997/3997 [==============================] - 136s 34ms/step - loss: 1.2426 - accuracy: 0.5693 - val_loss: 1.3780 - val_accuracy: 0.5343 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "3997/3997 [==============================] - 137s 34ms/step - loss: 1.1978 - accuracy: 0.5843 - val_loss: 1.1823 - val_accuracy: 0.5888 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "3997/3997 [==============================] - 136s 34ms/step - loss: 1.1469 - accuracy: 0.6042 - val_loss: 1.6980 - val_accuracy: 0.4274 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "3997/3997 [==============================] - 136s 34ms/step - loss: 1.1001 - accuracy: 0.6215 - val_loss: 1.3566 - val_accuracy: 0.5521 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "3997/3997 [==============================] - 143s 36ms/step - loss: 1.0593 - accuracy: 0.6341 - val_loss: 1.2528 - val_accuracy: 0.5659 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "3996/3997 [============================>.] - ETA: 0s - loss: 1.0115 - accuracy: 0.6529\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "3997/3997 [==============================] - 141s 35ms/step - loss: 1.0114 - accuracy: 0.6529 - val_loss: 1.2658 - val_accuracy: 0.5603 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "3997/3997 [==============================] - 143s 36ms/step - loss: 0.9247 - accuracy: 0.6842 - val_loss: 1.1933 - val_accuracy: 0.5987 - lr: 5.0000e-04\n",
      "Epoch 15/100\n",
      "3997/3997 [==============================] - 148s 37ms/step - loss: 0.8663 - accuracy: 0.7034 - val_loss: 1.0991 - val_accuracy: 0.6218 - lr: 5.0000e-04\n",
      "Epoch 16/100\n",
      "3997/3997 [==============================] - 143s 36ms/step - loss: 0.8341 - accuracy: 0.7142 - val_loss: 0.8763 - val_accuracy: 0.7075 - lr: 5.0000e-04\n",
      "Epoch 17/100\n",
      "3997/3997 [==============================] - 153s 38ms/step - loss: 0.8066 - accuracy: 0.7228 - val_loss: 0.8968 - val_accuracy: 0.7016 - lr: 5.0000e-04\n",
      "Epoch 18/100\n",
      "3997/3997 [==============================] - 150s 37ms/step - loss: 0.7752 - accuracy: 0.7353 - val_loss: 0.9576 - val_accuracy: 0.6859 - lr: 5.0000e-04\n",
      "Epoch 19/100\n",
      "3997/3997 [==============================] - 147s 37ms/step - loss: 0.7536 - accuracy: 0.7421 - val_loss: 0.9195 - val_accuracy: 0.6887 - lr: 5.0000e-04\n",
      "Epoch 20/100\n",
      "3996/3997 [============================>.] - ETA: 0s - loss: 0.7309 - accuracy: 0.7505\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "3997/3997 [==============================] - 143s 36ms/step - loss: 0.7309 - accuracy: 0.7504 - val_loss: 0.8764 - val_accuracy: 0.7069 - lr: 5.0000e-04\n",
      "Epoch 21/100\n",
      "3997/3997 [==============================] - 148s 37ms/step - loss: 0.6806 - accuracy: 0.7663 - val_loss: 0.8717 - val_accuracy: 0.7183 - lr: 2.5000e-04\n",
      "Epoch 22/100\n",
      "3997/3997 [==============================] - 143s 36ms/step - loss: 0.6515 - accuracy: 0.7764 - val_loss: 0.8437 - val_accuracy: 0.7182 - lr: 2.5000e-04\n",
      "Epoch 23/100\n",
      "3997/3997 [==============================] - 136s 34ms/step - loss: 0.6338 - accuracy: 0.7827 - val_loss: 1.0359 - val_accuracy: 0.6793 - lr: 2.5000e-04\n",
      "Epoch 24/100\n",
      "3997/3997 [==============================] - 136s 34ms/step - loss: 0.6204 - accuracy: 0.7880 - val_loss: 1.0162 - val_accuracy: 0.6839 - lr: 2.5000e-04\n",
      "Epoch 25/100\n",
      "3997/3997 [==============================] - 136s 34ms/step - loss: 0.6080 - accuracy: 0.7934 - val_loss: 0.7997 - val_accuracy: 0.7375 - lr: 2.5000e-04\n",
      "Epoch 26/100\n",
      "3997/3997 [==============================] - 138s 35ms/step - loss: 0.5908 - accuracy: 0.7980 - val_loss: 0.8701 - val_accuracy: 0.7046 - lr: 2.5000e-04\n",
      "Epoch 27/100\n",
      "3997/3997 [==============================] - 136s 34ms/step - loss: 0.5777 - accuracy: 0.8026 - val_loss: 0.8091 - val_accuracy: 0.7305 - lr: 2.5000e-04\n",
      "Epoch 28/100\n",
      "3997/3997 [==============================] - 136s 34ms/step - loss: 0.5631 - accuracy: 0.8072 - val_loss: 0.7349 - val_accuracy: 0.7579 - lr: 2.5000e-04\n",
      "Epoch 29/100\n",
      "3997/3997 [==============================] - 136s 34ms/step - loss: 0.5563 - accuracy: 0.8106 - val_loss: 0.7825 - val_accuracy: 0.7403 - lr: 2.5000e-04\n",
      "Epoch 30/100\n",
      "3997/3997 [==============================] - 136s 34ms/step - loss: 0.5409 - accuracy: 0.8141 - val_loss: 0.7466 - val_accuracy: 0.7568 - lr: 2.5000e-04\n",
      "Epoch 31/100\n",
      "3997/3997 [==============================] - 136s 34ms/step - loss: 0.5353 - accuracy: 0.8161 - val_loss: 0.7202 - val_accuracy: 0.7666 - lr: 2.5000e-04\n",
      "Epoch 32/100\n",
      "3997/3997 [==============================] - 147s 37ms/step - loss: 0.5194 - accuracy: 0.8229 - val_loss: 0.7158 - val_accuracy: 0.7678 - lr: 2.5000e-04\n",
      "Epoch 33/100\n",
      "3997/3997 [==============================] - 146s 36ms/step - loss: 0.5096 - accuracy: 0.8261 - val_loss: 0.7191 - val_accuracy: 0.7657 - lr: 2.5000e-04\n",
      "Epoch 34/100\n",
      "3997/3997 [==============================] - 143s 36ms/step - loss: 0.5038 - accuracy: 0.8276 - val_loss: 0.7095 - val_accuracy: 0.7723 - lr: 2.5000e-04\n",
      "Epoch 35/100\n",
      "3997/3997 [==============================] - 136s 34ms/step - loss: 0.4963 - accuracy: 0.8276 - val_loss: 0.6988 - val_accuracy: 0.7755 - lr: 2.5000e-04\n",
      "Epoch 36/100\n",
      "3997/3997 [==============================] - 145s 36ms/step - loss: 0.4872 - accuracy: 0.8327 - val_loss: 0.7602 - val_accuracy: 0.7618 - lr: 2.5000e-04\n",
      "Epoch 37/100\n",
      "3997/3997 [==============================] - 135s 34ms/step - loss: 0.4722 - accuracy: 0.8377 - val_loss: 0.8210 - val_accuracy: 0.7324 - lr: 2.5000e-04\n",
      "Epoch 38/100\n",
      "3997/3997 [==============================] - 136s 34ms/step - loss: 0.4626 - accuracy: 0.8410 - val_loss: 0.7118 - val_accuracy: 0.7740 - lr: 2.5000e-04\n",
      "Epoch 39/100\n",
      "3997/3997 [==============================] - ETA: 0s - loss: 0.4621 - accuracy: 0.8415\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "3997/3997 [==============================] - 135s 34ms/step - loss: 0.4621 - accuracy: 0.8415 - val_loss: 0.7307 - val_accuracy: 0.7700 - lr: 2.5000e-04\n",
      "Epoch 40/100\n",
      "3997/3997 [==============================] - 136s 34ms/step - loss: 0.4388 - accuracy: 0.8501 - val_loss: 0.6729 - val_accuracy: 0.7880 - lr: 1.2500e-04\n",
      "Epoch 41/100\n",
      "3997/3997 [==============================] - 142s 36ms/step - loss: 0.4258 - accuracy: 0.8544 - val_loss: 0.7679 - val_accuracy: 0.7640 - lr: 1.2500e-04\n",
      "Epoch 42/100\n",
      "3997/3997 [==============================] - 135s 34ms/step - loss: 0.4220 - accuracy: 0.8547 - val_loss: 0.7298 - val_accuracy: 0.7640 - lr: 1.2500e-04\n",
      "Epoch 43/100\n",
      "3997/3997 [==============================] - 136s 34ms/step - loss: 0.4175 - accuracy: 0.8564 - val_loss: 0.6950 - val_accuracy: 0.7860 - lr: 1.2500e-04\n",
      "Epoch 44/100\n",
      "3997/3997 [==============================] - ETA: 0s - loss: 0.4092 - accuracy: 0.8597\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "3997/3997 [==============================] - 135s 34ms/step - loss: 0.4092 - accuracy: 0.8597 - val_loss: 0.6736 - val_accuracy: 0.7886 - lr: 1.2500e-04\n",
      "Epoch 45/100\n",
      "3997/3997 [==============================] - 135s 34ms/step - loss: 0.3987 - accuracy: 0.8617 - val_loss: 0.6594 - val_accuracy: 0.7927 - lr: 6.2500e-05\n",
      "Epoch 46/100\n",
      "3997/3997 [==============================] - 141s 35ms/step - loss: 0.3909 - accuracy: 0.8668 - val_loss: 0.6839 - val_accuracy: 0.7890 - lr: 6.2500e-05\n",
      "Epoch 47/100\n",
      "3997/3997 [==============================] - 135s 34ms/step - loss: 0.3874 - accuracy: 0.8680 - val_loss: 0.6618 - val_accuracy: 0.7958 - lr: 6.2500e-05\n",
      "Epoch 48/100\n",
      "3997/3997 [==============================] - 136s 34ms/step - loss: 0.3865 - accuracy: 0.8673 - val_loss: 0.6684 - val_accuracy: 0.7917 - lr: 6.2500e-05\n",
      "Epoch 49/100\n",
      "3997/3997 [==============================] - 136s 34ms/step - loss: 0.3837 - accuracy: 0.8676 - val_loss: 0.6552 - val_accuracy: 0.7985 - lr: 6.2500e-05\n",
      "Epoch 50/100\n",
      "3997/3997 [==============================] - 135s 34ms/step - loss: 0.3788 - accuracy: 0.8702 - val_loss: 0.6575 - val_accuracy: 0.7958 - lr: 6.2500e-05\n",
      "Epoch 51/100\n",
      "3997/3997 [==============================] - 135s 34ms/step - loss: 0.3788 - accuracy: 0.8694 - val_loss: 0.6644 - val_accuracy: 0.7947 - lr: 6.2500e-05\n",
      "Epoch 52/100\n",
      "3997/3997 [==============================] - 135s 34ms/step - loss: 0.3712 - accuracy: 0.8725 - val_loss: 0.6601 - val_accuracy: 0.7964 - lr: 6.2500e-05\n",
      "Epoch 53/100\n",
      "3997/3997 [==============================] - ETA: 0s - loss: 0.3718 - accuracy: 0.8718\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "3997/3997 [==============================] - 140s 35ms/step - loss: 0.3718 - accuracy: 0.8718 - val_loss: 0.7081 - val_accuracy: 0.7850 - lr: 6.2500e-05\n",
      "Epoch 54/100\n",
      "3997/3997 [==============================] - 137s 34ms/step - loss: 0.3678 - accuracy: 0.8752 - val_loss: 0.6734 - val_accuracy: 0.7949 - lr: 3.1250e-05\n",
      "Epoch 55/100\n",
      "3997/3997 [==============================] - 135s 34ms/step - loss: 0.3629 - accuracy: 0.8761 - val_loss: 0.6694 - val_accuracy: 0.7957 - lr: 3.1250e-05\n",
      "Epoch 56/100\n",
      "3997/3997 [==============================] - 135s 34ms/step - loss: 0.3613 - accuracy: 0.8754 - val_loss: 0.6614 - val_accuracy: 0.7966 - lr: 3.1250e-05\n",
      "Epoch 57/100\n",
      "3997/3997 [==============================] - ETA: 0s - loss: 0.3568 - accuracy: 0.8769\n",
      "Epoch 57: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "3997/3997 [==============================] - 135s 34ms/step - loss: 0.3568 - accuracy: 0.8769 - val_loss: 0.6643 - val_accuracy: 0.7986 - lr: 3.1250e-05\n",
      "Epoch 58/100\n",
      "3997/3997 [==============================] - 141s 35ms/step - loss: 0.3561 - accuracy: 0.8776 - val_loss: 0.6516 - val_accuracy: 0.8009 - lr: 1.5625e-05\n",
      "Epoch 59/100\n",
      "3997/3997 [==============================] - 141s 35ms/step - loss: 0.3506 - accuracy: 0.8805 - val_loss: 0.6547 - val_accuracy: 0.8010 - lr: 1.5625e-05\n",
      "Epoch 60/100\n",
      "3997/3997 [==============================] - 140s 35ms/step - loss: 0.3538 - accuracy: 0.8776 - val_loss: 0.6544 - val_accuracy: 0.8002 - lr: 1.5625e-05\n",
      "Epoch 61/100\n",
      "3997/3997 [==============================] - 138s 34ms/step - loss: 0.3565 - accuracy: 0.8777 - val_loss: 0.6549 - val_accuracy: 0.8006 - lr: 1.5625e-05\n",
      "Epoch 62/100\n",
      "3997/3997 [==============================] - ETA: 0s - loss: 0.3531 - accuracy: 0.8789\n",
      "Epoch 62: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "3997/3997 [==============================] - 137s 34ms/step - loss: 0.3531 - accuracy: 0.8789 - val_loss: 0.6617 - val_accuracy: 0.7987 - lr: 1.5625e-05\n",
      "Epoch 63/100\n",
      "3997/3997 [==============================] - 136s 34ms/step - loss: 0.3498 - accuracy: 0.8804 - val_loss: 0.6554 - val_accuracy: 0.7994 - lr: 1.0000e-05\n",
      "Epoch 64/100\n",
      "3997/3997 [==============================] - 135s 34ms/step - loss: 0.3507 - accuracy: 0.8792 - val_loss: 0.6647 - val_accuracy: 0.7980 - lr: 1.0000e-05\n",
      "Epoch 65/100\n",
      "3997/3997 [==============================] - 136s 34ms/step - loss: 0.3507 - accuracy: 0.8803 - val_loss: 0.6505 - val_accuracy: 0.8010 - lr: 1.0000e-05\n",
      "Epoch 66/100\n",
      "3997/3997 [==============================] - 139s 35ms/step - loss: 0.3556 - accuracy: 0.8770 - val_loss: 0.6591 - val_accuracy: 0.8005 - lr: 1.0000e-05\n",
      "Epoch 67/100\n",
      "3997/3997 [==============================] - 141s 35ms/step - loss: 0.3515 - accuracy: 0.8796 - val_loss: 0.6608 - val_accuracy: 0.7976 - lr: 1.0000e-05\n",
      "Epoch 68/100\n",
      "3997/3997 [==============================] - 146s 37ms/step - loss: 0.3540 - accuracy: 0.8783 - val_loss: 0.6518 - val_accuracy: 0.8005 - lr: 1.0000e-05\n",
      "Epoch 69/100\n",
      "3997/3997 [==============================] - 145s 36ms/step - loss: 0.3483 - accuracy: 0.8805 - val_loss: 0.6608 - val_accuracy: 0.7984 - lr: 1.0000e-05\n",
      "Epoch 70/100\n",
      "3997/3997 [==============================] - 138s 35ms/step - loss: 0.3495 - accuracy: 0.8794 - val_loss: 0.6549 - val_accuracy: 0.8002 - lr: 1.0000e-05\n",
      "Epoch 71/100\n",
      "3997/3997 [==============================] - 135s 34ms/step - loss: 0.3504 - accuracy: 0.8790 - val_loss: 0.6553 - val_accuracy: 0.7991 - lr: 1.0000e-05\n",
      "Epoch 72/100\n",
      "3997/3997 [==============================] - 141s 35ms/step - loss: 0.3472 - accuracy: 0.8808 - val_loss: 0.6572 - val_accuracy: 0.7982 - lr: 1.0000e-05\n",
      "Epoch 73/100\n",
      "3997/3997 [==============================] - 147s 37ms/step - loss: 0.3525 - accuracy: 0.8786 - val_loss: 0.6477 - val_accuracy: 0.8018 - lr: 1.0000e-05\n",
      "Epoch 74/100\n",
      "3997/3997 [==============================] - 146s 37ms/step - loss: 0.3478 - accuracy: 0.8792 - val_loss: 0.6459 - val_accuracy: 0.8035 - lr: 1.0000e-05\n",
      "Epoch 75/100\n",
      "3997/3997 [==============================] - 144s 36ms/step - loss: 0.3515 - accuracy: 0.8791 - val_loss: 0.6460 - val_accuracy: 0.8026 - lr: 1.0000e-05\n",
      "Epoch 76/100\n",
      "3997/3997 [==============================] - 142s 36ms/step - loss: 0.3446 - accuracy: 0.8809 - val_loss: 0.6489 - val_accuracy: 0.8018 - lr: 1.0000e-05\n",
      "Epoch 77/100\n",
      "3997/3997 [==============================] - 136s 34ms/step - loss: 0.3472 - accuracy: 0.8801 - val_loss: 0.6578 - val_accuracy: 0.7994 - lr: 1.0000e-05\n",
      "Epoch 78/100\n",
      "3997/3997 [==============================] - 142s 35ms/step - loss: 0.3450 - accuracy: 0.8825 - val_loss: 0.6607 - val_accuracy: 0.7990 - lr: 1.0000e-05\n",
      "Epoch 79/100\n",
      "3997/3997 [==============================] - 147s 37ms/step - loss: 0.3466 - accuracy: 0.8802 - val_loss: 0.6615 - val_accuracy: 0.7985 - lr: 1.0000e-05\n",
      "Epoch 80/100\n",
      "3997/3997 [==============================] - 143s 36ms/step - loss: 0.3458 - accuracy: 0.8814 - val_loss: 0.6552 - val_accuracy: 0.8001 - lr: 1.0000e-05\n",
      "Epoch 81/100\n",
      "3997/3997 [==============================] - 137s 34ms/step - loss: 0.3470 - accuracy: 0.8808 - val_loss: 0.6534 - val_accuracy: 0.7998 - lr: 1.0000e-05\n",
      "Epoch 82/100\n",
      "3997/3997 [==============================] - 137s 34ms/step - loss: 0.3464 - accuracy: 0.8818 - val_loss: 0.6503 - val_accuracy: 0.8025 - lr: 1.0000e-05\n",
      "Epoch 83/100\n",
      "3997/3997 [==============================] - 139s 35ms/step - loss: 0.3373 - accuracy: 0.8835 - val_loss: 0.6540 - val_accuracy: 0.8007 - lr: 1.0000e-05\n",
      "Epoch 84/100\n",
      "3997/3997 [==============================] - 140s 35ms/step - loss: 0.3451 - accuracy: 0.8808 - val_loss: 0.6435 - val_accuracy: 0.8033 - lr: 1.0000e-05\n",
      "Epoch 85/100\n",
      "3997/3997 [==============================] - 144s 36ms/step - loss: 0.3423 - accuracy: 0.8817 - val_loss: 0.6510 - val_accuracy: 0.8019 - lr: 1.0000e-05\n",
      "Epoch 86/100\n",
      "3997/3997 [==============================] - 144s 36ms/step - loss: 0.3396 - accuracy: 0.8832 - val_loss: 0.6521 - val_accuracy: 0.8018 - lr: 1.0000e-05\n",
      "Epoch 87/100\n",
      "3997/3997 [==============================] - 142s 36ms/step - loss: 0.3412 - accuracy: 0.8831 - val_loss: 0.6528 - val_accuracy: 0.8011 - lr: 1.0000e-05\n",
      "Epoch 88/100\n",
      "3997/3997 [==============================] - 141s 35ms/step - loss: 0.3383 - accuracy: 0.8841 - val_loss: 0.6435 - val_accuracy: 0.8046 - lr: 1.0000e-05\n",
      "Epoch 89/100\n",
      "3997/3997 [==============================] - 144s 36ms/step - loss: 0.3361 - accuracy: 0.8850 - val_loss: 0.6651 - val_accuracy: 0.7991 - lr: 1.0000e-05\n",
      "Epoch 90/100\n",
      "3997/3997 [==============================] - 144s 36ms/step - loss: 0.3384 - accuracy: 0.8846 - val_loss: 0.6672 - val_accuracy: 0.7973 - lr: 1.0000e-05\n",
      "Epoch 91/100\n",
      "3997/3997 [==============================] - 142s 35ms/step - loss: 0.3424 - accuracy: 0.8820 - val_loss: 0.6492 - val_accuracy: 0.8027 - lr: 1.0000e-05\n",
      "Epoch 92/100\n",
      "3997/3997 [==============================] - 140s 35ms/step - loss: 0.3392 - accuracy: 0.8835 - val_loss: 0.6490 - val_accuracy: 0.8015 - lr: 1.0000e-05\n",
      "Epoch 93/100\n",
      "3997/3997 [==============================] - 140s 35ms/step - loss: 0.3381 - accuracy: 0.8840 - val_loss: 0.6555 - val_accuracy: 0.8012 - lr: 1.0000e-05\n",
      "Epoch 94/100\n",
      "3997/3997 [==============================] - 140s 35ms/step - loss: 0.3353 - accuracy: 0.8846 - val_loss: 0.6589 - val_accuracy: 0.7995 - lr: 1.0000e-05\n",
      "Epoch 95/100\n",
      "3997/3997 [==============================] - 145s 36ms/step - loss: 0.3378 - accuracy: 0.8841 - val_loss: 0.6485 - val_accuracy: 0.8032 - lr: 1.0000e-05\n",
      "Epoch 96/100\n",
      "3997/3997 [==============================] - 141s 35ms/step - loss: 0.3332 - accuracy: 0.8836 - val_loss: 0.6498 - val_accuracy: 0.8051 - lr: 1.0000e-05\n",
      "Epoch 97/100\n",
      "3997/3997 [==============================] - 139s 35ms/step - loss: 0.3390 - accuracy: 0.8835 - val_loss: 0.6465 - val_accuracy: 0.8038 - lr: 1.0000e-05\n",
      "Epoch 98/100\n",
      "3997/3997 [==============================] - 143s 36ms/step - loss: 0.3314 - accuracy: 0.8866 - val_loss: 0.6518 - val_accuracy: 0.8025 - lr: 1.0000e-05\n",
      "Epoch 99/100\n",
      "3997/3997 [==============================] - 141s 35ms/step - loss: 0.3386 - accuracy: 0.8834 - val_loss: 0.6593 - val_accuracy: 0.8004 - lr: 1.0000e-05\n",
      "Epoch 100/100\n",
      "3997/3997 [==============================] - 141s 35ms/step - loss: 0.3361 - accuracy: 0.8846 - val_loss: 0.6515 - val_accuracy: 0.8015 - lr: 1.0000e-05\n"
     ]
    }
   ],
   "source": [
    "# model 1: Adam, batch of 16, no augmentation, Conv-dropout = 0.4\n",
    "\n",
    "model_1 = initiate_model()\n",
    "model_1.compile(loss=tf.keras.losses.categorical_crossentropy, metrics='accuracy',optimizer=adam)\n",
    "history_1 = model_1.fit(train_gen, validation_data=validation_gen, epochs = 100, callbacks = [reduce_lr, early_stopping, model_checkpoint, csv_logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e98525c1-7115-40f2-b97f-60b533335388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 26s 104ms/step - loss: 0.6923 - accuracy: 0.8000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6923049688339233, 0.7999500036239624]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.evaluate(test_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "95d79193-5602-45b4-adc5-1828ea59feaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 6s 22ms/step - loss: 0.6890 - accuracy: 0.8035\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6890215277671814, 0.803450882434845]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1_best = load_model('checkpoints\\CNN_80%_B16_NO-AUG_T2.h5')\n",
    "model_1_best_temp = model_1_best\n",
    "model_1_best.evaluate(test_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1d27f5bf-236d-49c1-b81a-48a4d7390ea2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history_1.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history_1.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy'); plt.ylabel('Accuracy'); plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history_1.history['loss'], label='Training Loss')\n",
    "plt.plot(history_1.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss'); plt.ylabel('Loss'); plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1de3e8c7-66e5-4b9f-b2a3-3a914c248706",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model_1_best.layers[:-7]:\n",
    "    if isinstance(layer, tf.keras.layers.Dropout):\n",
    "        layer.training = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3f46ff6f-4cf5-4622-8240-d52e9af34914",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1_best = model_1_best_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "05cd2121-56aa-49d1-9799-1267275bd7d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3997/3997 [==============================] - 138s 34ms/step - loss: 0.3361 - accuracy: 0.8842 - val_loss: 0.6538 - val_accuracy: 0.8017 - lr: 1.0000e-05\n",
      "Epoch 2/100\n",
      "3997/3997 [==============================] - 136s 34ms/step - loss: 0.3345 - accuracy: 0.8853 - val_loss: 0.6485 - val_accuracy: 0.8042 - lr: 1.0000e-05\n",
      "Epoch 3/100\n",
      "3997/3997 [==============================] - 136s 34ms/step - loss: 0.3299 - accuracy: 0.8883 - val_loss: 0.6488 - val_accuracy: 0.8040 - lr: 1.0000e-05\n",
      "Epoch 4/100\n",
      "3997/3997 [==============================] - 136s 34ms/step - loss: 0.3311 - accuracy: 0.8855 - val_loss: 0.6427 - val_accuracy: 0.8047 - lr: 1.0000e-05\n",
      "Epoch 5/100\n",
      "3997/3997 [==============================] - 137s 34ms/step - loss: 0.3263 - accuracy: 0.8871 - val_loss: 0.6453 - val_accuracy: 0.8046 - lr: 1.0000e-05\n",
      "Epoch 6/100\n",
      "3997/3997 [==============================] - 146s 36ms/step - loss: 0.3349 - accuracy: 0.8861 - val_loss: 0.6446 - val_accuracy: 0.8052 - lr: 1.0000e-05\n",
      "Epoch 7/100\n",
      "3997/3997 [==============================] - 136s 34ms/step - loss: 0.3329 - accuracy: 0.8867 - val_loss: 0.6451 - val_accuracy: 0.8039 - lr: 1.0000e-05\n",
      "Epoch 8/100\n",
      "3997/3997 [==============================] - 136s 34ms/step - loss: 0.3301 - accuracy: 0.8864 - val_loss: 0.6529 - val_accuracy: 0.8021 - lr: 1.0000e-05\n",
      "Epoch 9/100\n",
      "3997/3997 [==============================] - 136s 34ms/step - loss: 0.3347 - accuracy: 0.8861 - val_loss: 0.6475 - val_accuracy: 0.8031 - lr: 1.0000e-05\n",
      "Epoch 10/100\n",
      "3997/3997 [==============================] - 138s 34ms/step - loss: 0.3320 - accuracy: 0.8859 - val_loss: 0.6419 - val_accuracy: 0.8054 - lr: 1.0000e-05\n",
      "Epoch 11/100\n",
      "3997/3997 [==============================] - 136s 34ms/step - loss: 0.3289 - accuracy: 0.8870 - val_loss: 0.6451 - val_accuracy: 0.8058 - lr: 1.0000e-05\n",
      "Epoch 12/100\n",
      "3997/3997 [==============================] - 136s 34ms/step - loss: 0.3233 - accuracy: 0.8898 - val_loss: 0.6528 - val_accuracy: 0.8027 - lr: 1.0000e-05\n",
      "Epoch 13/100\n",
      "3997/3997 [==============================] - 136s 34ms/step - loss: 0.3275 - accuracy: 0.8881 - val_loss: 0.6513 - val_accuracy: 0.8033 - lr: 1.0000e-05\n",
      "Epoch 14/100\n",
      "3997/3997 [==============================] - 136s 34ms/step - loss: 0.3296 - accuracy: 0.8850 - val_loss: 0.6523 - val_accuracy: 0.8032 - lr: 1.0000e-05\n",
      "Epoch 15/100\n",
      "3997/3997 [==============================] - 137s 34ms/step - loss: 0.3306 - accuracy: 0.8863 - val_loss: 0.6487 - val_accuracy: 0.8037 - lr: 1.0000e-05\n",
      "Epoch 16/100\n",
      "3997/3997 [==============================] - 136s 34ms/step - loss: 0.3289 - accuracy: 0.8865 - val_loss: 0.6498 - val_accuracy: 0.8047 - lr: 1.0000e-05\n",
      "Epoch 17/100\n",
      "3997/3997 [==============================] - 137s 34ms/step - loss: 0.3296 - accuracy: 0.8871 - val_loss: 0.6530 - val_accuracy: 0.8040 - lr: 1.0000e-05\n",
      "Epoch 18/100\n",
      "3997/3997 [==============================] - 181s 45ms/step - loss: 0.3275 - accuracy: 0.8882 - val_loss: 0.6466 - val_accuracy: 0.8034 - lr: 1.0000e-05\n",
      "Epoch 19/100\n",
      "3997/3997 [==============================] - 136s 34ms/step - loss: 0.3217 - accuracy: 0.8905 - val_loss: 0.6539 - val_accuracy: 0.8032 - lr: 1.0000e-05\n",
      "Epoch 20/100\n",
      "3997/3997 [==============================] - 136s 34ms/step - loss: 0.3295 - accuracy: 0.8877 - val_loss: 0.6595 - val_accuracy: 0.8017 - lr: 1.0000e-05\n",
      "Epoch 21/100\n",
      "3997/3997 [==============================] - 136s 34ms/step - loss: 0.3361 - accuracy: 0.8845 - val_loss: 0.6467 - val_accuracy: 0.8052 - lr: 1.0000e-05\n",
      "Epoch 22/100\n",
      "3997/3997 [==============================] - 136s 34ms/step - loss: 0.3261 - accuracy: 0.8876 - val_loss: 0.6513 - val_accuracy: 0.8024 - lr: 1.0000e-05\n",
      "Epoch 23/100\n",
      "3997/3997 [==============================] - 136s 34ms/step - loss: 0.3258 - accuracy: 0.8872 - val_loss: 0.6512 - val_accuracy: 0.8034 - lr: 1.0000e-05\n",
      "Epoch 24/100\n",
      "3997/3997 [==============================] - 136s 34ms/step - loss: 0.3309 - accuracy: 0.8863 - val_loss: 0.6582 - val_accuracy: 0.8019 - lr: 1.0000e-05\n",
      "Epoch 25/100\n",
      "3997/3997 [==============================] - 137s 34ms/step - loss: 0.3247 - accuracy: 0.8880 - val_loss: 0.6429 - val_accuracy: 0.8051 - lr: 1.0000e-05\n",
      "Epoch 26/100\n",
      "3997/3997 [==============================] - 137s 34ms/step - loss: 0.3262 - accuracy: 0.8877 - val_loss: 0.6599 - val_accuracy: 0.8011 - lr: 1.0000e-05\n",
      "Epoch 27/100\n",
      "3997/3997 [==============================] - 137s 34ms/step - loss: 0.3308 - accuracy: 0.8868 - val_loss: 0.6455 - val_accuracy: 0.8066 - lr: 1.0000e-05\n",
      "Epoch 28/100\n",
      "3997/3997 [==============================] - 136s 34ms/step - loss: 0.3316 - accuracy: 0.8864 - val_loss: 0.6498 - val_accuracy: 0.8050 - lr: 1.0000e-05\n",
      "Epoch 29/100\n",
      "3997/3997 [==============================] - 137s 34ms/step - loss: 0.3283 - accuracy: 0.8882 - val_loss: 0.6469 - val_accuracy: 0.8051 - lr: 1.0000e-05\n",
      "Epoch 30/100\n",
      "3997/3997 [==============================] - 137s 34ms/step - loss: 0.3255 - accuracy: 0.8899 - val_loss: 0.6464 - val_accuracy: 0.8046 - lr: 1.0000e-05\n",
      "Epoch 31/100\n",
      "3997/3997 [==============================] - 136s 34ms/step - loss: 0.3248 - accuracy: 0.8878 - val_loss: 0.6523 - val_accuracy: 0.8017 - lr: 1.0000e-05\n",
      "Epoch 32/100\n",
      "3997/3997 [==============================] - 150s 38ms/step - loss: 0.3266 - accuracy: 0.8882 - val_loss: 0.6562 - val_accuracy: 0.8033 - lr: 1.0000e-05\n",
      "Epoch 33/100\n",
      "3997/3997 [==============================] - 148s 37ms/step - loss: 0.3273 - accuracy: 0.8879 - val_loss: 0.6545 - val_accuracy: 0.8033 - lr: 1.0000e-05\n",
      "Epoch 34/100\n",
      "3997/3997 [==============================] - 143s 36ms/step - loss: 0.3244 - accuracy: 0.8889 - val_loss: 0.6554 - val_accuracy: 0.8036 - lr: 1.0000e-05\n",
      "Epoch 35/100\n",
      "3997/3997 [==============================] - 138s 35ms/step - loss: 0.3282 - accuracy: 0.8882 - val_loss: 0.6467 - val_accuracy: 0.8041 - lr: 1.0000e-05\n",
      "Epoch 36/100\n",
      "3997/3997 [==============================] - 145s 36ms/step - loss: 0.3232 - accuracy: 0.8884 - val_loss: 0.6541 - val_accuracy: 0.8032 - lr: 1.0000e-05\n",
      "Epoch 37/100\n",
      "3997/3997 [==============================] - 143s 36ms/step - loss: 0.3183 - accuracy: 0.8910 - val_loss: 0.6431 - val_accuracy: 0.8064 - lr: 1.0000e-05\n",
      "Epoch 38/100\n",
      "3997/3997 [==============================] - 137s 34ms/step - loss: 0.3231 - accuracy: 0.8888 - val_loss: 0.6447 - val_accuracy: 0.8056 - lr: 1.0000e-05\n",
      "Epoch 39/100\n",
      "3997/3997 [==============================] - 136s 34ms/step - loss: 0.3180 - accuracy: 0.8913 - val_loss: 0.6537 - val_accuracy: 0.8023 - lr: 1.0000e-05\n",
      "Epoch 40/100\n",
      "3997/3997 [==============================] - 143s 36ms/step - loss: 0.3187 - accuracy: 0.8911 - val_loss: 0.6552 - val_accuracy: 0.8042 - lr: 1.0000e-05\n",
      "Epoch 41/100\n",
      "3997/3997 [==============================] - 137s 34ms/step - loss: 0.3190 - accuracy: 0.8901 - val_loss: 0.6440 - val_accuracy: 0.8057 - lr: 1.0000e-05\n",
      "Epoch 42/100\n",
      "3997/3997 [==============================] - 141s 35ms/step - loss: 0.3209 - accuracy: 0.8898 - val_loss: 0.6483 - val_accuracy: 0.8058 - lr: 1.0000e-05\n",
      "Epoch 43/100\n",
      "3997/3997 [==============================] - 137s 34ms/step - loss: 0.3194 - accuracy: 0.8895 - val_loss: 0.6404 - val_accuracy: 0.8076 - lr: 1.0000e-05\n",
      "Epoch 44/100\n",
      "3997/3997 [==============================] - 142s 36ms/step - loss: 0.3187 - accuracy: 0.8900 - val_loss: 0.6497 - val_accuracy: 0.8052 - lr: 1.0000e-05\n",
      "Epoch 45/100\n",
      "3997/3997 [==============================] - 149s 37ms/step - loss: 0.3193 - accuracy: 0.8900 - val_loss: 0.6536 - val_accuracy: 0.8043 - lr: 1.0000e-05\n",
      "Epoch 46/100\n",
      "3997/3997 [==============================] - 136s 34ms/step - loss: 0.3200 - accuracy: 0.8894 - val_loss: 0.6464 - val_accuracy: 0.8055 - lr: 1.0000e-05\n",
      "Epoch 47/100\n",
      "3997/3997 [==============================] - 139s 35ms/step - loss: 0.3240 - accuracy: 0.8889 - val_loss: 0.6541 - val_accuracy: 0.8032 - lr: 1.0000e-05\n",
      "Epoch 48/100\n",
      "3997/3997 [==============================] - 136s 34ms/step - loss: 0.3202 - accuracy: 0.8900 - val_loss: 0.6467 - val_accuracy: 0.8057 - lr: 1.0000e-05\n",
      "Epoch 49/100\n",
      "3997/3997 [==============================] - 135s 34ms/step - loss: 0.3156 - accuracy: 0.8913 - val_loss: 0.6418 - val_accuracy: 0.8073 - lr: 1.0000e-05\n",
      "Epoch 50/100\n",
      "3997/3997 [==============================] - 135s 34ms/step - loss: 0.3182 - accuracy: 0.8921 - val_loss: 0.6480 - val_accuracy: 0.8042 - lr: 1.0000e-05\n",
      "Epoch 51/100\n",
      "3997/3997 [==============================] - 136s 34ms/step - loss: 0.3192 - accuracy: 0.8901 - val_loss: 0.6451 - val_accuracy: 0.8067 - lr: 1.0000e-05\n",
      "Epoch 52/100\n",
      "3997/3997 [==============================] - 140s 35ms/step - loss: 0.3160 - accuracy: 0.8917 - val_loss: 0.6490 - val_accuracy: 0.8066 - lr: 1.0000e-05\n",
      "Epoch 53/100\n",
      "3997/3997 [==============================] - 136s 34ms/step - loss: 0.3140 - accuracy: 0.8919 - val_loss: 0.6441 - val_accuracy: 0.8061 - lr: 1.0000e-05\n",
      "Epoch 54/100\n",
      "3997/3997 [==============================] - 136s 34ms/step - loss: 0.3147 - accuracy: 0.8922 - val_loss: 0.6485 - val_accuracy: 0.8075 - lr: 1.0000e-05\n",
      "Epoch 55/100\n",
      "3997/3997 [==============================] - 135s 34ms/step - loss: 0.3146 - accuracy: 0.8931 - val_loss: 0.6455 - val_accuracy: 0.8069 - lr: 1.0000e-05\n",
      "Epoch 56/100\n",
      "3997/3997 [==============================] - 136s 34ms/step - loss: 0.3166 - accuracy: 0.8918 - val_loss: 0.6379 - val_accuracy: 0.8089 - lr: 1.0000e-05\n",
      "Epoch 57/100\n",
      "3997/3997 [==============================] - 136s 34ms/step - loss: 0.3159 - accuracy: 0.8911 - val_loss: 0.6468 - val_accuracy: 0.8066 - lr: 1.0000e-05\n",
      "Epoch 58/100\n",
      "3997/3997 [==============================] - 138s 35ms/step - loss: 0.3156 - accuracy: 0.8917 - val_loss: 0.6519 - val_accuracy: 0.8060 - lr: 1.0000e-05\n",
      "Epoch 59/100\n",
      "3997/3997 [==============================] - 136s 34ms/step - loss: 0.3147 - accuracy: 0.8929 - val_loss: 0.6448 - val_accuracy: 0.8057 - lr: 1.0000e-05\n",
      "Epoch 60/100\n",
      "3997/3997 [==============================] - 136s 34ms/step - loss: 0.3137 - accuracy: 0.8923 - val_loss: 0.6372 - val_accuracy: 0.8082 - lr: 1.0000e-05\n",
      "Epoch 61/100\n",
      "3997/3997 [==============================] - 136s 34ms/step - loss: 0.3145 - accuracy: 0.8930 - val_loss: 0.6436 - val_accuracy: 0.8079 - lr: 1.0000e-05\n",
      "Epoch 62/100\n",
      "3997/3997 [==============================] - 136s 34ms/step - loss: 0.3099 - accuracy: 0.8943 - val_loss: 0.6534 - val_accuracy: 0.8047 - lr: 1.0000e-05\n",
      "Epoch 63/100\n",
      "3997/3997 [==============================] - 139s 35ms/step - loss: 0.3110 - accuracy: 0.8930 - val_loss: 0.6387 - val_accuracy: 0.8097 - lr: 1.0000e-05\n",
      "Epoch 64/100\n",
      "3997/3997 [==============================] - 141s 35ms/step - loss: 0.3129 - accuracy: 0.8929 - val_loss: 0.6430 - val_accuracy: 0.8081 - lr: 1.0000e-05\n",
      "Epoch 65/100\n",
      "3997/3997 [==============================] - 143s 36ms/step - loss: 0.3165 - accuracy: 0.8915 - val_loss: 0.6402 - val_accuracy: 0.8096 - lr: 1.0000e-05\n",
      "Epoch 66/100\n",
      "3997/3997 [==============================] - 143s 36ms/step - loss: 0.3133 - accuracy: 0.8929 - val_loss: 0.6454 - val_accuracy: 0.8069 - lr: 1.0000e-05\n",
      "Epoch 67/100\n",
      "3997/3997 [==============================] - 143s 36ms/step - loss: 0.3166 - accuracy: 0.8905 - val_loss: 0.6393 - val_accuracy: 0.8074 - lr: 1.0000e-05\n",
      "Epoch 68/100\n",
      "3997/3997 [==============================] - 143s 36ms/step - loss: 0.3079 - accuracy: 0.8936 - val_loss: 0.6416 - val_accuracy: 0.8083 - lr: 1.0000e-05\n",
      "Epoch 69/100\n",
      "3997/3997 [==============================] - 148s 37ms/step - loss: 0.3117 - accuracy: 0.8932 - val_loss: 0.6409 - val_accuracy: 0.8079 - lr: 1.0000e-05\n",
      "Epoch 70/100\n",
      "3997/3997 [==============================] - 142s 36ms/step - loss: 0.3122 - accuracy: 0.8932 - val_loss: 0.6448 - val_accuracy: 0.8073 - lr: 1.0000e-05\n",
      "Epoch 71/100\n",
      "3997/3997 [==============================] - 138s 35ms/step - loss: 0.3109 - accuracy: 0.8933 - val_loss: 0.6450 - val_accuracy: 0.8077 - lr: 1.0000e-05\n",
      "Epoch 72/100\n",
      "3997/3997 [==============================] - 141s 35ms/step - loss: 0.3121 - accuracy: 0.8929 - val_loss: 0.6423 - val_accuracy: 0.8078 - lr: 1.0000e-05\n",
      "Epoch 73/100\n",
      "3997/3997 [==============================] - 137s 34ms/step - loss: 0.3083 - accuracy: 0.8943 - val_loss: 0.6399 - val_accuracy: 0.8099 - lr: 1.0000e-05\n",
      "Epoch 74/100\n",
      "3997/3997 [==============================] - 141s 35ms/step - loss: 0.3013 - accuracy: 0.8960 - val_loss: 0.6524 - val_accuracy: 0.8055 - lr: 1.0000e-05\n",
      "Epoch 75/100\n",
      "3997/3997 [==============================] - 139s 35ms/step - loss: 0.3089 - accuracy: 0.8946 - val_loss: 0.6510 - val_accuracy: 0.8046 - lr: 1.0000e-05\n",
      "Epoch 76/100\n",
      "3997/3997 [==============================] - 139s 35ms/step - loss: 0.3069 - accuracy: 0.8966 - val_loss: 0.6356 - val_accuracy: 0.8104 - lr: 1.0000e-05\n",
      "Epoch 77/100\n",
      "3997/3997 [==============================] - 140s 35ms/step - loss: 0.3097 - accuracy: 0.8925 - val_loss: 0.6333 - val_accuracy: 0.8094 - lr: 1.0000e-05\n",
      "Epoch 78/100\n",
      "3997/3997 [==============================] - 138s 34ms/step - loss: 0.3087 - accuracy: 0.8940 - val_loss: 0.6401 - val_accuracy: 0.8065 - lr: 1.0000e-05\n",
      "Epoch 79/100\n",
      "3997/3997 [==============================] - 136s 34ms/step - loss: 0.3075 - accuracy: 0.8945 - val_loss: 0.6449 - val_accuracy: 0.8077 - lr: 1.0000e-05\n",
      "Epoch 80/100\n",
      "3997/3997 [==============================] - 141s 35ms/step - loss: 0.3079 - accuracy: 0.8949 - val_loss: 0.6429 - val_accuracy: 0.8062 - lr: 1.0000e-05\n",
      "Epoch 81/100\n",
      "3997/3997 [==============================] - 138s 35ms/step - loss: 0.3077 - accuracy: 0.8942 - val_loss: 0.6442 - val_accuracy: 0.8080 - lr: 1.0000e-05\n",
      "Epoch 82/100\n",
      "3997/3997 [==============================] - 138s 35ms/step - loss: 0.3089 - accuracy: 0.8935 - val_loss: 0.6583 - val_accuracy: 0.8037 - lr: 1.0000e-05\n",
      "Epoch 83/100\n",
      "3997/3997 [==============================] - 140s 35ms/step - loss: 0.3061 - accuracy: 0.8970 - val_loss: 0.6431 - val_accuracy: 0.8072 - lr: 1.0000e-05\n",
      "Epoch 84/100\n",
      "3997/3997 [==============================] - 139s 35ms/step - loss: 0.3083 - accuracy: 0.8944 - val_loss: 0.6437 - val_accuracy: 0.8077 - lr: 1.0000e-05\n",
      "Epoch 85/100\n",
      "3997/3997 [==============================] - 139s 35ms/step - loss: 0.3061 - accuracy: 0.8964 - val_loss: 0.6386 - val_accuracy: 0.8071 - lr: 1.0000e-05\n",
      "Epoch 86/100\n",
      "3997/3997 [==============================] - 140s 35ms/step - loss: 0.3039 - accuracy: 0.8955 - val_loss: 0.6377 - val_accuracy: 0.8097 - lr: 1.0000e-05\n",
      "Epoch 87/100\n",
      "3997/3997 [==============================] - 137s 34ms/step - loss: 0.3061 - accuracy: 0.8937 - val_loss: 0.6410 - val_accuracy: 0.8071 - lr: 1.0000e-05\n",
      "Epoch 88/100\n",
      "3997/3997 [==============================] - 141s 35ms/step - loss: 0.3066 - accuracy: 0.8938 - val_loss: 0.6368 - val_accuracy: 0.8088 - lr: 1.0000e-05\n",
      "Epoch 89/100\n",
      "3997/3997 [==============================] - 136s 34ms/step - loss: 0.3068 - accuracy: 0.8958 - val_loss: 0.6426 - val_accuracy: 0.8086 - lr: 1.0000e-05\n",
      "Epoch 90/100\n",
      "3997/3997 [==============================] - 139s 35ms/step - loss: 0.3065 - accuracy: 0.8931 - val_loss: 0.6424 - val_accuracy: 0.8079 - lr: 1.0000e-05\n",
      "Epoch 91/100\n",
      "3997/3997 [==============================] - 139s 35ms/step - loss: 0.3025 - accuracy: 0.8959 - val_loss: 0.6489 - val_accuracy: 0.8062 - lr: 1.0000e-05\n",
      "Epoch 92/100\n",
      "3997/3997 [==============================] - 139s 35ms/step - loss: 0.3056 - accuracy: 0.8955 - val_loss: 0.6417 - val_accuracy: 0.8083 - lr: 1.0000e-05\n",
      "Epoch 93/100\n",
      "3997/3997 [==============================] - 139s 35ms/step - loss: 0.2971 - accuracy: 0.8976 - val_loss: 0.6418 - val_accuracy: 0.8075 - lr: 1.0000e-05\n",
      "Epoch 94/100\n",
      "3997/3997 [==============================] - 140s 35ms/step - loss: 0.3016 - accuracy: 0.8972 - val_loss: 0.6386 - val_accuracy: 0.8105 - lr: 1.0000e-05\n",
      "Epoch 95/100\n",
      "3997/3997 [==============================] - 139s 35ms/step - loss: 0.3007 - accuracy: 0.8976 - val_loss: 0.6420 - val_accuracy: 0.8078 - lr: 1.0000e-05\n",
      "Epoch 96/100\n",
      "3997/3997 [==============================] - 140s 35ms/step - loss: 0.3030 - accuracy: 0.8964 - val_loss: 0.6450 - val_accuracy: 0.8076 - lr: 1.0000e-05\n",
      "Epoch 97/100\n",
      "3997/3997 [==============================] - 140s 35ms/step - loss: 0.3008 - accuracy: 0.8960 - val_loss: 0.6421 - val_accuracy: 0.8097 - lr: 1.0000e-05\n",
      "Epoch 98/100\n",
      "3997/3997 [==============================] - 138s 35ms/step - loss: 0.2988 - accuracy: 0.8971 - val_loss: 0.6559 - val_accuracy: 0.8062 - lr: 1.0000e-05\n",
      "Epoch 99/100\n",
      "3997/3997 [==============================] - 139s 35ms/step - loss: 0.3039 - accuracy: 0.8972 - val_loss: 0.6404 - val_accuracy: 0.8089 - lr: 1.0000e-05\n",
      "Epoch 100/100\n",
      "3997/3997 [==============================] - 139s 35ms/step - loss: 0.2973 - accuracy: 0.8981 - val_loss: 0.6391 - val_accuracy: 0.8103 - lr: 1.0000e-05\n"
     ]
    }
   ],
   "source": [
    "# 2nd training session\n",
    "\n",
    "model_1.compile(loss=tf.keras.losses.categorical_crossentropy, metrics='accuracy',optimizer=adam)\n",
    "history_1 = model_1.fit(train_gen, validation_data=validation_gen, epochs = 100, callbacks = [reduce_lr, early_stopping, model_checkpoint, csv_logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5d6c9a43-5f16-4ab4-8083-b507f83549ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 6s 23ms/step - loss: 0.6790 - accuracy: 0.8110\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6790119409561157, 0.8109527230262756]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1_best = load_model('checkpoints\\CNN_81%_B16_NO-AUG_T2.h5')\n",
    "model_1_best.evaluate(test_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d2e8cb4b-25e0-4994-affd-5fa65385c414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " 897/3997 [=====>........................] - ETA: 1:54 - loss: 0.2099 - accuracy: 0.9291"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[46], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m history_1 \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_1_best\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_gen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_gen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mreduce_lr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_checkpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcsv_logger\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorgpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorgpu\\lib\\site-packages\\keras\\engine\\training.py:1570\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1568\u001b[0m logs \u001b[38;5;241m=\u001b[39m tmp_logs\n\u001b[0;32m   1569\u001b[0m end_step \u001b[38;5;241m=\u001b[39m step \u001b[38;5;241m+\u001b[39m data_handler\u001b[38;5;241m.\u001b[39mstep_increment\n\u001b[1;32m-> 1570\u001b[0m \u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_train_batch_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mend_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n\u001b[0;32m   1572\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorgpu\\lib\\site-packages\\keras\\callbacks.py:470\u001b[0m, in \u001b[0;36mCallbackList.on_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    463\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Calls the `on_train_batch_end` methods of its callbacks.\u001b[39;00m\n\u001b[0;32m    464\u001b[0m \n\u001b[0;32m    465\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m    466\u001b[0m \u001b[38;5;124;03m    batch: Integer, index of batch within the current epoch.\u001b[39;00m\n\u001b[0;32m    467\u001b[0m \u001b[38;5;124;03m    logs: Dict. Aggregated metric results up until this batch.\u001b[39;00m\n\u001b[0;32m    468\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    469\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_call_train_batch_hooks:\n\u001b[1;32m--> 470\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mModeKeys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTRAIN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mend\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorgpu\\lib\\site-packages\\keras\\callbacks.py:317\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook\u001b[1;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[0;32m    315\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_batch_begin_hook(mode, batch, logs)\n\u001b[0;32m    316\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m hook \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 317\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_end_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    319\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized hook: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExpected values are [\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbegin\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    322\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorgpu\\lib\\site-packages\\keras\\callbacks.py:340\u001b[0m, in \u001b[0;36mCallbackList._call_batch_end_hook\u001b[1;34m(self, mode, batch, logs)\u001b[0m\n\u001b[0;32m    337\u001b[0m     batch_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_start_time\n\u001b[0;32m    338\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_times\u001b[38;5;241m.\u001b[39mappend(batch_time)\n\u001b[1;32m--> 340\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_hook_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhook_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    342\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_times) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_batches_for_timing_check:\n\u001b[0;32m    343\u001b[0m     end_hook_name \u001b[38;5;241m=\u001b[39m hook_name\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorgpu\\lib\\site-packages\\keras\\callbacks.py:388\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook_helper\u001b[1;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[0;32m    386\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks:\n\u001b[0;32m    387\u001b[0m     hook \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(callback, hook_name)\n\u001b[1;32m--> 388\u001b[0m     \u001b[43mhook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    390\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_timing:\n\u001b[0;32m    391\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m hook_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_hook_times:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorgpu\\lib\\site-packages\\keras\\callbacks.py:1081\u001b[0m, in \u001b[0;36mProgbarLogger.on_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1080\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mon_train_batch_end\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch, logs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m-> 1081\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch_update_progbar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorgpu\\lib\\site-packages\\keras\\callbacks.py:1157\u001b[0m, in \u001b[0;36mProgbarLogger._batch_update_progbar\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1153\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseen \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m add_seen\n\u001b[0;32m   1155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1156\u001b[0m     \u001b[38;5;66;03m# Only block async when verbose = 1.\u001b[39;00m\n\u001b[1;32m-> 1157\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[43mtf_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msync_to_numpy_or_python_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1158\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprogbar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseen, \u001b[38;5;28mlist\u001b[39m(logs\u001b[38;5;241m.\u001b[39mitems()), finalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorgpu\\lib\\site-packages\\keras\\utils\\tf_utils.py:635\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type\u001b[1;34m(tensors)\u001b[0m\n\u001b[0;32m    632\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\n\u001b[0;32m    633\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mndim(t) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m t\n\u001b[1;32m--> 635\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_structure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_to_single_numpy_or_python_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorgpu\\lib\\site-packages\\tensorflow\\python\\util\\nest.py:917\u001b[0m, in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    913\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[0;32m    914\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[0;32m    916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pack_sequence_as(\n\u001b[1;32m--> 917\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m], [func(\u001b[38;5;241m*\u001b[39mx) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[0;32m    918\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorgpu\\lib\\site-packages\\tensorflow\\python\\util\\nest.py:917\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    913\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[0;32m    914\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[0;32m    916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pack_sequence_as(\n\u001b[1;32m--> 917\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m], [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[0;32m    918\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorgpu\\lib\\site-packages\\keras\\utils\\tf_utils.py:628\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type.<locals>._to_single_numpy_or_python_type\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    625\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_to_single_numpy_or_python_type\u001b[39m(t):\n\u001b[0;32m    626\u001b[0m     \u001b[38;5;66;03m# Don't turn ragged or sparse tensors to NumPy.\u001b[39;00m\n\u001b[0;32m    627\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, tf\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[1;32m--> 628\u001b[0m         t \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;66;03m# Strings, ragged and sparse tensors don't have .item(). Return them\u001b[39;00m\n\u001b[0;32m    630\u001b[0m     \u001b[38;5;66;03m# as-is.\u001b[39;00m\n\u001b[0;32m    631\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, (np\u001b[38;5;241m.\u001b[39mndarray, np\u001b[38;5;241m.\u001b[39mgeneric)):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorgpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1157\u001b[0m, in \u001b[0;36m_EagerTensorBase.numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1134\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Copy of the contents of this Tensor into a NumPy array or scalar.\u001b[39;00m\n\u001b[0;32m   1135\u001b[0m \n\u001b[0;32m   1136\u001b[0m \u001b[38;5;124;03mUnlike NumPy arrays, Tensors are immutable, so this method has to copy\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1154\u001b[0m \u001b[38;5;124;03m    NumPy dtype.\u001b[39;00m\n\u001b[0;32m   1155\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1156\u001b[0m \u001b[38;5;66;03m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[39;00m\n\u001b[1;32m-> 1157\u001b[0m maybe_arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1158\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m maybe_arr\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(maybe_arr, np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;28;01melse\u001b[39;00m maybe_arr\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorgpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1123\u001b[0m, in \u001b[0;36m_EagerTensorBase._numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1121\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_numpy\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m   1122\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1124\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1125\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history_1 = model_1_best.fit(train_gen, validation_data=validation_gen, epochs = 100, callbacks = [reduce_lr, early_stopping, model_checkpoint, csv_logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a43546d1-bcb4-4e71-beb4-6c8b13ff5b80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 6s 23ms/step - loss: 0.6763 - accuracy: 0.8127\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6763340830802917, 0.8127031922340393]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1_best = load_model('checkpoints\\CNN_81%_B16_NO-AUG_T3.h5')\n",
    "model_1_best.evaluate(test_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "46837703-685f-4ada-b8d3-97b29f3ece4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "3997/3997 [==============================] - 195s 49ms/step - loss: 0.2793 - accuracy: 0.9036 - val_loss: 0.6385 - val_accuracy: 0.8138 - lr: 1.0000e-05\n",
      "Epoch 2/300\n",
      "3997/3997 [==============================] - 149s 37ms/step - loss: 0.2833 - accuracy: 0.9028 - val_loss: 0.6362 - val_accuracy: 0.8126 - lr: 1.0000e-05\n",
      "Epoch 3/300\n",
      "3997/3997 [==============================] - 141s 35ms/step - loss: 0.2853 - accuracy: 0.9026 - val_loss: 0.6307 - val_accuracy: 0.8140 - lr: 1.0000e-05\n",
      "Epoch 4/300\n",
      "3997/3997 [==============================] - 136s 34ms/step - loss: 0.2833 - accuracy: 0.9036 - val_loss: 0.6479 - val_accuracy: 0.8093 - lr: 1.0000e-05\n",
      "Epoch 5/300\n",
      "3997/3997 [==============================] - 136s 34ms/step - loss: 0.2826 - accuracy: 0.9024 - val_loss: 0.6443 - val_accuracy: 0.8113 - lr: 1.0000e-05\n",
      "Epoch 6/300\n",
      "3997/3997 [==============================] - 136s 34ms/step - loss: 0.2825 - accuracy: 0.9033 - val_loss: 0.6490 - val_accuracy: 0.8100 - lr: 1.0000e-05\n",
      "Epoch 7/300\n",
      "3997/3997 [==============================] - 136s 34ms/step - loss: 0.2822 - accuracy: 0.9034 - val_loss: 0.6395 - val_accuracy: 0.8131 - lr: 1.0000e-05\n",
      "Epoch 8/300\n",
      "3997/3997 [==============================] - 136s 34ms/step - loss: 0.2830 - accuracy: 0.9034 - val_loss: 0.6385 - val_accuracy: 0.8124 - lr: 1.0000e-05\n",
      "Epoch 9/300\n",
      "3997/3997 [==============================] - 136s 34ms/step - loss: 0.2865 - accuracy: 0.9018 - val_loss: 0.6433 - val_accuracy: 0.8108 - lr: 1.0000e-05\n",
      "Epoch 10/300\n",
      "3997/3997 [==============================] - 136s 34ms/step - loss: 0.2850 - accuracy: 0.9024 - val_loss: 0.6465 - val_accuracy: 0.8092 - lr: 1.0000e-05\n",
      "Epoch 11/300\n",
      "3997/3997 [==============================] - 136s 34ms/step - loss: 0.2847 - accuracy: 0.9031 - val_loss: 0.6450 - val_accuracy: 0.8104 - lr: 1.0000e-05\n",
      "Epoch 12/300\n",
      "3997/3997 [==============================] - 136s 34ms/step - loss: 0.2861 - accuracy: 0.9030 - val_loss: 0.6429 - val_accuracy: 0.8116 - lr: 1.0000e-05\n",
      "Epoch 13/300\n",
      "3997/3997 [==============================] - 137s 34ms/step - loss: 0.2830 - accuracy: 0.9024 - val_loss: 0.6458 - val_accuracy: 0.8113 - lr: 1.0000e-05\n",
      "Epoch 14/300\n",
      "3997/3997 [==============================] - 137s 34ms/step - loss: 0.2797 - accuracy: 0.9033 - val_loss: 0.6334 - val_accuracy: 0.8120 - lr: 1.0000e-05\n",
      "Epoch 15/300\n",
      "3997/3997 [==============================] - 160s 40ms/step - loss: 0.2782 - accuracy: 0.9044 - val_loss: 0.6297 - val_accuracy: 0.8142 - lr: 1.0000e-05\n",
      "Epoch 16/300\n",
      "3997/3997 [==============================] - 167s 42ms/step - loss: 0.2810 - accuracy: 0.9027 - val_loss: 0.6356 - val_accuracy: 0.8122 - lr: 1.0000e-05\n",
      "Epoch 17/300\n",
      "3997/3997 [==============================] - 160s 40ms/step - loss: 0.2804 - accuracy: 0.9037 - val_loss: 0.6402 - val_accuracy: 0.8132 - lr: 1.0000e-05\n",
      "Epoch 18/300\n",
      "3997/3997 [==============================] - 137s 34ms/step - loss: 0.2815 - accuracy: 0.9030 - val_loss: 0.6346 - val_accuracy: 0.8142 - lr: 1.0000e-05\n",
      "Epoch 19/300\n",
      "3997/3997 [==============================] - 136s 34ms/step - loss: 0.2848 - accuracy: 0.9024 - val_loss: 0.6445 - val_accuracy: 0.8122 - lr: 1.0000e-05\n",
      "Epoch 20/300\n",
      "3997/3997 [==============================] - 136s 34ms/step - loss: 0.2775 - accuracy: 0.9051 - val_loss: 0.6387 - val_accuracy: 0.8139 - lr: 1.0000e-05\n",
      "Epoch 21/300\n",
      "3997/3997 [==============================] - 137s 34ms/step - loss: 0.2748 - accuracy: 0.9054 - val_loss: 0.6307 - val_accuracy: 0.8140 - lr: 1.0000e-05\n",
      "Epoch 22/300\n",
      "3997/3997 [==============================] - 137s 34ms/step - loss: 0.2793 - accuracy: 0.9046 - val_loss: 0.6366 - val_accuracy: 0.8135 - lr: 1.0000e-05\n",
      "Epoch 23/300\n",
      "3997/3997 [==============================] - 137s 34ms/step - loss: 0.2796 - accuracy: 0.9023 - val_loss: 0.6305 - val_accuracy: 0.8145 - lr: 1.0000e-05\n",
      "Epoch 24/300\n",
      "3997/3997 [==============================] - 137s 34ms/step - loss: 0.2764 - accuracy: 0.9051 - val_loss: 0.6379 - val_accuracy: 0.8145 - lr: 1.0000e-05\n",
      "Epoch 25/300\n",
      "3997/3997 [==============================] - 136s 34ms/step - loss: 0.2760 - accuracy: 0.9053 - val_loss: 0.6386 - val_accuracy: 0.8130 - lr: 1.0000e-05\n",
      "Epoch 26/300\n",
      "3997/3997 [==============================] - 136s 34ms/step - loss: 0.2809 - accuracy: 0.9031 - val_loss: 0.6318 - val_accuracy: 0.8147 - lr: 1.0000e-05\n",
      "Epoch 27/300\n",
      "3997/3997 [==============================] - 138s 35ms/step - loss: 0.2758 - accuracy: 0.9060 - val_loss: 0.6319 - val_accuracy: 0.8157 - lr: 1.0000e-05\n",
      "Epoch 28/300\n",
      "3997/3997 [==============================] - 137s 34ms/step - loss: 0.2763 - accuracy: 0.9049 - val_loss: 0.6343 - val_accuracy: 0.8142 - lr: 1.0000e-05\n",
      "Epoch 29/300\n",
      "3997/3997 [==============================] - 136s 34ms/step - loss: 0.2755 - accuracy: 0.9048 - val_loss: 0.6356 - val_accuracy: 0.8151 - lr: 1.0000e-05\n",
      "Epoch 30/300\n",
      "3997/3997 [==============================] - 137s 34ms/step - loss: 0.2764 - accuracy: 0.9053 - val_loss: 0.6354 - val_accuracy: 0.8166 - lr: 1.0000e-05\n",
      "Epoch 31/300\n",
      "3997/3997 [==============================] - 137s 34ms/step - loss: 0.2725 - accuracy: 0.9074 - val_loss: 0.6524 - val_accuracy: 0.8124 - lr: 1.0000e-05\n",
      "Epoch 32/300\n",
      "3997/3997 [==============================] - 137s 34ms/step - loss: 0.2783 - accuracy: 0.9050 - val_loss: 0.6454 - val_accuracy: 0.8120 - lr: 1.0000e-05\n",
      "Epoch 33/300\n",
      "3997/3997 [==============================] - 137s 34ms/step - loss: 0.2723 - accuracy: 0.9060 - val_loss: 0.6343 - val_accuracy: 0.8162 - lr: 1.0000e-05\n",
      "Epoch 34/300\n",
      "3997/3997 [==============================] - 137s 34ms/step - loss: 0.2800 - accuracy: 0.9038 - val_loss: 0.6387 - val_accuracy: 0.8137 - lr: 1.0000e-05\n",
      "Epoch 35/300\n",
      "3997/3997 [==============================] - 136s 34ms/step - loss: 0.2746 - accuracy: 0.9057 - val_loss: 0.6300 - val_accuracy: 0.8171 - lr: 1.0000e-05\n",
      "Epoch 36/300\n",
      "3997/3997 [==============================] - 135s 34ms/step - loss: 0.2734 - accuracy: 0.9067 - val_loss: 0.6442 - val_accuracy: 0.8128 - lr: 1.0000e-05\n",
      "Epoch 37/300\n",
      "3997/3997 [==============================] - 137s 34ms/step - loss: 0.2721 - accuracy: 0.9069 - val_loss: 0.6342 - val_accuracy: 0.8156 - lr: 1.0000e-05\n",
      "Epoch 38/300\n",
      "3997/3997 [==============================] - 137s 34ms/step - loss: 0.2715 - accuracy: 0.9059 - val_loss: 0.6487 - val_accuracy: 0.8114 - lr: 1.0000e-05\n",
      "Epoch 39/300\n",
      "3997/3997 [==============================] - 134s 34ms/step - loss: 0.2722 - accuracy: 0.9064 - val_loss: 0.6440 - val_accuracy: 0.8137 - lr: 1.0000e-05\n",
      "Epoch 40/300\n",
      "3997/3997 [==============================] - 146s 36ms/step - loss: 0.2717 - accuracy: 0.9071 - val_loss: 0.6422 - val_accuracy: 0.8132 - lr: 1.0000e-05\n",
      "Epoch 41/300\n",
      "3997/3997 [==============================] - 146s 37ms/step - loss: 0.2761 - accuracy: 0.9051 - val_loss: 0.6388 - val_accuracy: 0.8122 - lr: 1.0000e-05\n",
      "Epoch 42/300\n",
      "3997/3997 [==============================] - 147s 37ms/step - loss: 0.2723 - accuracy: 0.9065 - val_loss: 0.6432 - val_accuracy: 0.8123 - lr: 1.0000e-05\n",
      "Epoch 43/300\n",
      "3997/3997 [==============================] - 146s 36ms/step - loss: 0.2729 - accuracy: 0.9056 - val_loss: 0.6333 - val_accuracy: 0.8161 - lr: 1.0000e-05\n",
      "Epoch 44/300\n",
      "3997/3997 [==============================] - 147s 37ms/step - loss: 0.2724 - accuracy: 0.9061 - val_loss: 0.6352 - val_accuracy: 0.8153 - lr: 1.0000e-05\n",
      "Epoch 45/300\n",
      "3997/3997 [==============================] - 135s 34ms/step - loss: 0.2715 - accuracy: 0.9066 - val_loss: 0.6325 - val_accuracy: 0.8145 - lr: 1.0000e-05\n",
      "Epoch 46/300\n",
      "3997/3997 [==============================] - 147s 37ms/step - loss: 0.2687 - accuracy: 0.9084 - val_loss: 0.6360 - val_accuracy: 0.8137 - lr: 1.0000e-05\n",
      "Epoch 47/300\n",
      "3997/3997 [==============================] - 140s 35ms/step - loss: 0.2698 - accuracy: 0.9075 - val_loss: 0.6401 - val_accuracy: 0.8133 - lr: 1.0000e-05\n",
      "Epoch 48/300\n",
      "3997/3997 [==============================] - 126s 31ms/step - loss: 0.2706 - accuracy: 0.9067 - val_loss: 0.6384 - val_accuracy: 0.8154 - lr: 1.0000e-05\n",
      "Epoch 49/300\n",
      "3997/3997 [==============================] - 144s 36ms/step - loss: 0.2727 - accuracy: 0.9055 - val_loss: 0.6446 - val_accuracy: 0.8126 - lr: 1.0000e-05\n",
      "Epoch 50/300\n",
      "3997/3997 [==============================] - 145s 36ms/step - loss: 0.2711 - accuracy: 0.9076 - val_loss: 0.6417 - val_accuracy: 0.8129 - lr: 1.0000e-05\n",
      "Epoch 51/300\n",
      "3997/3997 [==============================] - 143s 36ms/step - loss: 0.2730 - accuracy: 0.9068 - val_loss: 0.6311 - val_accuracy: 0.8162 - lr: 1.0000e-05\n",
      "Epoch 52/300\n",
      "3997/3997 [==============================] - 140s 35ms/step - loss: 0.2718 - accuracy: 0.9077 - val_loss: 0.6364 - val_accuracy: 0.8147 - lr: 1.0000e-05\n",
      "Epoch 53/300\n",
      "3997/3997 [==============================] - 144s 36ms/step - loss: 0.2698 - accuracy: 0.9070 - val_loss: 0.6368 - val_accuracy: 0.8131 - lr: 1.0000e-05\n",
      "Epoch 54/300\n",
      "3997/3997 [==============================] - 141s 35ms/step - loss: 0.2658 - accuracy: 0.9097 - val_loss: 0.6447 - val_accuracy: 0.8147 - lr: 1.0000e-05\n",
      "Epoch 55/300\n",
      "3997/3997 [==============================] - 138s 35ms/step - loss: 0.2728 - accuracy: 0.9078 - val_loss: 0.6326 - val_accuracy: 0.8166 - lr: 1.0000e-05\n",
      "Epoch 56/300\n",
      "3997/3997 [==============================] - 144s 36ms/step - loss: 0.2684 - accuracy: 0.9084 - val_loss: 0.6327 - val_accuracy: 0.8157 - lr: 1.0000e-05\n",
      "Epoch 57/300\n",
      "3997/3997 [==============================] - 148s 37ms/step - loss: 0.2675 - accuracy: 0.9088 - val_loss: 0.6367 - val_accuracy: 0.8142 - lr: 1.0000e-05\n",
      "Epoch 58/300\n",
      "3997/3997 [==============================] - 147s 37ms/step - loss: 0.2698 - accuracy: 0.9078 - val_loss: 0.6612 - val_accuracy: 0.8102 - lr: 1.0000e-05\n",
      "Epoch 59/300\n",
      "3997/3997 [==============================] - 142s 36ms/step - loss: 0.2660 - accuracy: 0.9096 - val_loss: 0.6369 - val_accuracy: 0.8156 - lr: 1.0000e-05\n",
      "Epoch 60/300\n",
      "3997/3997 [==============================] - 140s 35ms/step - loss: 0.2686 - accuracy: 0.9087 - val_loss: 0.6432 - val_accuracy: 0.8141 - lr: 1.0000e-05\n",
      "Epoch 61/300\n",
      "3997/3997 [==============================] - 141s 35ms/step - loss: 0.2694 - accuracy: 0.9082 - val_loss: 0.6387 - val_accuracy: 0.8148 - lr: 1.0000e-05\n",
      "Epoch 62/300\n",
      "3997/3997 [==============================] - 140s 35ms/step - loss: 0.2660 - accuracy: 0.9085 - val_loss: 0.6445 - val_accuracy: 0.8134 - lr: 1.0000e-05\n",
      "Epoch 63/300\n",
      "3997/3997 [==============================] - 140s 35ms/step - loss: 0.2640 - accuracy: 0.9086 - val_loss: 0.6386 - val_accuracy: 0.8144 - lr: 1.0000e-05\n",
      "Epoch 64/300\n",
      "3997/3997 [==============================] - 140s 35ms/step - loss: 0.2697 - accuracy: 0.9070 - val_loss: 0.6363 - val_accuracy: 0.8142 - lr: 1.0000e-05\n",
      "Epoch 65/300\n",
      "3997/3997 [==============================] - 140s 35ms/step - loss: 0.2695 - accuracy: 0.9074 - val_loss: 0.6357 - val_accuracy: 0.8149 - lr: 1.0000e-05\n",
      "Epoch 66/300\n",
      "3997/3997 [==============================] - 146s 36ms/step - loss: 0.2678 - accuracy: 0.9077 - val_loss: 0.6355 - val_accuracy: 0.8150 - lr: 1.0000e-05\n",
      "Epoch 67/300\n",
      "3997/3997 [==============================] - 148s 37ms/step - loss: 0.2673 - accuracy: 0.9095 - val_loss: 0.6417 - val_accuracy: 0.8132 - lr: 1.0000e-05\n",
      "Epoch 68/300\n",
      "3997/3997 [==============================] - 147s 37ms/step - loss: 0.2684 - accuracy: 0.9081 - val_loss: 0.6449 - val_accuracy: 0.8136 - lr: 1.0000e-05\n",
      "Epoch 69/300\n",
      "3997/3997 [==============================] - 148s 37ms/step - loss: 0.2630 - accuracy: 0.9110 - val_loss: 0.6412 - val_accuracy: 0.8137 - lr: 1.0000e-05\n",
      "Epoch 70/300\n",
      "3997/3997 [==============================] - 148s 37ms/step - loss: 0.2672 - accuracy: 0.9089 - val_loss: 0.6364 - val_accuracy: 0.8142 - lr: 1.0000e-05\n",
      "Epoch 71/300\n",
      "3997/3997 [==============================] - 147s 37ms/step - loss: 0.2639 - accuracy: 0.9082 - val_loss: 0.6357 - val_accuracy: 0.8145 - lr: 1.0000e-05\n",
      "Epoch 72/300\n",
      "3997/3997 [==============================] - 144s 36ms/step - loss: 0.2653 - accuracy: 0.9091 - val_loss: 0.6431 - val_accuracy: 0.8127 - lr: 1.0000e-05\n",
      "Epoch 73/300\n",
      "3997/3997 [==============================] - 144s 36ms/step - loss: 0.2648 - accuracy: 0.9089 - val_loss: 0.6414 - val_accuracy: 0.8134 - lr: 1.0000e-05\n",
      "Epoch 74/300\n",
      "3997/3997 [==============================] - 142s 35ms/step - loss: 0.2700 - accuracy: 0.9076 - val_loss: 0.6350 - val_accuracy: 0.8155 - lr: 1.0000e-05\n",
      "Epoch 75/300\n",
      "3997/3997 [==============================] - 145s 36ms/step - loss: 0.2582 - accuracy: 0.9121 - val_loss: 0.6422 - val_accuracy: 0.8140 - lr: 1.0000e-05\n",
      "Epoch 76/300\n",
      "3997/3997 [==============================] - 144s 36ms/step - loss: 0.2647 - accuracy: 0.9077 - val_loss: 0.6430 - val_accuracy: 0.8129 - lr: 1.0000e-05\n",
      "Epoch 77/300\n",
      "3997/3997 [==============================] - 145s 36ms/step - loss: 0.2690 - accuracy: 0.9089 - val_loss: 0.6465 - val_accuracy: 0.8136 - lr: 1.0000e-05\n",
      "Epoch 78/300\n",
      "3997/3997 [==============================] - 142s 36ms/step - loss: 0.2649 - accuracy: 0.9089 - val_loss: 0.6411 - val_accuracy: 0.8138 - lr: 1.0000e-05\n",
      "Epoch 79/300\n",
      "3997/3997 [==============================] - 143s 36ms/step - loss: 0.2620 - accuracy: 0.9098 - val_loss: 0.6500 - val_accuracy: 0.8122 - lr: 1.0000e-05\n",
      "Epoch 80/300\n",
      "3997/3997 [==============================] - 141s 35ms/step - loss: 0.2619 - accuracy: 0.9105 - val_loss: 0.6320 - val_accuracy: 0.8162 - lr: 1.0000e-05\n",
      "Epoch 81/300\n",
      "3997/3997 [==============================] - 141s 35ms/step - loss: 0.2604 - accuracy: 0.9112 - val_loss: 0.6452 - val_accuracy: 0.8142 - lr: 1.0000e-05\n",
      "Epoch 82/300\n",
      "3997/3997 [==============================] - 143s 36ms/step - loss: 0.2634 - accuracy: 0.9100 - val_loss: 0.6367 - val_accuracy: 0.8166 - lr: 1.0000e-05\n",
      "Epoch 83/300\n",
      "3997/3997 [==============================] - 141s 35ms/step - loss: 0.2593 - accuracy: 0.9119 - val_loss: 0.6363 - val_accuracy: 0.8140 - lr: 1.0000e-05\n",
      "Epoch 84/300\n",
      "3997/3997 [==============================] - 143s 36ms/step - loss: 0.2650 - accuracy: 0.9083 - val_loss: 0.6366 - val_accuracy: 0.8147 - lr: 1.0000e-05\n",
      "Epoch 85/300\n",
      "3997/3997 [==============================] - 140s 35ms/step - loss: 0.2587 - accuracy: 0.9104 - val_loss: 0.6386 - val_accuracy: 0.8152 - lr: 1.0000e-05\n",
      "Epoch 86/300\n",
      "3997/3997 [==============================] - 145s 36ms/step - loss: 0.2638 - accuracy: 0.9109 - val_loss: 0.6336 - val_accuracy: 0.8180 - lr: 1.0000e-05\n",
      "Epoch 87/300\n",
      "3997/3997 [==============================] - 147s 37ms/step - loss: 0.2631 - accuracy: 0.9088 - val_loss: 0.6335 - val_accuracy: 0.8152 - lr: 1.0000e-05\n",
      "Epoch 88/300\n",
      "3997/3997 [==============================] - 140s 35ms/step - loss: 0.2628 - accuracy: 0.9098 - val_loss: 0.6503 - val_accuracy: 0.8122 - lr: 1.0000e-05\n",
      "Epoch 89/300\n",
      "3997/3997 [==============================] - 136s 34ms/step - loss: 0.2627 - accuracy: 0.9094 - val_loss: 0.6376 - val_accuracy: 0.8162 - lr: 1.0000e-05\n",
      "Epoch 90/300\n",
      "3997/3997 [==============================] - 142s 36ms/step - loss: 0.2611 - accuracy: 0.9112 - val_loss: 0.6423 - val_accuracy: 0.8154 - lr: 1.0000e-05\n",
      "Epoch 91/300\n",
      "2419/3997 [=================>............] - ETA: 49s - loss: 0.2676 - accuracy: 0.9075"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m history_1 \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_1_best\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_gen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_gen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m300\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mreduce_lr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_checkpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcsv_logger\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorgpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorgpu\\lib\\site-packages\\keras\\engine\\training.py:1570\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1568\u001b[0m logs \u001b[38;5;241m=\u001b[39m tmp_logs\n\u001b[0;32m   1569\u001b[0m end_step \u001b[38;5;241m=\u001b[39m step \u001b[38;5;241m+\u001b[39m data_handler\u001b[38;5;241m.\u001b[39mstep_increment\n\u001b[1;32m-> 1570\u001b[0m \u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_train_batch_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mend_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n\u001b[0;32m   1572\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorgpu\\lib\\site-packages\\keras\\callbacks.py:470\u001b[0m, in \u001b[0;36mCallbackList.on_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    463\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Calls the `on_train_batch_end` methods of its callbacks.\u001b[39;00m\n\u001b[0;32m    464\u001b[0m \n\u001b[0;32m    465\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m    466\u001b[0m \u001b[38;5;124;03m    batch: Integer, index of batch within the current epoch.\u001b[39;00m\n\u001b[0;32m    467\u001b[0m \u001b[38;5;124;03m    logs: Dict. Aggregated metric results up until this batch.\u001b[39;00m\n\u001b[0;32m    468\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    469\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_call_train_batch_hooks:\n\u001b[1;32m--> 470\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mModeKeys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTRAIN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mend\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorgpu\\lib\\site-packages\\keras\\callbacks.py:317\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook\u001b[1;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[0;32m    315\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_batch_begin_hook(mode, batch, logs)\n\u001b[0;32m    316\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m hook \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 317\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_end_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    319\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized hook: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExpected values are [\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbegin\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    322\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorgpu\\lib\\site-packages\\keras\\callbacks.py:340\u001b[0m, in \u001b[0;36mCallbackList._call_batch_end_hook\u001b[1;34m(self, mode, batch, logs)\u001b[0m\n\u001b[0;32m    337\u001b[0m     batch_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_start_time\n\u001b[0;32m    338\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_times\u001b[38;5;241m.\u001b[39mappend(batch_time)\n\u001b[1;32m--> 340\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_hook_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhook_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    342\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_times) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_batches_for_timing_check:\n\u001b[0;32m    343\u001b[0m     end_hook_name \u001b[38;5;241m=\u001b[39m hook_name\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorgpu\\lib\\site-packages\\keras\\callbacks.py:388\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook_helper\u001b[1;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[0;32m    386\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks:\n\u001b[0;32m    387\u001b[0m     hook \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(callback, hook_name)\n\u001b[1;32m--> 388\u001b[0m     \u001b[43mhook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    390\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_timing:\n\u001b[0;32m    391\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m hook_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_hook_times:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorgpu\\lib\\site-packages\\keras\\callbacks.py:1081\u001b[0m, in \u001b[0;36mProgbarLogger.on_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1080\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mon_train_batch_end\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch, logs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m-> 1081\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch_update_progbar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorgpu\\lib\\site-packages\\keras\\callbacks.py:1157\u001b[0m, in \u001b[0;36mProgbarLogger._batch_update_progbar\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1153\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseen \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m add_seen\n\u001b[0;32m   1155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1156\u001b[0m     \u001b[38;5;66;03m# Only block async when verbose = 1.\u001b[39;00m\n\u001b[1;32m-> 1157\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[43mtf_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msync_to_numpy_or_python_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1158\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprogbar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseen, \u001b[38;5;28mlist\u001b[39m(logs\u001b[38;5;241m.\u001b[39mitems()), finalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorgpu\\lib\\site-packages\\keras\\utils\\tf_utils.py:635\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type\u001b[1;34m(tensors)\u001b[0m\n\u001b[0;32m    632\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\n\u001b[0;32m    633\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mndim(t) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m t\n\u001b[1;32m--> 635\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_structure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_to_single_numpy_or_python_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorgpu\\lib\\site-packages\\tensorflow\\python\\util\\nest.py:917\u001b[0m, in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    913\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[0;32m    914\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[0;32m    916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pack_sequence_as(\n\u001b[1;32m--> 917\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m], [func(\u001b[38;5;241m*\u001b[39mx) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[0;32m    918\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorgpu\\lib\\site-packages\\tensorflow\\python\\util\\nest.py:917\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    913\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[0;32m    914\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[0;32m    916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pack_sequence_as(\n\u001b[1;32m--> 917\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m], [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[0;32m    918\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorgpu\\lib\\site-packages\\keras\\utils\\tf_utils.py:628\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type.<locals>._to_single_numpy_or_python_type\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    625\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_to_single_numpy_or_python_type\u001b[39m(t):\n\u001b[0;32m    626\u001b[0m     \u001b[38;5;66;03m# Don't turn ragged or sparse tensors to NumPy.\u001b[39;00m\n\u001b[0;32m    627\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, tf\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[1;32m--> 628\u001b[0m         t \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;66;03m# Strings, ragged and sparse tensors don't have .item(). Return them\u001b[39;00m\n\u001b[0;32m    630\u001b[0m     \u001b[38;5;66;03m# as-is.\u001b[39;00m\n\u001b[0;32m    631\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, (np\u001b[38;5;241m.\u001b[39mndarray, np\u001b[38;5;241m.\u001b[39mgeneric)):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorgpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1157\u001b[0m, in \u001b[0;36m_EagerTensorBase.numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1134\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Copy of the contents of this Tensor into a NumPy array or scalar.\u001b[39;00m\n\u001b[0;32m   1135\u001b[0m \n\u001b[0;32m   1136\u001b[0m \u001b[38;5;124;03mUnlike NumPy arrays, Tensors are immutable, so this method has to copy\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1154\u001b[0m \u001b[38;5;124;03m    NumPy dtype.\u001b[39;00m\n\u001b[0;32m   1155\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1156\u001b[0m \u001b[38;5;66;03m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[39;00m\n\u001b[1;32m-> 1157\u001b[0m maybe_arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1158\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m maybe_arr\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(maybe_arr, np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;28;01melse\u001b[39;00m maybe_arr\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorgpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1123\u001b[0m, in \u001b[0;36m_EagerTensorBase._numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1121\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_numpy\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m   1122\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1124\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1125\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history_1 = model_1_best.fit(train_gen, validation_data=validation_gen, epochs = 300, callbacks = [reduce_lr, model_checkpoint, csv_logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2409f1cf-5914-469e-b07f-40dfc88ecb2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 6s 22ms/step - loss: 0.6820 - accuracy: 0.8157\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6819954514503479, 0.8157039284706116]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1_best = load_model('checkpoints\\mdl_wts.h5')\n",
    "model_1_best.evaluate(test_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9c0153c1-1457-419e-a04a-cb0aaba6f1f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "3997/3997 [==============================] - 136s 34ms/step - loss: 0.2623 - accuracy: 0.9117 - val_loss: 0.6428 - val_accuracy: 0.8159 - lr: 1.0000e-05\n",
      "Epoch 2/300\n",
      "3997/3997 [==============================] - 147s 37ms/step - loss: 0.2588 - accuracy: 0.9113 - val_loss: 0.6334 - val_accuracy: 0.8157 - lr: 1.0000e-05\n",
      "Epoch 3/300\n",
      "3997/3997 [==============================] - 135s 34ms/step - loss: 0.2616 - accuracy: 0.9104 - val_loss: 0.6374 - val_accuracy: 0.8140 - lr: 1.0000e-05\n",
      "Epoch 4/300\n",
      "3997/3997 [==============================] - 136s 34ms/step - loss: 0.2591 - accuracy: 0.9112 - val_loss: 0.6484 - val_accuracy: 0.8132 - lr: 1.0000e-05\n",
      "Epoch 5/300\n",
      "3997/3997 [==============================] - 135s 34ms/step - loss: 0.2586 - accuracy: 0.9115 - val_loss: 0.6399 - val_accuracy: 0.8165 - lr: 1.0000e-05\n",
      "Epoch 6/300\n",
      "3997/3997 [==============================] - 137s 34ms/step - loss: 0.2648 - accuracy: 0.9099 - val_loss: 0.6404 - val_accuracy: 0.8138 - lr: 1.0000e-05\n",
      "Epoch 7/300\n",
      "3997/3997 [==============================] - 147s 37ms/step - loss: 0.2612 - accuracy: 0.9112 - val_loss: 0.6347 - val_accuracy: 0.8144 - lr: 1.0000e-05\n",
      "Epoch 8/300\n",
      "3997/3997 [==============================] - 146s 37ms/step - loss: 0.2624 - accuracy: 0.9107 - val_loss: 0.6508 - val_accuracy: 0.8143 - lr: 1.0000e-05\n",
      "Epoch 9/300\n",
      "3997/3997 [==============================] - 142s 36ms/step - loss: 0.2552 - accuracy: 0.9122 - val_loss: 0.6332 - val_accuracy: 0.8152 - lr: 1.0000e-05\n",
      "Epoch 10/300\n",
      "3997/3997 [==============================] - 145s 36ms/step - loss: 0.2576 - accuracy: 0.9116 - val_loss: 0.6435 - val_accuracy: 0.8137 - lr: 1.0000e-05\n",
      "Epoch 11/300\n",
      "3997/3997 [==============================] - 146s 36ms/step - loss: 0.2591 - accuracy: 0.9114 - val_loss: 0.6392 - val_accuracy: 0.8151 - lr: 1.0000e-05\n",
      "Epoch 12/300\n",
      "3997/3997 [==============================] - 138s 35ms/step - loss: 0.2630 - accuracy: 0.9113 - val_loss: 0.6320 - val_accuracy: 0.8167 - lr: 1.0000e-05\n",
      "Epoch 13/300\n",
      "3997/3997 [==============================] - 135s 34ms/step - loss: 0.2620 - accuracy: 0.9104 - val_loss: 0.6371 - val_accuracy: 0.8153 - lr: 1.0000e-05\n",
      "Epoch 14/300\n",
      "3997/3997 [==============================] - 136s 34ms/step - loss: 0.2619 - accuracy: 0.9113 - val_loss: 0.6397 - val_accuracy: 0.8171 - lr: 1.0000e-05\n",
      "Epoch 15/300\n",
      "3997/3997 [==============================] - 136s 34ms/step - loss: 0.2590 - accuracy: 0.9119 - val_loss: 0.6365 - val_accuracy: 0.8159 - lr: 1.0000e-05\n",
      "Epoch 16/300\n",
      "3997/3997 [==============================] - 135s 34ms/step - loss: 0.2570 - accuracy: 0.9121 - val_loss: 0.6469 - val_accuracy: 0.8137 - lr: 1.0000e-05\n",
      "Epoch 17/300\n",
      "3997/3997 [==============================] - 135s 34ms/step - loss: 0.2638 - accuracy: 0.9099 - val_loss: 0.6409 - val_accuracy: 0.8147 - lr: 1.0000e-05\n",
      "Epoch 18/300\n",
      "3997/3997 [==============================] - 136s 34ms/step - loss: 0.2551 - accuracy: 0.9123 - val_loss: 0.6316 - val_accuracy: 0.8161 - lr: 1.0000e-05\n",
      "Epoch 19/300\n",
      "3997/3997 [==============================] - 136s 34ms/step - loss: 0.2586 - accuracy: 0.9110 - val_loss: 0.6358 - val_accuracy: 0.8151 - lr: 1.0000e-05\n",
      "Epoch 20/300\n",
      "3997/3997 [==============================] - 136s 34ms/step - loss: 0.2561 - accuracy: 0.9120 - val_loss: 0.6312 - val_accuracy: 0.8162 - lr: 1.0000e-05\n",
      "Epoch 21/300\n",
      "3997/3997 [==============================] - 137s 34ms/step - loss: 0.2560 - accuracy: 0.9132 - val_loss: 0.6320 - val_accuracy: 0.8183 - lr: 1.0000e-05\n",
      "Epoch 22/300\n",
      "3997/3997 [==============================] - 136s 34ms/step - loss: 0.2572 - accuracy: 0.9113 - val_loss: 0.6405 - val_accuracy: 0.8154 - lr: 1.0000e-05\n",
      "Epoch 23/300\n",
      "3997/3997 [==============================] - 136s 34ms/step - loss: 0.2562 - accuracy: 0.9113 - val_loss: 0.6316 - val_accuracy: 0.8177 - lr: 1.0000e-05\n",
      "Epoch 24/300\n",
      "3997/3997 [==============================] - 136s 34ms/step - loss: 0.2587 - accuracy: 0.9111 - val_loss: 0.6433 - val_accuracy: 0.8152 - lr: 1.0000e-05\n",
      "Epoch 25/300\n",
      "3997/3997 [==============================] - 136s 34ms/step - loss: 0.2521 - accuracy: 0.9134 - val_loss: 0.6428 - val_accuracy: 0.8143 - lr: 1.0000e-05\n",
      "Epoch 26/300\n",
      "3997/3997 [==============================] - 136s 34ms/step - loss: 0.2561 - accuracy: 0.9121 - val_loss: 0.6341 - val_accuracy: 0.8172 - lr: 1.0000e-05\n",
      "Epoch 27/300\n",
      "3997/3997 [==============================] - 136s 34ms/step - loss: 0.2538 - accuracy: 0.9135 - val_loss: 0.6286 - val_accuracy: 0.8180 - lr: 1.0000e-05\n",
      "Epoch 28/300\n",
      "3997/3997 [==============================] - 138s 34ms/step - loss: 0.2505 - accuracy: 0.9151 - val_loss: 0.6242 - val_accuracy: 0.8206 - lr: 1.0000e-05\n",
      "Epoch 29/300\n",
      "3997/3997 [==============================] - 136s 34ms/step - loss: 0.2574 - accuracy: 0.9120 - val_loss: 0.6385 - val_accuracy: 0.8177 - lr: 1.0000e-05\n",
      "Epoch 30/300\n",
      "3997/3997 [==============================] - 137s 34ms/step - loss: 0.2585 - accuracy: 0.9114 - val_loss: 0.6308 - val_accuracy: 0.8182 - lr: 1.0000e-05\n",
      "Epoch 31/300\n",
      "3997/3997 [==============================] - 137s 34ms/step - loss: 0.2502 - accuracy: 0.9146 - val_loss: 0.6368 - val_accuracy: 0.8172 - lr: 1.0000e-05\n",
      "Epoch 32/300\n",
      "3997/3997 [==============================] - 137s 34ms/step - loss: 0.2508 - accuracy: 0.9143 - val_loss: 0.6377 - val_accuracy: 0.8166 - lr: 1.0000e-05\n",
      "Epoch 33/300\n",
      "3997/3997 [==============================] - 137s 34ms/step - loss: 0.2507 - accuracy: 0.9145 - val_loss: 0.6330 - val_accuracy: 0.8170 - lr: 1.0000e-05\n",
      "Epoch 34/300\n",
      "3997/3997 [==============================] - 138s 34ms/step - loss: 0.2549 - accuracy: 0.9136 - val_loss: 0.6404 - val_accuracy: 0.8173 - lr: 1.0000e-05\n",
      "Epoch 35/300\n",
      "3997/3997 [==============================] - 136s 34ms/step - loss: 0.2505 - accuracy: 0.9137 - val_loss: 0.6453 - val_accuracy: 0.8154 - lr: 1.0000e-05\n",
      "Epoch 36/300\n",
      "3997/3997 [==============================] - 136s 34ms/step - loss: 0.2504 - accuracy: 0.9139 - val_loss: 0.6357 - val_accuracy: 0.8179 - lr: 1.0000e-05\n",
      "Epoch 37/300\n",
      "3997/3997 [==============================] - 136s 34ms/step - loss: 0.2503 - accuracy: 0.9136 - val_loss: 0.6355 - val_accuracy: 0.8171 - lr: 1.0000e-05\n",
      "Epoch 38/300\n",
      "3997/3997 [==============================] - 137s 34ms/step - loss: 0.2498 - accuracy: 0.9139 - val_loss: 0.6450 - val_accuracy: 0.8157 - lr: 1.0000e-05\n",
      "Epoch 39/300\n",
      "3997/3997 [==============================] - 137s 34ms/step - loss: 0.2519 - accuracy: 0.9122 - val_loss: 0.6462 - val_accuracy: 0.8160 - lr: 1.0000e-05\n",
      "Epoch 40/300\n",
      "3997/3997 [==============================] - 137s 34ms/step - loss: 0.2499 - accuracy: 0.9139 - val_loss: 0.6373 - val_accuracy: 0.8167 - lr: 1.0000e-05\n",
      "Epoch 41/300\n",
      "3997/3997 [==============================] - 136s 34ms/step - loss: 0.2532 - accuracy: 0.9127 - val_loss: 0.6376 - val_accuracy: 0.8178 - lr: 1.0000e-05\n",
      "Epoch 42/300\n",
      "3997/3997 [==============================] - 138s 34ms/step - loss: 0.2511 - accuracy: 0.9136 - val_loss: 0.6329 - val_accuracy: 0.8168 - lr: 1.0000e-05\n",
      "Epoch 43/300\n",
      "3997/3997 [==============================] - 136s 34ms/step - loss: 0.2484 - accuracy: 0.9145 - val_loss: 0.6464 - val_accuracy: 0.8157 - lr: 1.0000e-05\n",
      "Epoch 44/300\n",
      "3997/3997 [==============================] - 137s 34ms/step - loss: 0.2516 - accuracy: 0.9145 - val_loss: 0.6416 - val_accuracy: 0.8151 - lr: 1.0000e-05\n",
      "Epoch 45/300\n",
      "3997/3997 [==============================] - 137s 34ms/step - loss: 0.2478 - accuracy: 0.9145 - val_loss: 0.6364 - val_accuracy: 0.8183 - lr: 1.0000e-05\n",
      "Epoch 46/300\n",
      "3997/3997 [==============================] - 138s 34ms/step - loss: 0.2493 - accuracy: 0.9145 - val_loss: 0.6454 - val_accuracy: 0.8160 - lr: 1.0000e-05\n",
      "Epoch 47/300\n",
      "3997/3997 [==============================] - 138s 34ms/step - loss: 0.2467 - accuracy: 0.9150 - val_loss: 0.6363 - val_accuracy: 0.8172 - lr: 1.0000e-05\n",
      "Epoch 48/300\n",
      "3997/3997 [==============================] - 137s 34ms/step - loss: 0.2545 - accuracy: 0.9126 - val_loss: 0.6386 - val_accuracy: 0.8178 - lr: 1.0000e-05\n",
      "Epoch 49/300\n",
      "3997/3997 [==============================] - 137s 34ms/step - loss: 0.2476 - accuracy: 0.9151 - val_loss: 0.6365 - val_accuracy: 0.8167 - lr: 1.0000e-05\n",
      "Epoch 50/300\n",
      "3997/3997 [==============================] - 139s 35ms/step - loss: 0.2510 - accuracy: 0.9137 - val_loss: 0.6379 - val_accuracy: 0.8161 - lr: 1.0000e-05\n",
      "Epoch 51/300\n",
      "3997/3997 [==============================] - 139s 35ms/step - loss: 0.2556 - accuracy: 0.9128 - val_loss: 0.6384 - val_accuracy: 0.8181 - lr: 1.0000e-05\n",
      "Epoch 52/300\n",
      "3997/3997 [==============================] - 138s 34ms/step - loss: 0.2484 - accuracy: 0.9147 - val_loss: 0.6389 - val_accuracy: 0.8188 - lr: 1.0000e-05\n",
      "Epoch 53/300\n",
      "3997/3997 [==============================] - 137s 34ms/step - loss: 0.2483 - accuracy: 0.9154 - val_loss: 0.6375 - val_accuracy: 0.8177 - lr: 1.0000e-05\n",
      "Epoch 54/300\n",
      "3997/3997 [==============================] - 138s 35ms/step - loss: 0.2487 - accuracy: 0.9149 - val_loss: 0.6353 - val_accuracy: 0.8169 - lr: 1.0000e-05\n",
      "Epoch 55/300\n",
      "3997/3997 [==============================] - 139s 35ms/step - loss: 0.2458 - accuracy: 0.9157 - val_loss: 0.6300 - val_accuracy: 0.8185 - lr: 1.0000e-05\n",
      "Epoch 56/300\n",
      "3997/3997 [==============================] - 139s 35ms/step - loss: 0.2475 - accuracy: 0.9145 - val_loss: 0.6331 - val_accuracy: 0.8179 - lr: 1.0000e-05\n",
      "Epoch 57/300\n",
      "3997/3997 [==============================] - 140s 35ms/step - loss: 0.2482 - accuracy: 0.9156 - val_loss: 0.6352 - val_accuracy: 0.8197 - lr: 1.0000e-05\n",
      "Epoch 58/300\n",
      "3997/3997 [==============================] - 140s 35ms/step - loss: 0.2458 - accuracy: 0.9169 - val_loss: 0.6394 - val_accuracy: 0.8183 - lr: 1.0000e-05\n",
      "Epoch 59/300\n",
      "3997/3997 [==============================] - 140s 35ms/step - loss: 0.2460 - accuracy: 0.9160 - val_loss: 0.6356 - val_accuracy: 0.8188 - lr: 1.0000e-05\n",
      "Epoch 60/300\n",
      "3997/3997 [==============================] - 141s 35ms/step - loss: 0.2539 - accuracy: 0.9135 - val_loss: 0.6374 - val_accuracy: 0.8191 - lr: 1.0000e-05\n",
      "Epoch 61/300\n",
      "3997/3997 [==============================] - 139s 35ms/step - loss: 0.2465 - accuracy: 0.9156 - val_loss: 0.6398 - val_accuracy: 0.8188 - lr: 1.0000e-05\n",
      "Epoch 62/300\n",
      "3997/3997 [==============================] - 139s 35ms/step - loss: 0.2463 - accuracy: 0.9162 - val_loss: 0.6344 - val_accuracy: 0.8193 - lr: 1.0000e-05\n",
      "Epoch 63/300\n",
      "3997/3997 [==============================] - 141s 35ms/step - loss: 0.2484 - accuracy: 0.9143 - val_loss: 0.6222 - val_accuracy: 0.8218 - lr: 1.0000e-05\n",
      "Epoch 64/300\n",
      "3997/3997 [==============================] - 140s 35ms/step - loss: 0.2489 - accuracy: 0.9142 - val_loss: 0.6305 - val_accuracy: 0.8206 - lr: 1.0000e-05\n",
      "Epoch 65/300\n",
      "3997/3997 [==============================] - 139s 35ms/step - loss: 0.2458 - accuracy: 0.9166 - val_loss: 0.6331 - val_accuracy: 0.8184 - lr: 1.0000e-05\n",
      "Epoch 66/300\n",
      "3997/3997 [==============================] - 139s 35ms/step - loss: 0.2480 - accuracy: 0.9146 - val_loss: 0.6427 - val_accuracy: 0.8168 - lr: 1.0000e-05\n",
      "Epoch 67/300\n",
      "3997/3997 [==============================] - 140s 35ms/step - loss: 0.2489 - accuracy: 0.9160 - val_loss: 0.6264 - val_accuracy: 0.8202 - lr: 1.0000e-05\n",
      "Epoch 68/300\n",
      "3997/3997 [==============================] - 137s 34ms/step - loss: 0.2456 - accuracy: 0.9153 - val_loss: 0.6284 - val_accuracy: 0.8200 - lr: 1.0000e-05\n",
      "Epoch 69/300\n",
      "3997/3997 [==============================] - 138s 34ms/step - loss: 0.2383 - accuracy: 0.9187 - val_loss: 0.6370 - val_accuracy: 0.8185 - lr: 1.0000e-05\n",
      "Epoch 70/300\n",
      "3997/3997 [==============================] - 141s 35ms/step - loss: 0.2470 - accuracy: 0.9143 - val_loss: 0.6299 - val_accuracy: 0.8192 - lr: 1.0000e-05\n",
      "Epoch 71/300\n",
      "3997/3997 [==============================] - 139s 35ms/step - loss: 0.2441 - accuracy: 0.9171 - val_loss: 0.6378 - val_accuracy: 0.8178 - lr: 1.0000e-05\n",
      "Epoch 72/300\n",
      "3997/3997 [==============================] - 140s 35ms/step - loss: 0.2464 - accuracy: 0.9160 - val_loss: 0.6405 - val_accuracy: 0.8181 - lr: 1.0000e-05\n",
      "Epoch 73/300\n",
      "3997/3997 [==============================] - 139s 35ms/step - loss: 0.2432 - accuracy: 0.9159 - val_loss: 0.6319 - val_accuracy: 0.8206 - lr: 1.0000e-05\n",
      "Epoch 74/300\n",
      "3997/3997 [==============================] - 139s 35ms/step - loss: 0.2416 - accuracy: 0.9169 - val_loss: 0.6328 - val_accuracy: 0.8203 - lr: 1.0000e-05\n",
      "Epoch 75/300\n",
      "3997/3997 [==============================] - 140s 35ms/step - loss: 0.2449 - accuracy: 0.9162 - val_loss: 0.6320 - val_accuracy: 0.8208 - lr: 1.0000e-05\n",
      "Epoch 76/300\n",
      "3997/3997 [==============================] - 138s 35ms/step - loss: 0.2461 - accuracy: 0.9153 - val_loss: 0.6438 - val_accuracy: 0.8175 - lr: 1.0000e-05\n",
      "Epoch 77/300\n",
      "3997/3997 [==============================] - 138s 35ms/step - loss: 0.2455 - accuracy: 0.9160 - val_loss: 0.6286 - val_accuracy: 0.8200 - lr: 1.0000e-05\n",
      "Epoch 78/300\n",
      "3997/3997 [==============================] - 139s 35ms/step - loss: 0.2486 - accuracy: 0.9154 - val_loss: 0.6434 - val_accuracy: 0.8169 - lr: 1.0000e-05\n",
      "Epoch 79/300\n",
      "3997/3997 [==============================] - 139s 35ms/step - loss: 0.2427 - accuracy: 0.9173 - val_loss: 0.6395 - val_accuracy: 0.8175 - lr: 1.0000e-05\n",
      "Epoch 80/300\n",
      "3997/3997 [==============================] - 139s 35ms/step - loss: 0.2385 - accuracy: 0.9176 - val_loss: 0.6409 - val_accuracy: 0.8177 - lr: 1.0000e-05\n",
      "Epoch 81/300\n",
      "3997/3997 [==============================] - 138s 35ms/step - loss: 0.2436 - accuracy: 0.9167 - val_loss: 0.6407 - val_accuracy: 0.8182 - lr: 1.0000e-05\n",
      "Epoch 82/300\n",
      "3997/3997 [==============================] - 138s 35ms/step - loss: 0.2419 - accuracy: 0.9159 - val_loss: 0.6381 - val_accuracy: 0.8190 - lr: 1.0000e-05\n",
      "Epoch 83/300\n",
      "3997/3997 [==============================] - 144s 36ms/step - loss: 0.2387 - accuracy: 0.9189 - val_loss: 0.6350 - val_accuracy: 0.8187 - lr: 1.0000e-05\n",
      "Epoch 84/300\n",
      "3997/3997 [==============================] - 167s 42ms/step - loss: 0.2380 - accuracy: 0.9178 - val_loss: 0.6297 - val_accuracy: 0.8187 - lr: 1.0000e-05\n",
      "Epoch 85/300\n",
      "3997/3997 [==============================] - 140s 35ms/step - loss: 0.2392 - accuracy: 0.9186 - val_loss: 0.6407 - val_accuracy: 0.8183 - lr: 1.0000e-05\n",
      "Epoch 86/300\n",
      "3997/3997 [==============================] - 144s 36ms/step - loss: 0.2442 - accuracy: 0.9164 - val_loss: 0.6310 - val_accuracy: 0.8208 - lr: 1.0000e-05\n",
      "Epoch 87/300\n",
      "3997/3997 [==============================] - 140s 35ms/step - loss: 0.2446 - accuracy: 0.9165 - val_loss: 0.6321 - val_accuracy: 0.8198 - lr: 1.0000e-05\n",
      "Epoch 88/300\n",
      "3997/3997 [==============================] - 139s 35ms/step - loss: 0.2442 - accuracy: 0.9149 - val_loss: 0.6360 - val_accuracy: 0.8203 - lr: 1.0000e-05\n",
      "Epoch 89/300\n",
      "3997/3997 [==============================] - 139s 35ms/step - loss: 0.2452 - accuracy: 0.9164 - val_loss: 0.6399 - val_accuracy: 0.8188 - lr: 1.0000e-05\n",
      "Epoch 90/300\n",
      "3997/3997 [==============================] - 139s 35ms/step - loss: 0.2418 - accuracy: 0.9183 - val_loss: 0.6323 - val_accuracy: 0.8191 - lr: 1.0000e-05\n",
      "Epoch 91/300\n",
      "3997/3997 [==============================] - 139s 35ms/step - loss: 0.2463 - accuracy: 0.9147 - val_loss: 0.6332 - val_accuracy: 0.8175 - lr: 1.0000e-05\n",
      "Epoch 92/300\n",
      "3997/3997 [==============================] - 140s 35ms/step - loss: 0.2416 - accuracy: 0.9162 - val_loss: 0.6300 - val_accuracy: 0.8196 - lr: 1.0000e-05\n",
      "Epoch 93/300\n",
      "3997/3997 [==============================] - 140s 35ms/step - loss: 0.2392 - accuracy: 0.9183 - val_loss: 0.6445 - val_accuracy: 0.8161 - lr: 1.0000e-05\n",
      "Epoch 94/300\n",
      "3997/3997 [==============================] - 139s 35ms/step - loss: 0.2413 - accuracy: 0.9178 - val_loss: 0.6379 - val_accuracy: 0.8195 - lr: 1.0000e-05\n",
      "Epoch 95/300\n",
      "3997/3997 [==============================] - 138s 35ms/step - loss: 0.2384 - accuracy: 0.9184 - val_loss: 0.6333 - val_accuracy: 0.8197 - lr: 1.0000e-05\n",
      "Epoch 96/300\n",
      "3997/3997 [==============================] - 138s 35ms/step - loss: 0.2437 - accuracy: 0.9164 - val_loss: 0.6360 - val_accuracy: 0.8191 - lr: 1.0000e-05\n",
      "Epoch 97/300\n",
      "3997/3997 [==============================] - 141s 35ms/step - loss: 0.2421 - accuracy: 0.9176 - val_loss: 0.6238 - val_accuracy: 0.8214 - lr: 1.0000e-05\n",
      "Epoch 98/300\n",
      "3997/3997 [==============================] - 138s 35ms/step - loss: 0.2455 - accuracy: 0.9167 - val_loss: 0.6317 - val_accuracy: 0.8213 - lr: 1.0000e-05\n",
      "Epoch 99/300\n",
      "3997/3997 [==============================] - 138s 35ms/step - loss: 0.2388 - accuracy: 0.9178 - val_loss: 0.6356 - val_accuracy: 0.8194 - lr: 1.0000e-05\n",
      "Epoch 100/300\n",
      "3997/3997 [==============================] - 139s 35ms/step - loss: 0.2387 - accuracy: 0.9186 - val_loss: 0.6268 - val_accuracy: 0.8206 - lr: 1.0000e-05\n",
      "Epoch 101/300\n",
      "3997/3997 [==============================] - 139s 35ms/step - loss: 0.2445 - accuracy: 0.9169 - val_loss: 0.6344 - val_accuracy: 0.8194 - lr: 1.0000e-05\n",
      "Epoch 102/300\n",
      "3997/3997 [==============================] - 138s 34ms/step - loss: 0.2400 - accuracy: 0.9185 - val_loss: 0.6505 - val_accuracy: 0.8165 - lr: 1.0000e-05\n",
      "Epoch 103/300\n",
      "3997/3997 [==============================] - 139s 35ms/step - loss: 0.2400 - accuracy: 0.9176 - val_loss: 0.6259 - val_accuracy: 0.8203 - lr: 1.0000e-05\n",
      "Epoch 104/300\n",
      "3997/3997 [==============================] - 143s 36ms/step - loss: 0.2360 - accuracy: 0.9190 - val_loss: 0.6415 - val_accuracy: 0.8188 - lr: 1.0000e-05\n",
      "Epoch 105/300\n",
      "3997/3997 [==============================] - 139s 35ms/step - loss: 0.2373 - accuracy: 0.9185 - val_loss: 0.6369 - val_accuracy: 0.8194 - lr: 1.0000e-05\n",
      "Epoch 106/300\n",
      "3997/3997 [==============================] - 138s 35ms/step - loss: 0.2405 - accuracy: 0.9180 - val_loss: 0.6365 - val_accuracy: 0.8186 - lr: 1.0000e-05\n",
      "Epoch 107/300\n",
      "3997/3997 [==============================] - 138s 35ms/step - loss: 0.2386 - accuracy: 0.9183 - val_loss: 0.6383 - val_accuracy: 0.8193 - lr: 1.0000e-05\n",
      "Epoch 108/300\n",
      "3997/3997 [==============================] - 138s 35ms/step - loss: 0.2365 - accuracy: 0.9190 - val_loss: 0.6322 - val_accuracy: 0.8199 - lr: 1.0000e-05\n",
      "Epoch 109/300\n",
      "3997/3997 [==============================] - 138s 35ms/step - loss: 0.2377 - accuracy: 0.9188 - val_loss: 0.6294 - val_accuracy: 0.8218 - lr: 1.0000e-05\n",
      "Epoch 110/300\n",
      "3997/3997 [==============================] - 139s 35ms/step - loss: 0.2387 - accuracy: 0.9174 - val_loss: 0.6274 - val_accuracy: 0.8228 - lr: 1.0000e-05\n",
      "Epoch 111/300\n",
      "3997/3997 [==============================] - 144s 36ms/step - loss: 0.2361 - accuracy: 0.9184 - val_loss: 0.6273 - val_accuracy: 0.8223 - lr: 1.0000e-05\n",
      "Epoch 112/300\n",
      "3997/3997 [==============================] - 142s 36ms/step - loss: 0.2348 - accuracy: 0.9195 - val_loss: 0.6449 - val_accuracy: 0.8180 - lr: 1.0000e-05\n",
      "Epoch 113/300\n",
      "3997/3997 [==============================] - 141s 35ms/step - loss: 0.2354 - accuracy: 0.9193 - val_loss: 0.6395 - val_accuracy: 0.8200 - lr: 1.0000e-05\n",
      "Epoch 114/300\n",
      "3997/3997 [==============================] - 139s 35ms/step - loss: 0.2366 - accuracy: 0.9195 - val_loss: 0.6232 - val_accuracy: 0.8213 - lr: 1.0000e-05\n",
      "Epoch 115/300\n",
      "3997/3997 [==============================] - 138s 35ms/step - loss: 0.2318 - accuracy: 0.9206 - val_loss: 0.6406 - val_accuracy: 0.8180 - lr: 1.0000e-05\n",
      "Epoch 116/300\n",
      "3997/3997 [==============================] - 138s 34ms/step - loss: 0.2347 - accuracy: 0.9199 - val_loss: 0.6339 - val_accuracy: 0.8208 - lr: 1.0000e-05\n",
      "Epoch 117/300\n",
      "3997/3997 [==============================] - 140s 35ms/step - loss: 0.2357 - accuracy: 0.9190 - val_loss: 0.6320 - val_accuracy: 0.8212 - lr: 1.0000e-05\n",
      "Epoch 118/300\n",
      "3997/3997 [==============================] - 143s 36ms/step - loss: 0.2397 - accuracy: 0.9182 - val_loss: 0.6253 - val_accuracy: 0.8214 - lr: 1.0000e-05\n",
      "Epoch 119/300\n",
      "3997/3997 [==============================] - 145s 36ms/step - loss: 0.2382 - accuracy: 0.9177 - val_loss: 0.6284 - val_accuracy: 0.8226 - lr: 1.0000e-05\n",
      "Epoch 120/300\n",
      "3997/3997 [==============================] - 141s 35ms/step - loss: 0.2316 - accuracy: 0.9206 - val_loss: 0.6282 - val_accuracy: 0.8211 - lr: 1.0000e-05\n",
      "Epoch 121/300\n",
      "3997/3997 [==============================] - 143s 36ms/step - loss: 0.2339 - accuracy: 0.9202 - val_loss: 0.6366 - val_accuracy: 0.8207 - lr: 1.0000e-05\n",
      "Epoch 122/300\n",
      "3997/3997 [==============================] - 141s 35ms/step - loss: 0.2370 - accuracy: 0.9189 - val_loss: 0.6396 - val_accuracy: 0.8193 - lr: 1.0000e-05\n",
      "Epoch 123/300\n",
      "3997/3997 [==============================] - 140s 35ms/step - loss: 0.2365 - accuracy: 0.9201 - val_loss: 0.6434 - val_accuracy: 0.8181 - lr: 1.0000e-05\n",
      "Epoch 124/300\n",
      "3997/3997 [==============================] - 138s 34ms/step - loss: 0.2389 - accuracy: 0.9192 - val_loss: 0.6466 - val_accuracy: 0.8167 - lr: 1.0000e-05\n",
      "Epoch 125/300\n",
      "3997/3997 [==============================] - 139s 35ms/step - loss: 0.2321 - accuracy: 0.9202 - val_loss: 0.6388 - val_accuracy: 0.8198 - lr: 1.0000e-05\n",
      "Epoch 126/300\n",
      "3997/3997 [==============================] - 138s 35ms/step - loss: 0.2342 - accuracy: 0.9200 - val_loss: 0.6301 - val_accuracy: 0.8223 - lr: 1.0000e-05\n",
      "Epoch 127/300\n",
      "3997/3997 [==============================] - 138s 35ms/step - loss: 0.2327 - accuracy: 0.9199 - val_loss: 0.6408 - val_accuracy: 0.8196 - lr: 1.0000e-05\n",
      "Epoch 128/300\n",
      "3997/3997 [==============================] - 138s 34ms/step - loss: 0.2343 - accuracy: 0.9201 - val_loss: 0.6306 - val_accuracy: 0.8200 - lr: 1.0000e-05\n",
      "Epoch 129/300\n",
      "3997/3997 [==============================] - 139s 35ms/step - loss: 0.2358 - accuracy: 0.9186 - val_loss: 0.6337 - val_accuracy: 0.8218 - lr: 1.0000e-05\n",
      "Epoch 130/300\n",
      "3997/3997 [==============================] - 137s 34ms/step - loss: 0.2340 - accuracy: 0.9209 - val_loss: 0.6327 - val_accuracy: 0.8216 - lr: 1.0000e-05\n",
      "Epoch 131/300\n",
      "3997/3997 [==============================] - 138s 35ms/step - loss: 0.2355 - accuracy: 0.9196 - val_loss: 0.6376 - val_accuracy: 0.8193 - lr: 1.0000e-05\n",
      "Epoch 132/300\n",
      "3997/3997 [==============================] - 137s 34ms/step - loss: 0.2321 - accuracy: 0.9209 - val_loss: 0.6322 - val_accuracy: 0.8208 - lr: 1.0000e-05\n",
      "Epoch 133/300\n",
      "3997/3997 [==============================] - 143s 36ms/step - loss: 0.2311 - accuracy: 0.9195 - val_loss: 0.6331 - val_accuracy: 0.8209 - lr: 1.0000e-05\n",
      "Epoch 134/300\n",
      "3997/3997 [==============================] - 139s 35ms/step - loss: 0.2314 - accuracy: 0.9209 - val_loss: 0.6417 - val_accuracy: 0.8180 - lr: 1.0000e-05\n",
      "Epoch 135/300\n",
      "3997/3997 [==============================] - 138s 34ms/step - loss: 0.2300 - accuracy: 0.9215 - val_loss: 0.6364 - val_accuracy: 0.8207 - lr: 1.0000e-05\n",
      "Epoch 136/300\n",
      "3997/3997 [==============================] - 138s 34ms/step - loss: 0.2344 - accuracy: 0.9205 - val_loss: 0.6392 - val_accuracy: 0.8208 - lr: 1.0000e-05\n",
      "Epoch 137/300\n",
      "3997/3997 [==============================] - 139s 35ms/step - loss: 0.2337 - accuracy: 0.9196 - val_loss: 0.6350 - val_accuracy: 0.8210 - lr: 1.0000e-05\n",
      "Epoch 138/300\n",
      "3997/3997 [==============================] - 141s 35ms/step - loss: 0.2316 - accuracy: 0.9210 - val_loss: 0.6335 - val_accuracy: 0.8219 - lr: 1.0000e-05\n",
      "Epoch 139/300\n",
      "3997/3997 [==============================] - 139s 35ms/step - loss: 0.2385 - accuracy: 0.9179 - val_loss: 0.6289 - val_accuracy: 0.8222 - lr: 1.0000e-05\n",
      "Epoch 140/300\n",
      "3997/3997 [==============================] - 136s 34ms/step - loss: 0.2292 - accuracy: 0.9225 - val_loss: 0.6270 - val_accuracy: 0.8228 - lr: 1.0000e-05\n",
      "Epoch 141/300\n",
      "3997/3997 [==============================] - 138s 35ms/step - loss: 0.2354 - accuracy: 0.9192 - val_loss: 0.6552 - val_accuracy: 0.8177 - lr: 1.0000e-05\n",
      "Epoch 142/300\n",
      "3997/3997 [==============================] - 138s 35ms/step - loss: 0.2319 - accuracy: 0.9207 - val_loss: 0.6263 - val_accuracy: 0.8228 - lr: 1.0000e-05\n",
      "Epoch 143/300\n",
      "3997/3997 [==============================] - 143s 36ms/step - loss: 0.2297 - accuracy: 0.9205 - val_loss: 0.6428 - val_accuracy: 0.8203 - lr: 1.0000e-05\n",
      "Epoch 144/300\n",
      "3997/3997 [==============================] - 138s 35ms/step - loss: 0.2287 - accuracy: 0.9200 - val_loss: 0.6360 - val_accuracy: 0.8205 - lr: 1.0000e-05\n",
      "Epoch 145/300\n",
      "3997/3997 [==============================] - 139s 35ms/step - loss: 0.2329 - accuracy: 0.9195 - val_loss: 0.6402 - val_accuracy: 0.8202 - lr: 1.0000e-05\n",
      "Epoch 146/300\n",
      "3997/3997 [==============================] - 139s 35ms/step - loss: 0.2284 - accuracy: 0.9222 - val_loss: 0.6318 - val_accuracy: 0.8223 - lr: 1.0000e-05\n",
      "Epoch 147/300\n",
      "3997/3997 [==============================] - 139s 35ms/step - loss: 0.2356 - accuracy: 0.9198 - val_loss: 0.6357 - val_accuracy: 0.8217 - lr: 1.0000e-05\n",
      "Epoch 148/300\n",
      "3997/3997 [==============================] - 139s 35ms/step - loss: 0.2265 - accuracy: 0.9224 - val_loss: 0.6323 - val_accuracy: 0.8228 - lr: 1.0000e-05\n",
      "Epoch 149/300\n",
      "3997/3997 [==============================] - 141s 35ms/step - loss: 0.2305 - accuracy: 0.9211 - val_loss: 0.6414 - val_accuracy: 0.8217 - lr: 1.0000e-05\n",
      "Epoch 150/300\n",
      "3997/3997 [==============================] - 139s 35ms/step - loss: 0.2284 - accuracy: 0.9218 - val_loss: 0.6279 - val_accuracy: 0.8234 - lr: 1.0000e-05\n",
      "Epoch 151/300\n",
      "3997/3997 [==============================] - 137s 34ms/step - loss: 0.2291 - accuracy: 0.9214 - val_loss: 0.6394 - val_accuracy: 0.8206 - lr: 1.0000e-05\n",
      "Epoch 152/300\n",
      "3997/3997 [==============================] - 140s 35ms/step - loss: 0.2279 - accuracy: 0.9208 - val_loss: 0.6263 - val_accuracy: 0.8233 - lr: 1.0000e-05\n",
      "Epoch 153/300\n",
      "3997/3997 [==============================] - 139s 35ms/step - loss: 0.2306 - accuracy: 0.9215 - val_loss: 0.6268 - val_accuracy: 0.8233 - lr: 1.0000e-05\n",
      "Epoch 154/300\n",
      "3997/3997 [==============================] - 141s 35ms/step - loss: 0.2303 - accuracy: 0.9213 - val_loss: 0.6319 - val_accuracy: 0.8229 - lr: 1.0000e-05\n",
      "Epoch 155/300\n",
      "3997/3997 [==============================] - 140s 35ms/step - loss: 0.2263 - accuracy: 0.9220 - val_loss: 0.6323 - val_accuracy: 0.8233 - lr: 1.0000e-05\n",
      "Epoch 156/300\n",
      "3997/3997 [==============================] - 139s 35ms/step - loss: 0.2293 - accuracy: 0.9225 - val_loss: 0.6390 - val_accuracy: 0.8223 - lr: 1.0000e-05\n",
      "Epoch 157/300\n",
      "3997/3997 [==============================] - 140s 35ms/step - loss: 0.2278 - accuracy: 0.9218 - val_loss: 0.6365 - val_accuracy: 0.8220 - lr: 1.0000e-05\n",
      "Epoch 158/300\n",
      "3997/3997 [==============================] - 140s 35ms/step - loss: 0.2297 - accuracy: 0.9204 - val_loss: 0.6346 - val_accuracy: 0.8222 - lr: 1.0000e-05\n",
      "Epoch 159/300\n",
      "3997/3997 [==============================] - 138s 35ms/step - loss: 0.2240 - accuracy: 0.9237 - val_loss: 0.6312 - val_accuracy: 0.8228 - lr: 1.0000e-05\n",
      "Epoch 160/300\n",
      "3997/3997 [==============================] - 141s 35ms/step - loss: 0.2216 - accuracy: 0.9232 - val_loss: 0.6350 - val_accuracy: 0.8223 - lr: 1.0000e-05\n",
      "Epoch 161/300\n",
      "3997/3997 [==============================] - 140s 35ms/step - loss: 0.2258 - accuracy: 0.9220 - val_loss: 0.6396 - val_accuracy: 0.8210 - lr: 1.0000e-05\n",
      "Epoch 162/300\n",
      "3997/3997 [==============================] - 140s 35ms/step - loss: 0.2289 - accuracy: 0.9225 - val_loss: 0.6364 - val_accuracy: 0.8218 - lr: 1.0000e-05\n",
      "Epoch 163/300\n",
      "3997/3997 [==============================] - 140s 35ms/step - loss: 0.2337 - accuracy: 0.9194 - val_loss: 0.6427 - val_accuracy: 0.8216 - lr: 1.0000e-05\n",
      "Epoch 164/300\n",
      "3997/3997 [==============================] - 141s 35ms/step - loss: 0.2256 - accuracy: 0.9221 - val_loss: 0.6399 - val_accuracy: 0.8213 - lr: 1.0000e-05\n",
      "Epoch 165/300\n",
      "3997/3997 [==============================] - 143s 36ms/step - loss: 0.2303 - accuracy: 0.9207 - val_loss: 0.6202 - val_accuracy: 0.8236 - lr: 1.0000e-05\n",
      "Epoch 166/300\n",
      "3997/3997 [==============================] - 143s 36ms/step - loss: 0.2256 - accuracy: 0.9214 - val_loss: 0.6442 - val_accuracy: 0.8210 - lr: 1.0000e-05\n",
      "Epoch 167/300\n",
      "3997/3997 [==============================] - 143s 36ms/step - loss: 0.2304 - accuracy: 0.9220 - val_loss: 0.6416 - val_accuracy: 0.8223 - lr: 1.0000e-05\n",
      "Epoch 168/300\n",
      "3997/3997 [==============================] - 144s 36ms/step - loss: 0.2246 - accuracy: 0.9226 - val_loss: 0.6435 - val_accuracy: 0.8212 - lr: 1.0000e-05\n",
      "Epoch 169/300\n",
      "3997/3997 [==============================] - 143s 36ms/step - loss: 0.2314 - accuracy: 0.9207 - val_loss: 0.6358 - val_accuracy: 0.8216 - lr: 1.0000e-05\n",
      "Epoch 170/300\n",
      "3997/3997 [==============================] - 143s 36ms/step - loss: 0.2260 - accuracy: 0.9218 - val_loss: 0.6333 - val_accuracy: 0.8228 - lr: 1.0000e-05\n",
      "Epoch 171/300\n",
      "3997/3997 [==============================] - 143s 36ms/step - loss: 0.2263 - accuracy: 0.9221 - val_loss: 0.6378 - val_accuracy: 0.8217 - lr: 1.0000e-05\n",
      "Epoch 172/300\n",
      "3997/3997 [==============================] - 143s 36ms/step - loss: 0.2264 - accuracy: 0.9225 - val_loss: 0.6364 - val_accuracy: 0.8219 - lr: 1.0000e-05\n",
      "Epoch 173/300\n",
      "3997/3997 [==============================] - 142s 36ms/step - loss: 0.2265 - accuracy: 0.9226 - val_loss: 0.6314 - val_accuracy: 0.8242 - lr: 1.0000e-05\n",
      "Epoch 174/300\n",
      "3997/3997 [==============================] - 141s 35ms/step - loss: 0.2221 - accuracy: 0.9237 - val_loss: 0.6434 - val_accuracy: 0.8215 - lr: 1.0000e-05\n",
      "Epoch 175/300\n",
      "3997/3997 [==============================] - 140s 35ms/step - loss: 0.2213 - accuracy: 0.9247 - val_loss: 0.6264 - val_accuracy: 0.8246 - lr: 1.0000e-05\n",
      "Epoch 176/300\n",
      "3997/3997 [==============================] - 141s 35ms/step - loss: 0.2212 - accuracy: 0.9236 - val_loss: 0.6359 - val_accuracy: 0.8219 - lr: 1.0000e-05\n",
      "Epoch 177/300\n",
      "3997/3997 [==============================] - 147s 37ms/step - loss: 0.2278 - accuracy: 0.9226 - val_loss: 0.6357 - val_accuracy: 0.8243 - lr: 1.0000e-05\n",
      "Epoch 178/300\n",
      "3997/3997 [==============================] - 148s 37ms/step - loss: 0.2237 - accuracy: 0.9237 - val_loss: 0.6423 - val_accuracy: 0.8203 - lr: 1.0000e-05\n",
      "Epoch 179/300\n",
      "3997/3997 [==============================] - 140s 35ms/step - loss: 0.2258 - accuracy: 0.9234 - val_loss: 0.6436 - val_accuracy: 0.8223 - lr: 1.0000e-05\n",
      "Epoch 180/300\n",
      "3997/3997 [==============================] - 141s 35ms/step - loss: 0.2215 - accuracy: 0.9237 - val_loss: 0.6356 - val_accuracy: 0.8238 - lr: 1.0000e-05\n",
      "Epoch 181/300\n",
      "3997/3997 [==============================] - 142s 35ms/step - loss: 0.2233 - accuracy: 0.9239 - val_loss: 0.6455 - val_accuracy: 0.8223 - lr: 1.0000e-05\n",
      "Epoch 182/300\n",
      "3997/3997 [==============================] - 139s 35ms/step - loss: 0.2327 - accuracy: 0.9202 - val_loss: 0.6397 - val_accuracy: 0.8228 - lr: 1.0000e-05\n",
      "Epoch 183/300\n",
      "3997/3997 [==============================] - 141s 35ms/step - loss: 0.2259 - accuracy: 0.9229 - val_loss: 0.6365 - val_accuracy: 0.8229 - lr: 1.0000e-05\n",
      "Epoch 184/300\n",
      "3997/3997 [==============================] - 141s 35ms/step - loss: 0.2243 - accuracy: 0.9230 - val_loss: 0.6384 - val_accuracy: 0.8223 - lr: 1.0000e-05\n",
      "Epoch 185/300\n",
      "3997/3997 [==============================] - 141s 35ms/step - loss: 0.2248 - accuracy: 0.9235 - val_loss: 0.6393 - val_accuracy: 0.8222 - lr: 1.0000e-05\n",
      "Epoch 186/300\n",
      "3997/3997 [==============================] - 140s 35ms/step - loss: 0.2253 - accuracy: 0.9243 - val_loss: 0.6422 - val_accuracy: 0.8212 - lr: 1.0000e-05\n",
      "Epoch 187/300\n",
      "3997/3997 [==============================] - 141s 35ms/step - loss: 0.2210 - accuracy: 0.9242 - val_loss: 0.6393 - val_accuracy: 0.8237 - lr: 1.0000e-05\n",
      "Epoch 188/300\n",
      "3997/3997 [==============================] - 140s 35ms/step - loss: 0.2204 - accuracy: 0.9250 - val_loss: 0.6337 - val_accuracy: 0.8232 - lr: 1.0000e-05\n",
      "Epoch 189/300\n",
      "3997/3997 [==============================] - 144s 36ms/step - loss: 0.2204 - accuracy: 0.9238 - val_loss: 0.6387 - val_accuracy: 0.8215 - lr: 1.0000e-05\n",
      "Epoch 190/300\n",
      "3997/3997 [==============================] - 142s 36ms/step - loss: 0.2206 - accuracy: 0.9254 - val_loss: 0.6401 - val_accuracy: 0.8220 - lr: 1.0000e-05\n",
      "Epoch 191/300\n",
      "3997/3997 [==============================] - 144s 36ms/step - loss: 0.2213 - accuracy: 0.9236 - val_loss: 0.6377 - val_accuracy: 0.8246 - lr: 1.0000e-05\n",
      "Epoch 192/300\n",
      "3997/3997 [==============================] - 142s 36ms/step - loss: 0.2176 - accuracy: 0.9253 - val_loss: 0.6443 - val_accuracy: 0.8229 - lr: 1.0000e-05\n",
      "Epoch 193/300\n",
      "3997/3997 [==============================] - 143s 36ms/step - loss: 0.2198 - accuracy: 0.9244 - val_loss: 0.6385 - val_accuracy: 0.8233 - lr: 1.0000e-05\n",
      "Epoch 194/300\n",
      "3997/3997 [==============================] - 142s 36ms/step - loss: 0.2215 - accuracy: 0.9237 - val_loss: 0.6436 - val_accuracy: 0.8219 - lr: 1.0000e-05\n",
      "Epoch 195/300\n",
      "3997/3997 [==============================] - 143s 36ms/step - loss: 0.2208 - accuracy: 0.9243 - val_loss: 0.6411 - val_accuracy: 0.8224 - lr: 1.0000e-05\n",
      "Epoch 196/300\n",
      "3997/3997 [==============================] - 142s 35ms/step - loss: 0.2186 - accuracy: 0.9244 - val_loss: 0.6363 - val_accuracy: 0.8236 - lr: 1.0000e-05\n",
      "Epoch 197/300\n",
      "3997/3997 [==============================] - 141s 35ms/step - loss: 0.2189 - accuracy: 0.9252 - val_loss: 0.6396 - val_accuracy: 0.8211 - lr: 1.0000e-05\n",
      "Epoch 198/300\n",
      "3997/3997 [==============================] - 140s 35ms/step - loss: 0.2241 - accuracy: 0.9236 - val_loss: 0.6316 - val_accuracy: 0.8243 - lr: 1.0000e-05\n",
      "Epoch 199/300\n",
      "3997/3997 [==============================] - 143s 36ms/step - loss: 0.2232 - accuracy: 0.9238 - val_loss: 0.6363 - val_accuracy: 0.8231 - lr: 1.0000e-05\n",
      "Epoch 200/300\n",
      "3997/3997 [==============================] - 141s 35ms/step - loss: 0.2246 - accuracy: 0.9230 - val_loss: 0.6316 - val_accuracy: 0.8243 - lr: 1.0000e-05\n",
      "Epoch 201/300\n",
      "3997/3997 [==============================] - 141s 35ms/step - loss: 0.2185 - accuracy: 0.9250 - val_loss: 0.6432 - val_accuracy: 0.8218 - lr: 1.0000e-05\n",
      "Epoch 202/300\n",
      "3997/3997 [==============================] - 141s 35ms/step - loss: 0.2232 - accuracy: 0.9234 - val_loss: 0.6511 - val_accuracy: 0.8206 - lr: 1.0000e-05\n",
      "Epoch 203/300\n",
      "3997/3997 [==============================] - 142s 35ms/step - loss: 0.2217 - accuracy: 0.9243 - val_loss: 0.6442 - val_accuracy: 0.8213 - lr: 1.0000e-05\n",
      "Epoch 204/300\n",
      "3997/3997 [==============================] - 142s 36ms/step - loss: 0.2151 - accuracy: 0.9246 - val_loss: 0.6485 - val_accuracy: 0.8212 - lr: 1.0000e-05\n",
      "Epoch 205/300\n",
      "3997/3997 [==============================] - 141s 35ms/step - loss: 0.2156 - accuracy: 0.9267 - val_loss: 0.6429 - val_accuracy: 0.8213 - lr: 1.0000e-05\n",
      "Epoch 206/300\n",
      "3997/3997 [==============================] - 143s 36ms/step - loss: 0.2196 - accuracy: 0.9238 - val_loss: 0.6364 - val_accuracy: 0.8211 - lr: 1.0000e-05\n",
      "Epoch 207/300\n",
      "3997/3997 [==============================] - 142s 36ms/step - loss: 0.2147 - accuracy: 0.9266 - val_loss: 0.6434 - val_accuracy: 0.8218 - lr: 1.0000e-05\n",
      "Epoch 208/300\n",
      "3997/3997 [==============================] - 143s 36ms/step - loss: 0.2196 - accuracy: 0.9247 - val_loss: 0.6294 - val_accuracy: 0.8248 - lr: 1.0000e-05\n",
      "Epoch 209/300\n",
      "3997/3997 [==============================] - 145s 36ms/step - loss: 0.2196 - accuracy: 0.9255 - val_loss: 0.6395 - val_accuracy: 0.8228 - lr: 1.0000e-05\n",
      "Epoch 210/300\n",
      "3997/3997 [==============================] - 145s 36ms/step - loss: 0.2164 - accuracy: 0.9261 - val_loss: 0.6479 - val_accuracy: 0.8208 - lr: 1.0000e-05\n",
      "Epoch 211/300\n",
      "3997/3997 [==============================] - 144s 36ms/step - loss: 0.2152 - accuracy: 0.9260 - val_loss: 0.6418 - val_accuracy: 0.8220 - lr: 1.0000e-05\n",
      "Epoch 212/300\n",
      "3997/3997 [==============================] - 146s 36ms/step - loss: 0.2141 - accuracy: 0.9269 - val_loss: 0.6351 - val_accuracy: 0.8238 - lr: 1.0000e-05\n",
      "Epoch 213/300\n",
      "3997/3997 [==============================] - 147s 37ms/step - loss: 0.2158 - accuracy: 0.9255 - val_loss: 0.6351 - val_accuracy: 0.8245 - lr: 1.0000e-05\n",
      "Epoch 214/300\n",
      "3997/3997 [==============================] - 147s 37ms/step - loss: 0.2172 - accuracy: 0.9256 - val_loss: 0.6411 - val_accuracy: 0.8230 - lr: 1.0000e-05\n",
      "Epoch 215/300\n",
      "3997/3997 [==============================] - 145s 36ms/step - loss: 0.2164 - accuracy: 0.9254 - val_loss: 0.6455 - val_accuracy: 0.8217 - lr: 1.0000e-05\n",
      "Epoch 216/300\n",
      "3997/3997 [==============================] - 152s 38ms/step - loss: 0.2140 - accuracy: 0.9280 - val_loss: 0.6355 - val_accuracy: 0.8236 - lr: 1.0000e-05\n",
      "Epoch 217/300\n",
      "3997/3997 [==============================] - 141s 35ms/step - loss: 0.2188 - accuracy: 0.9242 - val_loss: 0.6334 - val_accuracy: 0.8237 - lr: 1.0000e-05\n",
      "Epoch 218/300\n",
      "3997/3997 [==============================] - 146s 36ms/step - loss: 0.2156 - accuracy: 0.9265 - val_loss: 0.6350 - val_accuracy: 0.8232 - lr: 1.0000e-05\n",
      "Epoch 219/300\n",
      "3997/3997 [==============================] - 143s 36ms/step - loss: 0.2174 - accuracy: 0.9256 - val_loss: 0.6395 - val_accuracy: 0.8215 - lr: 1.0000e-05\n",
      "Epoch 220/300\n",
      "3997/3997 [==============================] - 137s 34ms/step - loss: 0.2135 - accuracy: 0.9264 - val_loss: 0.6408 - val_accuracy: 0.8225 - lr: 1.0000e-05\n",
      "Epoch 221/300\n",
      "3997/3997 [==============================] - 144s 36ms/step - loss: 0.2148 - accuracy: 0.9264 - val_loss: 0.6400 - val_accuracy: 0.8223 - lr: 1.0000e-05\n",
      "Epoch 222/300\n",
      "3997/3997 [==============================] - 138s 35ms/step - loss: 0.2186 - accuracy: 0.9245 - val_loss: 0.6439 - val_accuracy: 0.8224 - lr: 1.0000e-05\n",
      "Epoch 223/300\n",
      "3997/3997 [==============================] - 140s 35ms/step - loss: 0.2164 - accuracy: 0.9257 - val_loss: 0.6347 - val_accuracy: 0.8248 - lr: 1.0000e-05\n",
      "Epoch 224/300\n",
      "3997/3997 [==============================] - 140s 35ms/step - loss: 0.2128 - accuracy: 0.9265 - val_loss: 0.6366 - val_accuracy: 0.8240 - lr: 1.0000e-05\n",
      "Epoch 225/300\n",
      "3997/3997 [==============================] - 140s 35ms/step - loss: 0.2076 - accuracy: 0.9288 - val_loss: 0.6394 - val_accuracy: 0.8238 - lr: 1.0000e-05\n",
      "Epoch 226/300\n",
      "3997/3997 [==============================] - 140s 35ms/step - loss: 0.2176 - accuracy: 0.9259 - val_loss: 0.6481 - val_accuracy: 0.8227 - lr: 1.0000e-05\n",
      "Epoch 227/300\n",
      "3997/3997 [==============================] - 143s 36ms/step - loss: 0.2168 - accuracy: 0.9257 - val_loss: 0.6316 - val_accuracy: 0.8240 - lr: 1.0000e-05\n",
      "Epoch 228/300\n",
      "3997/3997 [==============================] - 143s 36ms/step - loss: 0.2155 - accuracy: 0.9267 - val_loss: 0.6362 - val_accuracy: 0.8243 - lr: 1.0000e-05\n",
      "Epoch 229/300\n",
      "3997/3997 [==============================] - 141s 35ms/step - loss: 0.2196 - accuracy: 0.9251 - val_loss: 0.6471 - val_accuracy: 0.8215 - lr: 1.0000e-05\n",
      "Epoch 230/300\n",
      "3997/3997 [==============================] - 136s 34ms/step - loss: 0.2163 - accuracy: 0.9262 - val_loss: 0.6388 - val_accuracy: 0.8240 - lr: 1.0000e-05\n",
      "Epoch 231/300\n",
      "3997/3997 [==============================] - 136s 34ms/step - loss: 0.2188 - accuracy: 0.9255 - val_loss: 0.6351 - val_accuracy: 0.8248 - lr: 1.0000e-05\n",
      "Epoch 232/300\n",
      "3997/3997 [==============================] - 135s 34ms/step - loss: 0.2176 - accuracy: 0.9254 - val_loss: 0.6402 - val_accuracy: 0.8242 - lr: 1.0000e-05\n",
      "Epoch 233/300\n",
      "3997/3997 [==============================] - 138s 35ms/step - loss: 0.2155 - accuracy: 0.9256 - val_loss: 0.6428 - val_accuracy: 0.8231 - lr: 1.0000e-05\n",
      "Epoch 234/300\n",
      "3997/3997 [==============================] - 137s 34ms/step - loss: 0.2176 - accuracy: 0.9253 - val_loss: 0.6453 - val_accuracy: 0.8233 - lr: 1.0000e-05\n",
      "Epoch 235/300\n",
      "3997/3997 [==============================] - 138s 34ms/step - loss: 0.2121 - accuracy: 0.9284 - val_loss: 0.6416 - val_accuracy: 0.8234 - lr: 1.0000e-05\n",
      "Epoch 236/300\n",
      "3997/3997 [==============================] - 137s 34ms/step - loss: 0.2101 - accuracy: 0.9277 - val_loss: 0.6404 - val_accuracy: 0.8238 - lr: 1.0000e-05\n",
      "Epoch 237/300\n",
      "3997/3997 [==============================] - 138s 34ms/step - loss: 0.2154 - accuracy: 0.9262 - val_loss: 0.6402 - val_accuracy: 0.8242 - lr: 1.0000e-05\n",
      "Epoch 238/300\n",
      "3997/3997 [==============================] - 137s 34ms/step - loss: 0.2114 - accuracy: 0.9278 - val_loss: 0.6425 - val_accuracy: 0.8219 - lr: 1.0000e-05\n",
      "Epoch 239/300\n",
      "3997/3997 [==============================] - 144s 36ms/step - loss: 0.2167 - accuracy: 0.9259 - val_loss: 0.6378 - val_accuracy: 0.8254 - lr: 1.0000e-05\n",
      "Epoch 240/300\n",
      "3997/3997 [==============================] - 145s 36ms/step - loss: 0.2162 - accuracy: 0.9262 - val_loss: 0.6319 - val_accuracy: 0.8250 - lr: 1.0000e-05\n",
      "Epoch 241/300\n",
      "3997/3997 [==============================] - 145s 36ms/step - loss: 0.2105 - accuracy: 0.9272 - val_loss: 0.6432 - val_accuracy: 0.8230 - lr: 1.0000e-05\n",
      "Epoch 242/300\n",
      "3997/3997 [==============================] - 136s 34ms/step - loss: 0.2158 - accuracy: 0.9263 - val_loss: 0.6366 - val_accuracy: 0.8239 - lr: 1.0000e-05\n",
      "Epoch 243/300\n",
      "3997/3997 [==============================] - 138s 35ms/step - loss: 0.2150 - accuracy: 0.9254 - val_loss: 0.6387 - val_accuracy: 0.8232 - lr: 1.0000e-05\n",
      "Epoch 244/300\n",
      "3997/3997 [==============================] - 138s 35ms/step - loss: 0.2146 - accuracy: 0.9265 - val_loss: 0.6339 - val_accuracy: 0.8258 - lr: 1.0000e-05\n",
      "Epoch 245/300\n",
      "3997/3997 [==============================] - 139s 35ms/step - loss: 0.2137 - accuracy: 0.9270 - val_loss: 0.6372 - val_accuracy: 0.8238 - lr: 1.0000e-05\n",
      "Epoch 246/300\n",
      "3997/3997 [==============================] - 137s 34ms/step - loss: 0.2179 - accuracy: 0.9256 - val_loss: 0.6396 - val_accuracy: 0.8235 - lr: 1.0000e-05\n",
      "Epoch 247/300\n",
      "3997/3997 [==============================] - 138s 35ms/step - loss: 0.2130 - accuracy: 0.9275 - val_loss: 0.6416 - val_accuracy: 0.8244 - lr: 1.0000e-05\n",
      "Epoch 248/300\n",
      "3997/3997 [==============================] - 137s 34ms/step - loss: 0.2113 - accuracy: 0.9276 - val_loss: 0.6493 - val_accuracy: 0.8216 - lr: 1.0000e-05\n",
      "Epoch 249/300\n",
      "3997/3997 [==============================] - 138s 34ms/step - loss: 0.2108 - accuracy: 0.9287 - val_loss: 0.6422 - val_accuracy: 0.8238 - lr: 1.0000e-05\n",
      "Epoch 250/300\n",
      "3997/3997 [==============================] - 137s 34ms/step - loss: 0.2182 - accuracy: 0.9248 - val_loss: 0.6424 - val_accuracy: 0.8238 - lr: 1.0000e-05\n",
      "Epoch 251/300\n",
      "3997/3997 [==============================] - 138s 34ms/step - loss: 0.2112 - accuracy: 0.9275 - val_loss: 0.6504 - val_accuracy: 0.8218 - lr: 1.0000e-05\n",
      "Epoch 252/300\n",
      "3997/3997 [==============================] - 137s 34ms/step - loss: 0.2123 - accuracy: 0.9271 - val_loss: 0.6367 - val_accuracy: 0.8248 - lr: 1.0000e-05\n",
      "Epoch 253/300\n",
      "3997/3997 [==============================] - 138s 35ms/step - loss: 0.2108 - accuracy: 0.9280 - val_loss: 0.6454 - val_accuracy: 0.8241 - lr: 1.0000e-05\n",
      "Epoch 254/300\n",
      "3997/3997 [==============================] - 137s 34ms/step - loss: 0.2136 - accuracy: 0.9276 - val_loss: 0.6473 - val_accuracy: 0.8225 - lr: 1.0000e-05\n",
      "Epoch 255/300\n",
      "3997/3997 [==============================] - 138s 35ms/step - loss: 0.2146 - accuracy: 0.9271 - val_loss: 0.6481 - val_accuracy: 0.8228 - lr: 1.0000e-05\n",
      "Epoch 256/300\n",
      "3997/3997 [==============================] - 137s 34ms/step - loss: 0.2141 - accuracy: 0.9274 - val_loss: 0.6425 - val_accuracy: 0.8229 - lr: 1.0000e-05\n",
      "Epoch 257/300\n",
      "3997/3997 [==============================] - 139s 35ms/step - loss: 0.2061 - accuracy: 0.9303 - val_loss: 0.6419 - val_accuracy: 0.8247 - lr: 1.0000e-05\n",
      "Epoch 258/300\n",
      "3997/3997 [==============================] - 140s 35ms/step - loss: 0.2122 - accuracy: 0.9279 - val_loss: 0.6393 - val_accuracy: 0.8238 - lr: 1.0000e-05\n",
      "Epoch 259/300\n",
      "3997/3997 [==============================] - 141s 35ms/step - loss: 0.2130 - accuracy: 0.9274 - val_loss: 0.6401 - val_accuracy: 0.8242 - lr: 1.0000e-05\n",
      "Epoch 260/300\n",
      "3997/3997 [==============================] - 149s 37ms/step - loss: 0.2087 - accuracy: 0.9289 - val_loss: 0.6397 - val_accuracy: 0.8234 - lr: 1.0000e-05\n",
      "Epoch 261/300\n",
      "3997/3997 [==============================] - 149s 37ms/step - loss: 0.2085 - accuracy: 0.9282 - val_loss: 0.6411 - val_accuracy: 0.8242 - lr: 1.0000e-05\n",
      "Epoch 262/300\n",
      "3997/3997 [==============================] - 138s 35ms/step - loss: 0.2135 - accuracy: 0.9271 - val_loss: 0.6567 - val_accuracy: 0.8219 - lr: 1.0000e-05\n",
      "Epoch 263/300\n",
      "3997/3997 [==============================] - 138s 34ms/step - loss: 0.2088 - accuracy: 0.9277 - val_loss: 0.6390 - val_accuracy: 0.8241 - lr: 1.0000e-05\n",
      "Epoch 264/300\n",
      "3997/3997 [==============================] - 139s 35ms/step - loss: 0.2118 - accuracy: 0.9276 - val_loss: 0.6372 - val_accuracy: 0.8242 - lr: 1.0000e-05\n",
      "Epoch 265/300\n",
      "3997/3997 [==============================] - 139s 35ms/step - loss: 0.2080 - accuracy: 0.9292 - val_loss: 0.6388 - val_accuracy: 0.8238 - lr: 1.0000e-05\n",
      "Epoch 266/300\n",
      "3997/3997 [==============================] - 140s 35ms/step - loss: 0.2092 - accuracy: 0.9282 - val_loss: 0.6459 - val_accuracy: 0.8242 - lr: 1.0000e-05\n",
      "Epoch 267/300\n",
      "3997/3997 [==============================] - 140s 35ms/step - loss: 0.2093 - accuracy: 0.9281 - val_loss: 0.6426 - val_accuracy: 0.8244 - lr: 1.0000e-05\n",
      "Epoch 268/300\n",
      "3997/3997 [==============================] - 142s 36ms/step - loss: 0.2125 - accuracy: 0.9273 - val_loss: 0.6433 - val_accuracy: 0.8232 - lr: 1.0000e-05\n",
      "Epoch 269/300\n",
      "3997/3997 [==============================] - 139s 35ms/step - loss: 0.2122 - accuracy: 0.9276 - val_loss: 0.6402 - val_accuracy: 0.8239 - lr: 1.0000e-05\n",
      "Epoch 270/300\n",
      "3997/3997 [==============================] - 139s 35ms/step - loss: 0.2131 - accuracy: 0.9269 - val_loss: 0.6350 - val_accuracy: 0.8247 - lr: 1.0000e-05\n",
      "Epoch 271/300\n",
      "3997/3997 [==============================] - 138s 34ms/step - loss: 0.2064 - accuracy: 0.9303 - val_loss: 0.6394 - val_accuracy: 0.8245 - lr: 1.0000e-05\n",
      "Epoch 272/300\n",
      "3997/3997 [==============================] - 139s 35ms/step - loss: 0.2049 - accuracy: 0.9288 - val_loss: 0.6366 - val_accuracy: 0.8243 - lr: 1.0000e-05\n",
      "Epoch 273/300\n",
      "3997/3997 [==============================] - 139s 35ms/step - loss: 0.2070 - accuracy: 0.9293 - val_loss: 0.6326 - val_accuracy: 0.8262 - lr: 1.0000e-05\n",
      "Epoch 274/300\n",
      "3997/3997 [==============================] - 139s 35ms/step - loss: 0.2060 - accuracy: 0.9296 - val_loss: 0.6360 - val_accuracy: 0.8247 - lr: 1.0000e-05\n",
      "Epoch 275/300\n",
      "3997/3997 [==============================] - 138s 34ms/step - loss: 0.2040 - accuracy: 0.9311 - val_loss: 0.6415 - val_accuracy: 0.8233 - lr: 1.0000e-05\n",
      "Epoch 276/300\n",
      "3997/3997 [==============================] - 140s 35ms/step - loss: 0.2063 - accuracy: 0.9286 - val_loss: 0.6268 - val_accuracy: 0.8276 - lr: 1.0000e-05\n",
      "Epoch 277/300\n",
      "3997/3997 [==============================] - 139s 35ms/step - loss: 0.2060 - accuracy: 0.9299 - val_loss: 0.6422 - val_accuracy: 0.8228 - lr: 1.0000e-05\n",
      "Epoch 278/300\n",
      "3997/3997 [==============================] - 139s 35ms/step - loss: 0.2082 - accuracy: 0.9292 - val_loss: 0.6341 - val_accuracy: 0.8250 - lr: 1.0000e-05\n",
      "Epoch 279/300\n",
      "3997/3997 [==============================] - 137s 34ms/step - loss: 0.2081 - accuracy: 0.9284 - val_loss: 0.6408 - val_accuracy: 0.8250 - lr: 1.0000e-05\n",
      "Epoch 280/300\n",
      "3997/3997 [==============================] - 140s 35ms/step - loss: 0.2060 - accuracy: 0.9299 - val_loss: 0.6356 - val_accuracy: 0.8225 - lr: 1.0000e-05\n",
      "Epoch 281/300\n",
      "3997/3997 [==============================] - 138s 34ms/step - loss: 0.2039 - accuracy: 0.9305 - val_loss: 0.6297 - val_accuracy: 0.8269 - lr: 1.0000e-05\n",
      "Epoch 282/300\n",
      "3997/3997 [==============================] - 139s 35ms/step - loss: 0.2075 - accuracy: 0.9290 - val_loss: 0.6384 - val_accuracy: 0.8237 - lr: 1.0000e-05\n",
      "Epoch 283/300\n",
      "3997/3997 [==============================] - 139s 35ms/step - loss: 0.2050 - accuracy: 0.9300 - val_loss: 0.6372 - val_accuracy: 0.8236 - lr: 1.0000e-05\n",
      "Epoch 284/300\n",
      "3997/3997 [==============================] - 140s 35ms/step - loss: 0.2083 - accuracy: 0.9286 - val_loss: 0.6402 - val_accuracy: 0.8262 - lr: 1.0000e-05\n",
      "Epoch 285/300\n",
      "3997/3997 [==============================] - 139s 35ms/step - loss: 0.2067 - accuracy: 0.9286 - val_loss: 0.6425 - val_accuracy: 0.8245 - lr: 1.0000e-05\n",
      "Epoch 286/300\n",
      "3997/3997 [==============================] - 139s 35ms/step - loss: 0.2098 - accuracy: 0.9280 - val_loss: 0.6354 - val_accuracy: 0.8263 - lr: 1.0000e-05\n",
      "Epoch 287/300\n",
      "3997/3997 [==============================] - 137s 34ms/step - loss: 0.2066 - accuracy: 0.9291 - val_loss: 0.6423 - val_accuracy: 0.8241 - lr: 1.0000e-05\n",
      "Epoch 288/300\n",
      "3997/3997 [==============================] - 139s 35ms/step - loss: 0.2031 - accuracy: 0.9310 - val_loss: 0.6273 - val_accuracy: 0.8278 - lr: 1.0000e-05\n",
      "Epoch 289/300\n",
      "3997/3997 [==============================] - 139s 35ms/step - loss: 0.2082 - accuracy: 0.9290 - val_loss: 0.6344 - val_accuracy: 0.8238 - lr: 1.0000e-05\n",
      "Epoch 290/300\n",
      "3997/3997 [==============================] - 145s 36ms/step - loss: 0.2078 - accuracy: 0.9291 - val_loss: 0.6461 - val_accuracy: 0.8236 - lr: 1.0000e-05\n",
      "Epoch 291/300\n",
      "3997/3997 [==============================] - 144s 36ms/step - loss: 0.2068 - accuracy: 0.9291 - val_loss: 0.6362 - val_accuracy: 0.8266 - lr: 1.0000e-05\n",
      "Epoch 292/300\n",
      "3997/3997 [==============================] - 142s 36ms/step - loss: 0.2072 - accuracy: 0.9302 - val_loss: 0.6350 - val_accuracy: 0.8258 - lr: 1.0000e-05\n",
      "Epoch 293/300\n",
      "3997/3997 [==============================] - 140s 35ms/step - loss: 0.2041 - accuracy: 0.9299 - val_loss: 0.6376 - val_accuracy: 0.8242 - lr: 1.0000e-05\n",
      "Epoch 294/300\n",
      "3997/3997 [==============================] - 142s 36ms/step - loss: 0.2030 - accuracy: 0.9302 - val_loss: 0.6249 - val_accuracy: 0.8278 - lr: 1.0000e-05\n",
      "Epoch 295/300\n",
      "3997/3997 [==============================] - 139s 35ms/step - loss: 0.2061 - accuracy: 0.9293 - val_loss: 0.6396 - val_accuracy: 0.8241 - lr: 1.0000e-05\n",
      "Epoch 296/300\n",
      "3997/3997 [==============================] - 142s 36ms/step - loss: 0.1995 - accuracy: 0.9325 - val_loss: 0.6428 - val_accuracy: 0.8268 - lr: 1.0000e-05\n",
      "Epoch 297/300\n",
      "3997/3997 [==============================] - 147s 37ms/step - loss: 0.2019 - accuracy: 0.9302 - val_loss: 0.6370 - val_accuracy: 0.8266 - lr: 1.0000e-05\n",
      "Epoch 298/300\n",
      "3997/3997 [==============================] - 143s 36ms/step - loss: 0.2051 - accuracy: 0.9311 - val_loss: 0.6359 - val_accuracy: 0.8259 - lr: 1.0000e-05\n",
      "Epoch 299/300\n",
      "3997/3997 [==============================] - 140s 35ms/step - loss: 0.2043 - accuracy: 0.9309 - val_loss: 0.6303 - val_accuracy: 0.8259 - lr: 1.0000e-05\n",
      "Epoch 300/300\n",
      "3997/3997 [==============================] - 142s 35ms/step - loss: 0.1992 - accuracy: 0.9320 - val_loss: 0.6441 - val_accuracy: 0.8256 - lr: 1.0000e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x26acf6356f0>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1_best.fit(train_gen, validation_data=validation_gen, epochs = 300, callbacks = [reduce_lr, model_checkpoint, csv_logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "af73ee91-94af-46ee-96db-ee2d7fb11e88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "3997/3997 [==============================] - 146s 37ms/step - loss: 0.2035 - accuracy: 0.9307 - val_loss: 0.6422 - val_accuracy: 0.8262 - lr: 1.0000e-05\n",
      "Epoch 2/300\n",
      "3997/3997 [==============================] - 139s 35ms/step - loss: 0.2040 - accuracy: 0.9312 - val_loss: 0.6509 - val_accuracy: 0.8246 - lr: 1.0000e-05\n",
      "Epoch 3/300\n",
      "3997/3997 [==============================] - 135s 34ms/step - loss: 0.2002 - accuracy: 0.9312 - val_loss: 0.6384 - val_accuracy: 0.8260 - lr: 1.0000e-05\n",
      "Epoch 4/300\n",
      "3997/3997 [==============================] - 134s 34ms/step - loss: 0.2029 - accuracy: 0.9302 - val_loss: 0.6484 - val_accuracy: 0.8252 - lr: 1.0000e-05\n",
      "Epoch 5/300\n",
      "3997/3997 [==============================] - 136s 34ms/step - loss: 0.2024 - accuracy: 0.9323 - val_loss: 0.6428 - val_accuracy: 0.8258 - lr: 1.0000e-05\n",
      "Epoch 6/300\n",
      "3997/3997 [==============================] - 142s 36ms/step - loss: 0.1968 - accuracy: 0.9326 - val_loss: 0.6447 - val_accuracy: 0.8238 - lr: 1.0000e-05\n",
      "Epoch 7/300\n",
      "3997/3997 [==============================] - 145s 36ms/step - loss: 0.2005 - accuracy: 0.9314 - val_loss: 0.6439 - val_accuracy: 0.8249 - lr: 1.0000e-05\n",
      "Epoch 8/300\n",
      "3997/3997 [==============================] - 134s 33ms/step - loss: 0.2041 - accuracy: 0.9308 - val_loss: 0.6337 - val_accuracy: 0.8264 - lr: 1.0000e-05\n",
      "Epoch 9/300\n",
      "3997/3997 [==============================] - 134s 34ms/step - loss: 0.2025 - accuracy: 0.9310 - val_loss: 0.6390 - val_accuracy: 0.8257 - lr: 1.0000e-05\n",
      "Epoch 10/300\n",
      "3997/3997 [==============================] - 134s 34ms/step - loss: 0.2023 - accuracy: 0.9305 - val_loss: 0.6382 - val_accuracy: 0.8248 - lr: 1.0000e-05\n",
      "Epoch 11/300\n",
      "3997/3997 [==============================] - 134s 34ms/step - loss: 0.2063 - accuracy: 0.9295 - val_loss: 0.6420 - val_accuracy: 0.8243 - lr: 1.0000e-05\n",
      "Epoch 12/300\n",
      "3997/3997 [==============================] - 134s 33ms/step - loss: 0.2011 - accuracy: 0.9313 - val_loss: 0.6355 - val_accuracy: 0.8257 - lr: 1.0000e-05\n",
      "Epoch 13/300\n",
      "3997/3997 [==============================] - 135s 34ms/step - loss: 0.1982 - accuracy: 0.9332 - val_loss: 0.6435 - val_accuracy: 0.8259 - lr: 1.0000e-05\n",
      "Epoch 14/300\n",
      "3997/3997 [==============================] - 175s 44ms/step - loss: 0.1990 - accuracy: 0.9322 - val_loss: 0.6469 - val_accuracy: 0.8248 - lr: 1.0000e-05\n",
      "Epoch 15/300\n",
      "3997/3997 [==============================] - 141s 35ms/step - loss: 0.2046 - accuracy: 0.9300 - val_loss: 0.6375 - val_accuracy: 0.8259 - lr: 1.0000e-05\n",
      "Epoch 16/300\n",
      "3997/3997 [==============================] - 137s 34ms/step - loss: 0.2030 - accuracy: 0.9302 - val_loss: 0.6343 - val_accuracy: 0.8272 - lr: 1.0000e-05\n",
      "Epoch 17/300\n",
      "3997/3997 [==============================] - 146s 36ms/step - loss: 0.1981 - accuracy: 0.9319 - val_loss: 0.6397 - val_accuracy: 0.8268 - lr: 1.0000e-05\n",
      "Epoch 18/300\n",
      "3997/3997 [==============================] - 147s 37ms/step - loss: 0.1992 - accuracy: 0.9323 - val_loss: 0.6436 - val_accuracy: 0.8255 - lr: 1.0000e-05\n",
      "Epoch 19/300\n",
      "3997/3997 [==============================] - 140s 35ms/step - loss: 0.2022 - accuracy: 0.9321 - val_loss: 0.6446 - val_accuracy: 0.8253 - lr: 1.0000e-05\n",
      "Epoch 20/300\n",
      "3997/3997 [==============================] - 145s 36ms/step - loss: 0.2000 - accuracy: 0.9326 - val_loss: 0.6448 - val_accuracy: 0.8242 - lr: 1.0000e-05\n",
      "Epoch 21/300\n",
      "3997/3997 [==============================] - 142s 36ms/step - loss: 0.2007 - accuracy: 0.9309 - val_loss: 0.6450 - val_accuracy: 0.8241 - lr: 1.0000e-05\n",
      "Epoch 22/300\n",
      "3997/3997 [==============================] - 144s 36ms/step - loss: 0.1997 - accuracy: 0.9315 - val_loss: 0.6499 - val_accuracy: 0.8253 - lr: 1.0000e-05\n",
      "Epoch 23/300\n",
      "3997/3997 [==============================] - 146s 36ms/step - loss: 0.1984 - accuracy: 0.9323 - val_loss: 0.6423 - val_accuracy: 0.8251 - lr: 1.0000e-05\n",
      "Epoch 24/300\n",
      "3997/3997 [==============================] - 135s 34ms/step - loss: 0.1962 - accuracy: 0.9320 - val_loss: 0.6429 - val_accuracy: 0.8243 - lr: 1.0000e-05\n",
      "Epoch 25/300\n",
      "3997/3997 [==============================] - 144s 36ms/step - loss: 0.2002 - accuracy: 0.9325 - val_loss: 0.6500 - val_accuracy: 0.8244 - lr: 1.0000e-05\n",
      "Epoch 26/300\n",
      "3997/3997 [==============================] - 144s 36ms/step - loss: 0.1993 - accuracy: 0.9317 - val_loss: 0.6423 - val_accuracy: 0.8250 - lr: 1.0000e-05\n",
      "Epoch 27/300\n",
      "3997/3997 [==============================] - 142s 35ms/step - loss: 0.2000 - accuracy: 0.9325 - val_loss: 0.6403 - val_accuracy: 0.8253 - lr: 1.0000e-05\n",
      "Epoch 28/300\n",
      "3997/3997 [==============================] - 144s 36ms/step - loss: 0.1958 - accuracy: 0.9325 - val_loss: 0.6453 - val_accuracy: 0.8254 - lr: 1.0000e-05\n",
      "Epoch 29/300\n",
      "3997/3997 [==============================] - 142s 36ms/step - loss: 0.1994 - accuracy: 0.9316 - val_loss: 0.6392 - val_accuracy: 0.8262 - lr: 1.0000e-05\n",
      "Epoch 30/300\n",
      "3997/3997 [==============================] - 142s 36ms/step - loss: 0.1948 - accuracy: 0.9338 - val_loss: 0.6329 - val_accuracy: 0.8264 - lr: 1.0000e-05\n",
      "Epoch 31/300\n",
      "3997/3997 [==============================] - 141s 35ms/step - loss: 0.1991 - accuracy: 0.9310 - val_loss: 0.6422 - val_accuracy: 0.8237 - lr: 1.0000e-05\n",
      "Epoch 32/300\n",
      "3997/3997 [==============================] - 141s 35ms/step - loss: 0.1979 - accuracy: 0.9326 - val_loss: 0.6398 - val_accuracy: 0.8263 - lr: 1.0000e-05\n",
      "Epoch 33/300\n",
      "3997/3997 [==============================] - 144s 36ms/step - loss: 0.1985 - accuracy: 0.9322 - val_loss: 0.6375 - val_accuracy: 0.8258 - lr: 1.0000e-05\n",
      "Epoch 34/300\n",
      "3997/3997 [==============================] - 142s 35ms/step - loss: 0.1947 - accuracy: 0.9334 - val_loss: 0.6390 - val_accuracy: 0.8251 - lr: 1.0000e-05\n",
      "Epoch 35/300\n",
      "3997/3997 [==============================] - 136s 34ms/step - loss: 0.1946 - accuracy: 0.9336 - val_loss: 0.6359 - val_accuracy: 0.8267 - lr: 1.0000e-05\n",
      "Epoch 36/300\n",
      "3997/3997 [==============================] - 143s 36ms/step - loss: 0.1938 - accuracy: 0.9345 - val_loss: 0.6439 - val_accuracy: 0.8255 - lr: 1.0000e-05\n",
      "Epoch 37/300\n",
      "3997/3997 [==============================] - 134s 34ms/step - loss: 0.1990 - accuracy: 0.9314 - val_loss: 0.6338 - val_accuracy: 0.8272 - lr: 1.0000e-05\n",
      "Epoch 38/300\n",
      "3997/3997 [==============================] - 134s 34ms/step - loss: 0.1965 - accuracy: 0.9328 - val_loss: 0.6627 - val_accuracy: 0.8228 - lr: 1.0000e-05\n",
      "Epoch 39/300\n",
      "3997/3997 [==============================] - 141s 35ms/step - loss: 0.1951 - accuracy: 0.9335 - val_loss: 0.6386 - val_accuracy: 0.8276 - lr: 1.0000e-05\n",
      "Epoch 40/300\n",
      "3997/3997 [==============================] - 134s 34ms/step - loss: 0.2022 - accuracy: 0.9317 - val_loss: 0.6434 - val_accuracy: 0.8237 - lr: 1.0000e-05\n",
      "Epoch 41/300\n",
      "3997/3997 [==============================] - 134s 34ms/step - loss: 0.1984 - accuracy: 0.9322 - val_loss: 0.6364 - val_accuracy: 0.8273 - lr: 1.0000e-05\n",
      "Epoch 42/300\n",
      "3997/3997 [==============================] - 135s 34ms/step - loss: 0.1995 - accuracy: 0.9317 - val_loss: 0.6352 - val_accuracy: 0.8264 - lr: 1.0000e-05\n",
      "Epoch 43/300\n",
      "3997/3997 [==============================] - 134s 34ms/step - loss: 0.1979 - accuracy: 0.9330 - val_loss: 0.6372 - val_accuracy: 0.8270 - lr: 1.0000e-05\n",
      "Epoch 44/300\n",
      "3997/3997 [==============================] - 139s 35ms/step - loss: 0.1953 - accuracy: 0.9333 - val_loss: 0.6388 - val_accuracy: 0.8269 - lr: 1.0000e-05\n",
      "Epoch 45/300\n",
      "3997/3997 [==============================] - 134s 33ms/step - loss: 0.1986 - accuracy: 0.9324 - val_loss: 0.6356 - val_accuracy: 0.8266 - lr: 1.0000e-05\n",
      "Epoch 46/300\n",
      "3997/3997 [==============================] - 138s 34ms/step - loss: 0.1989 - accuracy: 0.9324 - val_loss: 0.6371 - val_accuracy: 0.8262 - lr: 1.0000e-05\n",
      "Epoch 47/300\n",
      "3997/3997 [==============================] - 136s 34ms/step - loss: 0.2007 - accuracy: 0.9317 - val_loss: 0.6375 - val_accuracy: 0.8262 - lr: 1.0000e-05\n",
      "Epoch 48/300\n",
      "3997/3997 [==============================] - 134s 34ms/step - loss: 0.1993 - accuracy: 0.9330 - val_loss: 0.6391 - val_accuracy: 0.8255 - lr: 1.0000e-05\n",
      "Epoch 49/300\n",
      "3997/3997 [==============================] - 134s 34ms/step - loss: 0.1940 - accuracy: 0.9344 - val_loss: 0.6328 - val_accuracy: 0.8278 - lr: 1.0000e-05\n",
      "Epoch 50/300\n",
      "3997/3997 [==============================] - 134s 34ms/step - loss: 0.1978 - accuracy: 0.9321 - val_loss: 0.6524 - val_accuracy: 0.8264 - lr: 1.0000e-05\n",
      "Epoch 51/300\n",
      "3997/3997 [==============================] - 135s 34ms/step - loss: 0.1945 - accuracy: 0.9338 - val_loss: 0.6388 - val_accuracy: 0.8252 - lr: 1.0000e-05\n",
      "Epoch 52/300\n",
      "3997/3997 [==============================] - 134s 34ms/step - loss: 0.2003 - accuracy: 0.9316 - val_loss: 0.6340 - val_accuracy: 0.8269 - lr: 1.0000e-05\n",
      "Epoch 53/300\n",
      "3997/3997 [==============================] - 134s 34ms/step - loss: 0.1973 - accuracy: 0.9319 - val_loss: 0.6366 - val_accuracy: 0.8258 - lr: 1.0000e-05\n",
      "Epoch 54/300\n",
      "3997/3997 [==============================] - 138s 34ms/step - loss: 0.1943 - accuracy: 0.9329 - val_loss: 0.6352 - val_accuracy: 0.8274 - lr: 1.0000e-05\n",
      "Epoch 55/300\n",
      "3997/3997 [==============================] - 134s 34ms/step - loss: 0.1971 - accuracy: 0.9321 - val_loss: 0.6377 - val_accuracy: 0.8260 - lr: 1.0000e-05\n",
      "Epoch 56/300\n",
      "3997/3997 [==============================] - 134s 34ms/step - loss: 0.1953 - accuracy: 0.9329 - val_loss: 0.6386 - val_accuracy: 0.8262 - lr: 1.0000e-05\n",
      "Epoch 57/300\n",
      "3997/3997 [==============================] - 138s 34ms/step - loss: 0.1970 - accuracy: 0.9318 - val_loss: 0.6440 - val_accuracy: 0.8251 - lr: 1.0000e-05\n",
      "Epoch 58/300\n",
      "3997/3997 [==============================] - 137s 34ms/step - loss: 0.1922 - accuracy: 0.9349 - val_loss: 0.6517 - val_accuracy: 0.8256 - lr: 1.0000e-05\n",
      "Epoch 59/300\n",
      "3997/3997 [==============================] - 137s 34ms/step - loss: 0.1958 - accuracy: 0.9327 - val_loss: 0.6398 - val_accuracy: 0.8274 - lr: 1.0000e-05\n",
      "Epoch 60/300\n",
      "3997/3997 [==============================] - 139s 35ms/step - loss: 0.1929 - accuracy: 0.9344 - val_loss: 0.6304 - val_accuracy: 0.8276 - lr: 1.0000e-05\n",
      "Epoch 61/300\n",
      "3997/3997 [==============================] - 135s 34ms/step - loss: 0.1966 - accuracy: 0.9331 - val_loss: 0.6362 - val_accuracy: 0.8284 - lr: 1.0000e-05\n",
      "Epoch 62/300\n",
      "3997/3997 [==============================] - 139s 35ms/step - loss: 0.1948 - accuracy: 0.9333 - val_loss: 0.6422 - val_accuracy: 0.8258 - lr: 1.0000e-05\n",
      "Epoch 63/300\n",
      "3997/3997 [==============================] - 136s 34ms/step - loss: 0.1957 - accuracy: 0.9335 - val_loss: 0.6408 - val_accuracy: 0.8288 - lr: 1.0000e-05\n",
      "Epoch 64/300\n",
      "3997/3997 [==============================] - 140s 35ms/step - loss: 0.1950 - accuracy: 0.9342 - val_loss: 0.6484 - val_accuracy: 0.8281 - lr: 1.0000e-05\n",
      "Epoch 65/300\n",
      "3997/3997 [==============================] - 140s 35ms/step - loss: 0.1918 - accuracy: 0.9349 - val_loss: 0.6420 - val_accuracy: 0.8265 - lr: 1.0000e-05\n",
      "Epoch 66/300\n",
      "3997/3997 [==============================] - 139s 35ms/step - loss: 0.1970 - accuracy: 0.9330 - val_loss: 0.6457 - val_accuracy: 0.8265 - lr: 1.0000e-05\n",
      "Epoch 67/300\n",
      "3997/3997 [==============================] - 138s 34ms/step - loss: 0.1937 - accuracy: 0.9332 - val_loss: 0.6421 - val_accuracy: 0.8281 - lr: 1.0000e-05\n",
      "Epoch 68/300\n",
      "3997/3997 [==============================] - 135s 34ms/step - loss: 0.1966 - accuracy: 0.9328 - val_loss: 0.6344 - val_accuracy: 0.8281 - lr: 1.0000e-05\n",
      "Epoch 69/300\n",
      "3997/3997 [==============================] - 136s 34ms/step - loss: 0.1909 - accuracy: 0.9352 - val_loss: 0.6415 - val_accuracy: 0.8257 - lr: 1.0000e-05\n",
      "Epoch 70/300\n",
      "3997/3997 [==============================] - 138s 35ms/step - loss: 0.1940 - accuracy: 0.9340 - val_loss: 0.6382 - val_accuracy: 0.8271 - lr: 1.0000e-05\n",
      "Epoch 71/300\n",
      "3997/3997 [==============================] - 138s 35ms/step - loss: 0.1943 - accuracy: 0.9346 - val_loss: 0.6427 - val_accuracy: 0.8252 - lr: 1.0000e-05\n",
      "Epoch 72/300\n",
      "3997/3997 [==============================] - 143s 36ms/step - loss: 0.1916 - accuracy: 0.9340 - val_loss: 0.6364 - val_accuracy: 0.8256 - lr: 1.0000e-05\n",
      "Epoch 73/300\n",
      "3997/3997 [==============================] - 142s 36ms/step - loss: 0.1928 - accuracy: 0.9340 - val_loss: 0.6475 - val_accuracy: 0.8276 - lr: 1.0000e-05\n",
      "Epoch 74/300\n",
      "3997/3997 [==============================] - 142s 35ms/step - loss: 0.1921 - accuracy: 0.9337 - val_loss: 0.6368 - val_accuracy: 0.8268 - lr: 1.0000e-05\n",
      "Epoch 75/300\n",
      "3997/3997 [==============================] - 142s 36ms/step - loss: 0.1929 - accuracy: 0.9334 - val_loss: 0.6415 - val_accuracy: 0.8277 - lr: 1.0000e-05\n",
      "Epoch 76/300\n",
      "3997/3997 [==============================] - 142s 36ms/step - loss: 0.1917 - accuracy: 0.9351 - val_loss: 0.6389 - val_accuracy: 0.8272 - lr: 1.0000e-05\n",
      "Epoch 77/300\n",
      "3997/3997 [==============================] - 146s 36ms/step - loss: 0.1914 - accuracy: 0.9338 - val_loss: 0.6368 - val_accuracy: 0.8271 - lr: 1.0000e-05\n",
      "Epoch 78/300\n",
      "3997/3997 [==============================] - 141s 35ms/step - loss: 0.1918 - accuracy: 0.9345 - val_loss: 0.6392 - val_accuracy: 0.8252 - lr: 1.0000e-05\n",
      "Epoch 79/300\n",
      "3997/3997 [==============================] - 141s 35ms/step - loss: 0.1976 - accuracy: 0.9334 - val_loss: 0.6414 - val_accuracy: 0.8269 - lr: 1.0000e-05\n",
      "Epoch 80/300\n",
      "3997/3997 [==============================] - 143s 36ms/step - loss: 0.1910 - accuracy: 0.9351 - val_loss: 0.6529 - val_accuracy: 0.8256 - lr: 1.0000e-05\n",
      "Epoch 81/300\n",
      "3997/3997 [==============================] - 143s 36ms/step - loss: 0.1929 - accuracy: 0.9335 - val_loss: 0.6411 - val_accuracy: 0.8281 - lr: 1.0000e-05\n",
      "Epoch 82/300\n",
      "3997/3997 [==============================] - 144s 36ms/step - loss: 0.1881 - accuracy: 0.9356 - val_loss: 0.6387 - val_accuracy: 0.8263 - lr: 1.0000e-05\n",
      "Epoch 83/300\n",
      "3997/3997 [==============================] - 141s 35ms/step - loss: 0.1890 - accuracy: 0.9355 - val_loss: 0.6478 - val_accuracy: 0.8253 - lr: 1.0000e-05\n",
      "Epoch 84/300\n",
      "3997/3997 [==============================] - 142s 36ms/step - loss: 0.1890 - accuracy: 0.9348 - val_loss: 0.6481 - val_accuracy: 0.8242 - lr: 1.0000e-05\n",
      "Epoch 85/300\n",
      "3997/3997 [==============================] - 142s 35ms/step - loss: 0.1926 - accuracy: 0.9343 - val_loss: 0.6414 - val_accuracy: 0.8262 - lr: 1.0000e-05\n",
      "Epoch 86/300\n",
      "3997/3997 [==============================] - 138s 35ms/step - loss: 0.1934 - accuracy: 0.9344 - val_loss: 0.6415 - val_accuracy: 0.8262 - lr: 1.0000e-05\n",
      "Epoch 87/300\n",
      "3997/3997 [==============================] - 141s 35ms/step - loss: 0.1913 - accuracy: 0.9350 - val_loss: 0.6381 - val_accuracy: 0.8269 - lr: 1.0000e-05\n",
      "Epoch 88/300\n",
      "3997/3997 [==============================] - 163s 41ms/step - loss: 0.1896 - accuracy: 0.9348 - val_loss: 0.6314 - val_accuracy: 0.8312 - lr: 1.0000e-05\n",
      "Epoch 89/300\n",
      "3997/3997 [==============================] - 140s 35ms/step - loss: 0.1911 - accuracy: 0.9357 - val_loss: 0.6433 - val_accuracy: 0.8276 - lr: 1.0000e-05\n",
      "Epoch 90/300\n",
      "3997/3997 [==============================] - 138s 35ms/step - loss: 0.1900 - accuracy: 0.9351 - val_loss: 0.6501 - val_accuracy: 0.8260 - lr: 1.0000e-05\n",
      "Epoch 91/300\n",
      "3997/3997 [==============================] - 138s 34ms/step - loss: 0.1860 - accuracy: 0.9368 - val_loss: 0.6324 - val_accuracy: 0.8293 - lr: 1.0000e-05\n",
      "Epoch 92/300\n",
      "3997/3997 [==============================] - 139s 35ms/step - loss: 0.1935 - accuracy: 0.9337 - val_loss: 0.6408 - val_accuracy: 0.8287 - lr: 1.0000e-05\n",
      "Epoch 93/300\n",
      "3997/3997 [==============================] - 140s 35ms/step - loss: 0.1862 - accuracy: 0.9364 - val_loss: 0.6453 - val_accuracy: 0.8265 - lr: 1.0000e-05\n",
      "Epoch 94/300\n",
      "3997/3997 [==============================] - 140s 35ms/step - loss: 0.1934 - accuracy: 0.9336 - val_loss: 0.6447 - val_accuracy: 0.8258 - lr: 1.0000e-05\n",
      "Epoch 95/300\n",
      "3997/3997 [==============================] - 142s 35ms/step - loss: 0.1918 - accuracy: 0.9345 - val_loss: 0.6369 - val_accuracy: 0.8273 - lr: 1.0000e-05\n",
      "Epoch 96/300\n",
      "3997/3997 [==============================] - 141s 35ms/step - loss: 0.1897 - accuracy: 0.9352 - val_loss: 0.6368 - val_accuracy: 0.8279 - lr: 1.0000e-05\n",
      "Epoch 97/300\n",
      "3997/3997 [==============================] - 140s 35ms/step - loss: 0.1926 - accuracy: 0.9339 - val_loss: 0.6463 - val_accuracy: 0.8273 - lr: 1.0000e-05\n",
      "Epoch 98/300\n",
      "3997/3997 [==============================] - 140s 35ms/step - loss: 0.1894 - accuracy: 0.9342 - val_loss: 0.6376 - val_accuracy: 0.8286 - lr: 1.0000e-05\n",
      "Epoch 99/300\n",
      "3997/3997 [==============================] - 139s 35ms/step - loss: 0.1878 - accuracy: 0.9358 - val_loss: 0.6339 - val_accuracy: 0.8278 - lr: 1.0000e-05\n",
      "Epoch 100/300\n",
      "3997/3997 [==============================] - 141s 35ms/step - loss: 0.1872 - accuracy: 0.9361 - val_loss: 0.6404 - val_accuracy: 0.8278 - lr: 1.0000e-05\n",
      "Epoch 101/300\n",
      "3997/3997 [==============================] - 141s 35ms/step - loss: 0.1858 - accuracy: 0.9362 - val_loss: 0.6425 - val_accuracy: 0.8260 - lr: 1.0000e-05\n",
      "Epoch 102/300\n",
      "3997/3997 [==============================] - 141s 35ms/step - loss: 0.1912 - accuracy: 0.9348 - val_loss: 0.6470 - val_accuracy: 0.8259 - lr: 1.0000e-05\n",
      "Epoch 103/300\n",
      "3997/3997 [==============================] - 145s 36ms/step - loss: 0.1873 - accuracy: 0.9353 - val_loss: 0.6365 - val_accuracy: 0.8267 - lr: 1.0000e-05\n",
      "Epoch 104/300\n",
      "3997/3997 [==============================] - 145s 36ms/step - loss: 0.1885 - accuracy: 0.9353 - val_loss: 0.6327 - val_accuracy: 0.8290 - lr: 1.0000e-05\n",
      "Epoch 105/300\n",
      "3997/3997 [==============================] - 142s 36ms/step - loss: 0.1884 - accuracy: 0.9355 - val_loss: 0.6376 - val_accuracy: 0.8267 - lr: 1.0000e-05\n",
      "Epoch 106/300\n",
      "3997/3997 [==============================] - 143s 36ms/step - loss: 0.1890 - accuracy: 0.9350 - val_loss: 0.6346 - val_accuracy: 0.8280 - lr: 1.0000e-05\n",
      "Epoch 107/300\n",
      "3997/3997 [==============================] - 142s 35ms/step - loss: 0.1852 - accuracy: 0.9376 - val_loss: 0.6416 - val_accuracy: 0.8291 - lr: 1.0000e-05\n",
      "Epoch 108/300\n",
      "3997/3997 [==============================] - 141s 35ms/step - loss: 0.1833 - accuracy: 0.9379 - val_loss: 0.6402 - val_accuracy: 0.8278 - lr: 1.0000e-05\n",
      "Epoch 109/300\n",
      "3997/3997 [==============================] - 141s 35ms/step - loss: 0.1857 - accuracy: 0.9365 - val_loss: 0.6385 - val_accuracy: 0.8285 - lr: 1.0000e-05\n",
      "Epoch 110/300\n",
      "3997/3997 [==============================] - 141s 35ms/step - loss: 0.1900 - accuracy: 0.9351 - val_loss: 0.6457 - val_accuracy: 0.8265 - lr: 1.0000e-05\n",
      "Epoch 111/300\n",
      "3997/3997 [==============================] - 140s 35ms/step - loss: 0.1891 - accuracy: 0.9353 - val_loss: 0.6415 - val_accuracy: 0.8274 - lr: 1.0000e-05\n",
      "Epoch 112/300\n",
      "3997/3997 [==============================] - 142s 36ms/step - loss: 0.1851 - accuracy: 0.9371 - val_loss: 0.6353 - val_accuracy: 0.8278 - lr: 1.0000e-05\n",
      "Epoch 113/300\n",
      "3997/3997 [==============================] - 141s 35ms/step - loss: 0.1898 - accuracy: 0.9356 - val_loss: 0.6470 - val_accuracy: 0.8263 - lr: 1.0000e-05\n",
      "Epoch 114/300\n",
      "3997/3997 [==============================] - 141s 35ms/step - loss: 0.1873 - accuracy: 0.9366 - val_loss: 0.6402 - val_accuracy: 0.8273 - lr: 1.0000e-05\n",
      "Epoch 115/300\n",
      "3997/3997 [==============================] - 142s 35ms/step - loss: 0.1865 - accuracy: 0.9368 - val_loss: 0.6455 - val_accuracy: 0.8278 - lr: 1.0000e-05\n",
      "Epoch 116/300\n",
      "3997/3997 [==============================] - 142s 36ms/step - loss: 0.1849 - accuracy: 0.9371 - val_loss: 0.6359 - val_accuracy: 0.8281 - lr: 1.0000e-05\n",
      "Epoch 117/300\n",
      "3997/3997 [==============================] - 142s 35ms/step - loss: 0.1835 - accuracy: 0.9368 - val_loss: 0.6426 - val_accuracy: 0.8261 - lr: 1.0000e-05\n",
      "Epoch 118/300\n",
      "3997/3997 [==============================] - 141s 35ms/step - loss: 0.1898 - accuracy: 0.9350 - val_loss: 0.6433 - val_accuracy: 0.8281 - lr: 1.0000e-05\n",
      "Epoch 119/300\n",
      "3997/3997 [==============================] - 141s 35ms/step - loss: 0.1868 - accuracy: 0.9371 - val_loss: 0.6561 - val_accuracy: 0.8278 - lr: 1.0000e-05\n",
      "Epoch 120/300\n",
      "3997/3997 [==============================] - 141s 35ms/step - loss: 0.1846 - accuracy: 0.9371 - val_loss: 0.6332 - val_accuracy: 0.8271 - lr: 1.0000e-05\n",
      "Epoch 121/300\n",
      "3997/3997 [==============================] - 140s 35ms/step - loss: 0.1878 - accuracy: 0.9370 - val_loss: 0.6394 - val_accuracy: 0.8292 - lr: 1.0000e-05\n",
      "Epoch 122/300\n",
      "3997/3997 [==============================] - 143s 36ms/step - loss: 0.1809 - accuracy: 0.9380 - val_loss: 0.6478 - val_accuracy: 0.8294 - lr: 1.0000e-05\n",
      "Epoch 123/300\n",
      "3997/3997 [==============================] - 142s 36ms/step - loss: 0.1817 - accuracy: 0.9374 - val_loss: 0.6357 - val_accuracy: 0.8291 - lr: 1.0000e-05\n",
      "Epoch 124/300\n",
      "3997/3997 [==============================] - 142s 36ms/step - loss: 0.1873 - accuracy: 0.9375 - val_loss: 0.6362 - val_accuracy: 0.8298 - lr: 1.0000e-05\n",
      "Epoch 125/300\n",
      "3997/3997 [==============================] - 140s 35ms/step - loss: 0.1820 - accuracy: 0.9380 - val_loss: 0.6350 - val_accuracy: 0.8294 - lr: 1.0000e-05\n",
      "Epoch 126/300\n",
      "3997/3997 [==============================] - 141s 35ms/step - loss: 0.1888 - accuracy: 0.9362 - val_loss: 0.6395 - val_accuracy: 0.8277 - lr: 1.0000e-05\n",
      "Epoch 127/300\n",
      "3997/3997 [==============================] - 141s 35ms/step - loss: 0.1829 - accuracy: 0.9380 - val_loss: 0.6420 - val_accuracy: 0.8293 - lr: 1.0000e-05\n",
      "Epoch 128/300\n",
      "3997/3997 [==============================] - 143s 36ms/step - loss: 0.1823 - accuracy: 0.9377 - val_loss: 0.6479 - val_accuracy: 0.8292 - lr: 1.0000e-05\n",
      "Epoch 129/300\n",
      "3997/3997 [==============================] - 141s 35ms/step - loss: 0.1842 - accuracy: 0.9372 - val_loss: 0.6477 - val_accuracy: 0.8288 - lr: 1.0000e-05\n",
      "Epoch 130/300\n",
      "3997/3997 [==============================] - 142s 35ms/step - loss: 0.1865 - accuracy: 0.9361 - val_loss: 0.6437 - val_accuracy: 0.8277 - lr: 1.0000e-05\n",
      "Epoch 131/300\n",
      "3997/3997 [==============================] - 141s 35ms/step - loss: 0.1838 - accuracy: 0.9361 - val_loss: 0.6358 - val_accuracy: 0.8288 - lr: 1.0000e-05\n",
      "Epoch 132/300\n",
      "3997/3997 [==============================] - 142s 35ms/step - loss: 0.1815 - accuracy: 0.9376 - val_loss: 0.6321 - val_accuracy: 0.8291 - lr: 1.0000e-05\n",
      "Epoch 133/300\n",
      "3997/3997 [==============================] - 141s 35ms/step - loss: 0.1826 - accuracy: 0.9371 - val_loss: 0.6443 - val_accuracy: 0.8282 - lr: 1.0000e-05\n",
      "Epoch 134/300\n",
      "3997/3997 [==============================] - 141s 35ms/step - loss: 0.1855 - accuracy: 0.9361 - val_loss: 0.6396 - val_accuracy: 0.8303 - lr: 1.0000e-05\n",
      "Epoch 135/300\n",
      "3997/3997 [==============================] - 141s 35ms/step - loss: 0.1821 - accuracy: 0.9377 - val_loss: 0.6329 - val_accuracy: 0.8295 - lr: 1.0000e-05\n",
      "Epoch 136/300\n",
      "3997/3997 [==============================] - 143s 36ms/step - loss: 0.1831 - accuracy: 0.9380 - val_loss: 0.6318 - val_accuracy: 0.8303 - lr: 1.0000e-05\n",
      "Epoch 137/300\n",
      "3997/3997 [==============================] - 142s 35ms/step - loss: 0.1833 - accuracy: 0.9367 - val_loss: 0.6447 - val_accuracy: 0.8283 - lr: 1.0000e-05\n",
      "Epoch 138/300\n",
      "3997/3997 [==============================] - 141s 35ms/step - loss: 0.1811 - accuracy: 0.9379 - val_loss: 0.6471 - val_accuracy: 0.8279 - lr: 1.0000e-05\n",
      "Epoch 139/300\n",
      "3997/3997 [==============================] - 140s 35ms/step - loss: 0.1835 - accuracy: 0.9371 - val_loss: 0.6361 - val_accuracy: 0.8287 - lr: 1.0000e-05\n",
      "Epoch 140/300\n",
      "3997/3997 [==============================] - 142s 36ms/step - loss: 0.1812 - accuracy: 0.9381 - val_loss: 0.6422 - val_accuracy: 0.8287 - lr: 1.0000e-05\n",
      "Epoch 141/300\n",
      "3997/3997 [==============================] - 141s 35ms/step - loss: 0.1800 - accuracy: 0.9376 - val_loss: 0.6507 - val_accuracy: 0.8290 - lr: 1.0000e-05\n",
      "Epoch 142/300\n",
      "3997/3997 [==============================] - 141s 35ms/step - loss: 0.1865 - accuracy: 0.9375 - val_loss: 0.6413 - val_accuracy: 0.8292 - lr: 1.0000e-05\n",
      "Epoch 143/300\n",
      "3997/3997 [==============================] - 141s 35ms/step - loss: 0.1813 - accuracy: 0.9370 - val_loss: 0.6364 - val_accuracy: 0.8305 - lr: 1.0000e-05\n",
      "Epoch 144/300\n",
      "3997/3997 [==============================] - 143s 36ms/step - loss: 0.1840 - accuracy: 0.9365 - val_loss: 0.6365 - val_accuracy: 0.8299 - lr: 1.0000e-05\n",
      "Epoch 145/300\n",
      "3997/3997 [==============================] - 141s 35ms/step - loss: 0.1833 - accuracy: 0.9383 - val_loss: 0.6414 - val_accuracy: 0.8298 - lr: 1.0000e-05\n",
      "Epoch 146/300\n",
      "3997/3997 [==============================] - 141s 35ms/step - loss: 0.1816 - accuracy: 0.9381 - val_loss: 0.6396 - val_accuracy: 0.8301 - lr: 1.0000e-05\n",
      "Epoch 147/300\n",
      "3997/3997 [==============================] - 140s 35ms/step - loss: 0.1815 - accuracy: 0.9373 - val_loss: 0.6418 - val_accuracy: 0.8293 - lr: 1.0000e-05\n",
      "Epoch 148/300\n",
      "3997/3997 [==============================] - 139s 35ms/step - loss: 0.1800 - accuracy: 0.9384 - val_loss: 0.6387 - val_accuracy: 0.8301 - lr: 1.0000e-05\n",
      "Epoch 149/300\n",
      "3997/3997 [==============================] - 139s 35ms/step - loss: 0.1826 - accuracy: 0.9377 - val_loss: 0.6499 - val_accuracy: 0.8277 - lr: 1.0000e-05\n",
      "Epoch 150/300\n",
      "3997/3997 [==============================] - 141s 35ms/step - loss: 0.1778 - accuracy: 0.9386 - val_loss: 0.6406 - val_accuracy: 0.8288 - lr: 1.0000e-05\n",
      "Epoch 151/300\n",
      "3997/3997 [==============================] - 141s 35ms/step - loss: 0.1821 - accuracy: 0.9391 - val_loss: 0.6491 - val_accuracy: 0.8302 - lr: 1.0000e-05\n",
      "Epoch 152/300\n",
      "3997/3997 [==============================] - 140s 35ms/step - loss: 0.1803 - accuracy: 0.9388 - val_loss: 0.6404 - val_accuracy: 0.8283 - lr: 1.0000e-05\n",
      "Epoch 153/300\n",
      "3997/3997 [==============================] - 140s 35ms/step - loss: 0.1792 - accuracy: 0.9402 - val_loss: 0.6449 - val_accuracy: 0.8278 - lr: 1.0000e-05\n",
      "Epoch 154/300\n",
      "3997/3997 [==============================] - 142s 35ms/step - loss: 0.1801 - accuracy: 0.9398 - val_loss: 0.6457 - val_accuracy: 0.8291 - lr: 1.0000e-05\n",
      "Epoch 155/300\n",
      "3997/3997 [==============================] - 141s 35ms/step - loss: 0.1829 - accuracy: 0.9379 - val_loss: 0.6402 - val_accuracy: 0.8286 - lr: 1.0000e-05\n",
      "Epoch 156/300\n",
      "3997/3997 [==============================] - 141s 35ms/step - loss: 0.1797 - accuracy: 0.9377 - val_loss: 0.6445 - val_accuracy: 0.8293 - lr: 1.0000e-05\n",
      "Epoch 157/300\n",
      "3997/3997 [==============================] - 142s 35ms/step - loss: 0.1818 - accuracy: 0.9385 - val_loss: 0.6362 - val_accuracy: 0.8303 - lr: 1.0000e-05\n",
      "Epoch 158/300\n",
      "3997/3997 [==============================] - 142s 35ms/step - loss: 0.1822 - accuracy: 0.9380 - val_loss: 0.6439 - val_accuracy: 0.8297 - lr: 1.0000e-05\n",
      "Epoch 159/300\n",
      "3997/3997 [==============================] - 142s 36ms/step - loss: 0.1752 - accuracy: 0.9399 - val_loss: 0.6393 - val_accuracy: 0.8309 - lr: 1.0000e-05\n",
      "Epoch 160/300\n",
      "3997/3997 [==============================] - 141s 35ms/step - loss: 0.1756 - accuracy: 0.9395 - val_loss: 0.6355 - val_accuracy: 0.8313 - lr: 1.0000e-05\n",
      "Epoch 161/300\n",
      "3997/3997 [==============================] - 140s 35ms/step - loss: 0.1811 - accuracy: 0.9385 - val_loss: 0.6394 - val_accuracy: 0.8314 - lr: 1.0000e-05\n",
      "Epoch 162/300\n",
      "3997/3997 [==============================] - 143s 36ms/step - loss: 0.1772 - accuracy: 0.9399 - val_loss: 0.6449 - val_accuracy: 0.8299 - lr: 1.0000e-05\n",
      "Epoch 163/300\n",
      "3997/3997 [==============================] - 141s 35ms/step - loss: 0.1786 - accuracy: 0.9389 - val_loss: 0.6381 - val_accuracy: 0.8306 - lr: 1.0000e-05\n",
      "Epoch 164/300\n",
      "3997/3997 [==============================] - 141s 35ms/step - loss: 0.1815 - accuracy: 0.9391 - val_loss: 0.6417 - val_accuracy: 0.8303 - lr: 1.0000e-05\n",
      "Epoch 165/300\n",
      "3997/3997 [==============================] - 143s 36ms/step - loss: 0.1800 - accuracy: 0.9373 - val_loss: 0.6408 - val_accuracy: 0.8311 - lr: 1.0000e-05\n",
      "Epoch 166/300\n",
      "3997/3997 [==============================] - 146s 37ms/step - loss: 0.1787 - accuracy: 0.9392 - val_loss: 0.6492 - val_accuracy: 0.8292 - lr: 1.0000e-05\n",
      "Epoch 167/300\n",
      "3997/3997 [==============================] - 142s 35ms/step - loss: 0.1747 - accuracy: 0.9391 - val_loss: 0.6396 - val_accuracy: 0.8308 - lr: 1.0000e-05\n",
      "Epoch 168/300\n",
      "3997/3997 [==============================] - 141s 35ms/step - loss: 0.1783 - accuracy: 0.9395 - val_loss: 0.6439 - val_accuracy: 0.8288 - lr: 1.0000e-05\n",
      "Epoch 169/300\n",
      "3997/3997 [==============================] - 142s 36ms/step - loss: 0.1777 - accuracy: 0.9390 - val_loss: 0.6432 - val_accuracy: 0.8316 - lr: 1.0000e-05\n",
      "Epoch 170/300\n",
      "3997/3997 [==============================] - 142s 36ms/step - loss: 0.1780 - accuracy: 0.9391 - val_loss: 0.6398 - val_accuracy: 0.8293 - lr: 1.0000e-05\n",
      "Epoch 171/300\n",
      "3997/3997 [==============================] - 143s 36ms/step - loss: 0.1809 - accuracy: 0.9386 - val_loss: 0.6447 - val_accuracy: 0.8308 - lr: 1.0000e-05\n",
      "Epoch 172/300\n",
      "3997/3997 [==============================] - 144s 36ms/step - loss: 0.1749 - accuracy: 0.9405 - val_loss: 0.6459 - val_accuracy: 0.8303 - lr: 1.0000e-05\n",
      "Epoch 173/300\n",
      "3997/3997 [==============================] - 142s 36ms/step - loss: 0.1819 - accuracy: 0.9380 - val_loss: 0.6454 - val_accuracy: 0.8303 - lr: 1.0000e-05\n",
      "Epoch 174/300\n",
      "3997/3997 [==============================] - 142s 36ms/step - loss: 0.1793 - accuracy: 0.9384 - val_loss: 0.6466 - val_accuracy: 0.8297 - lr: 1.0000e-05\n",
      "Epoch 175/300\n",
      "3997/3997 [==============================] - 143s 36ms/step - loss: 0.1796 - accuracy: 0.9378 - val_loss: 0.6498 - val_accuracy: 0.8286 - lr: 1.0000e-05\n",
      "Epoch 176/300\n",
      "3997/3997 [==============================] - 144s 36ms/step - loss: 0.1770 - accuracy: 0.9401 - val_loss: 0.6388 - val_accuracy: 0.8318 - lr: 1.0000e-05\n",
      "Epoch 177/300\n",
      "3997/3997 [==============================] - 144s 36ms/step - loss: 0.1754 - accuracy: 0.9409 - val_loss: 0.6418 - val_accuracy: 0.8299 - lr: 1.0000e-05\n",
      "Epoch 178/300\n",
      "3997/3997 [==============================] - 142s 35ms/step - loss: 0.1774 - accuracy: 0.9390 - val_loss: 0.6505 - val_accuracy: 0.8288 - lr: 1.0000e-05\n",
      "Epoch 179/300\n",
      "3997/3997 [==============================] - 143s 36ms/step - loss: 0.1775 - accuracy: 0.9396 - val_loss: 0.6429 - val_accuracy: 0.8311 - lr: 1.0000e-05\n",
      "Epoch 180/300\n",
      "3997/3997 [==============================] - 142s 36ms/step - loss: 0.1752 - accuracy: 0.9404 - val_loss: 0.6315 - val_accuracy: 0.8326 - lr: 1.0000e-05\n",
      "Epoch 181/300\n",
      "3997/3997 [==============================] - 142s 36ms/step - loss: 0.1768 - accuracy: 0.9408 - val_loss: 0.6486 - val_accuracy: 0.8305 - lr: 1.0000e-05\n",
      "Epoch 182/300\n",
      "3997/3997 [==============================] - 143s 36ms/step - loss: 0.1759 - accuracy: 0.9399 - val_loss: 0.6361 - val_accuracy: 0.8323 - lr: 1.0000e-05\n",
      "Epoch 183/300\n",
      "3997/3997 [==============================] - 143s 36ms/step - loss: 0.1773 - accuracy: 0.9395 - val_loss: 0.6458 - val_accuracy: 0.8305 - lr: 1.0000e-05\n",
      "Epoch 184/300\n",
      "3997/3997 [==============================] - 142s 36ms/step - loss: 0.1740 - accuracy: 0.9408 - val_loss: 0.6459 - val_accuracy: 0.8288 - lr: 1.0000e-05\n",
      "Epoch 185/300\n",
      "3997/3997 [==============================] - 142s 35ms/step - loss: 0.1770 - accuracy: 0.9392 - val_loss: 0.6471 - val_accuracy: 0.8298 - lr: 1.0000e-05\n",
      "Epoch 186/300\n",
      "3997/3997 [==============================] - 142s 36ms/step - loss: 0.1705 - accuracy: 0.9415 - val_loss: 0.6418 - val_accuracy: 0.8324 - lr: 1.0000e-05\n",
      "Epoch 187/300\n",
      "3997/3997 [==============================] - 142s 36ms/step - loss: 0.1757 - accuracy: 0.9398 - val_loss: 0.6480 - val_accuracy: 0.8287 - lr: 1.0000e-05\n",
      "Epoch 188/300\n",
      "3997/3997 [==============================] - 142s 36ms/step - loss: 0.1749 - accuracy: 0.9408 - val_loss: 0.6391 - val_accuracy: 0.8304 - lr: 1.0000e-05\n",
      "Epoch 189/300\n",
      "3997/3997 [==============================] - 152s 38ms/step - loss: 0.1735 - accuracy: 0.9398 - val_loss: 0.6385 - val_accuracy: 0.8296 - lr: 1.0000e-05\n",
      "Epoch 190/300\n",
      "3997/3997 [==============================] - 148s 37ms/step - loss: 0.1764 - accuracy: 0.9396 - val_loss: 0.6456 - val_accuracy: 0.8303 - lr: 1.0000e-05\n",
      "Epoch 191/300\n",
      "3997/3997 [==============================] - 147s 37ms/step - loss: 0.1781 - accuracy: 0.9411 - val_loss: 0.6400 - val_accuracy: 0.8323 - lr: 1.0000e-05\n",
      "Epoch 192/300\n",
      "3997/3997 [==============================] - 148s 37ms/step - loss: 0.1768 - accuracy: 0.9408 - val_loss: 0.6518 - val_accuracy: 0.8294 - lr: 1.0000e-05\n",
      "Epoch 193/300\n",
      "3997/3997 [==============================] - 148s 37ms/step - loss: 0.1776 - accuracy: 0.9398 - val_loss: 0.6488 - val_accuracy: 0.8288 - lr: 1.0000e-05\n",
      "Epoch 194/300\n",
      "3997/3997 [==============================] - 143s 36ms/step - loss: 0.1795 - accuracy: 0.9395 - val_loss: 0.6478 - val_accuracy: 0.8303 - lr: 1.0000e-05\n",
      "Epoch 195/300\n",
      "3997/3997 [==============================] - 143s 36ms/step - loss: 0.1789 - accuracy: 0.9390 - val_loss: 0.6448 - val_accuracy: 0.8303 - lr: 1.0000e-05\n",
      "Epoch 196/300\n",
      "3997/3997 [==============================] - 143s 36ms/step - loss: 0.1749 - accuracy: 0.9404 - val_loss: 0.6372 - val_accuracy: 0.8307 - lr: 1.0000e-05\n",
      "Epoch 197/300\n",
      "3997/3997 [==============================] - 142s 36ms/step - loss: 0.1756 - accuracy: 0.9400 - val_loss: 0.6478 - val_accuracy: 0.8313 - lr: 1.0000e-05\n",
      "Epoch 198/300\n",
      "3997/3997 [==============================] - 143s 36ms/step - loss: 0.1724 - accuracy: 0.9415 - val_loss: 0.6430 - val_accuracy: 0.8316 - lr: 1.0000e-05\n",
      "Epoch 199/300\n",
      "3997/3997 [==============================] - 143s 36ms/step - loss: 0.1735 - accuracy: 0.9405 - val_loss: 0.6391 - val_accuracy: 0.8328 - lr: 1.0000e-05\n",
      "Epoch 200/300\n",
      "3997/3997 [==============================] - 143s 36ms/step - loss: 0.1746 - accuracy: 0.9407 - val_loss: 0.6437 - val_accuracy: 0.8333 - lr: 1.0000e-05\n",
      "Epoch 201/300\n",
      "3997/3997 [==============================] - 142s 36ms/step - loss: 0.1720 - accuracy: 0.9410 - val_loss: 0.6367 - val_accuracy: 0.8326 - lr: 1.0000e-05\n",
      "Epoch 202/300\n",
      "3997/3997 [==============================] - 142s 36ms/step - loss: 0.1717 - accuracy: 0.9408 - val_loss: 0.6384 - val_accuracy: 0.8328 - lr: 1.0000e-05\n",
      "Epoch 203/300\n",
      "3997/3997 [==============================] - 143s 36ms/step - loss: 0.1752 - accuracy: 0.9403 - val_loss: 0.6481 - val_accuracy: 0.8303 - lr: 1.0000e-05\n",
      "Epoch 204/300\n",
      "3997/3997 [==============================] - 141s 35ms/step - loss: 0.1760 - accuracy: 0.9393 - val_loss: 0.6399 - val_accuracy: 0.8310 - lr: 1.0000e-05\n",
      "Epoch 205/300\n",
      "3997/3997 [==============================] - 142s 35ms/step - loss: 0.1731 - accuracy: 0.9404 - val_loss: 0.6402 - val_accuracy: 0.8331 - lr: 1.0000e-05\n",
      "Epoch 206/300\n",
      "3997/3997 [==============================] - 152s 38ms/step - loss: 0.1735 - accuracy: 0.9407 - val_loss: 0.6379 - val_accuracy: 0.8317 - lr: 1.0000e-05\n",
      "Epoch 207/300\n",
      "3997/3997 [==============================] - 149s 37ms/step - loss: 0.1755 - accuracy: 0.9409 - val_loss: 0.6422 - val_accuracy: 0.8318 - lr: 1.0000e-05\n",
      "Epoch 208/300\n",
      "3997/3997 [==============================] - 142s 36ms/step - loss: 0.1751 - accuracy: 0.9404 - val_loss: 0.6398 - val_accuracy: 0.8323 - lr: 1.0000e-05\n",
      "Epoch 209/300\n",
      "3997/3997 [==============================] - 142s 35ms/step - loss: 0.1769 - accuracy: 0.9397 - val_loss: 0.6417 - val_accuracy: 0.8321 - lr: 1.0000e-05\n",
      "Epoch 210/300\n",
      "3997/3997 [==============================] - 143s 36ms/step - loss: 0.1723 - accuracy: 0.9417 - val_loss: 0.6429 - val_accuracy: 0.8323 - lr: 1.0000e-05\n",
      "Epoch 211/300\n",
      "3997/3997 [==============================] - 142s 35ms/step - loss: 0.1731 - accuracy: 0.9407 - val_loss: 0.6447 - val_accuracy: 0.8323 - lr: 1.0000e-05\n",
      "Epoch 212/300\n",
      "3997/3997 [==============================] - 140s 35ms/step - loss: 0.1726 - accuracy: 0.9410 - val_loss: 0.6453 - val_accuracy: 0.8316 - lr: 1.0000e-05\n",
      "Epoch 213/300\n",
      "3997/3997 [==============================] - 140s 35ms/step - loss: 0.1731 - accuracy: 0.9403 - val_loss: 0.6406 - val_accuracy: 0.8331 - lr: 1.0000e-05\n",
      "Epoch 214/300\n",
      "3997/3997 [==============================] - 142s 36ms/step - loss: 0.1743 - accuracy: 0.9407 - val_loss: 0.6329 - val_accuracy: 0.8332 - lr: 1.0000e-05\n",
      "Epoch 215/300\n",
      "3997/3997 [==============================] - 142s 36ms/step - loss: 0.1723 - accuracy: 0.9415 - val_loss: 0.6434 - val_accuracy: 0.8318 - lr: 1.0000e-05\n",
      "Epoch 216/300\n",
      "3997/3997 [==============================] - 140s 35ms/step - loss: 0.1767 - accuracy: 0.9397 - val_loss: 0.6451 - val_accuracy: 0.8332 - lr: 1.0000e-05\n",
      "Epoch 217/300\n",
      "3997/3997 [==============================] - 145s 36ms/step - loss: 0.1727 - accuracy: 0.9408 - val_loss: 0.6380 - val_accuracy: 0.8323 - lr: 1.0000e-05\n",
      "Epoch 218/300\n",
      "3997/3997 [==============================] - 149s 37ms/step - loss: 0.1686 - accuracy: 0.9431 - val_loss: 0.6510 - val_accuracy: 0.8311 - lr: 1.0000e-05\n",
      "Epoch 219/300\n",
      "3997/3997 [==============================] - 146s 36ms/step - loss: 0.1721 - accuracy: 0.9414 - val_loss: 0.6463 - val_accuracy: 0.8311 - lr: 1.0000e-05\n",
      "Epoch 220/300\n",
      "3997/3997 [==============================] - 144s 36ms/step - loss: 0.1766 - accuracy: 0.9401 - val_loss: 0.6364 - val_accuracy: 0.8315 - lr: 1.0000e-05\n",
      "Epoch 221/300\n",
      "3997/3997 [==============================] - 140s 35ms/step - loss: 0.1723 - accuracy: 0.9410 - val_loss: 0.6436 - val_accuracy: 0.8313 - lr: 1.0000e-05\n",
      "Epoch 222/300\n",
      "3997/3997 [==============================] - 140s 35ms/step - loss: 0.1759 - accuracy: 0.9407 - val_loss: 0.6387 - val_accuracy: 0.8318 - lr: 1.0000e-05\n",
      "Epoch 223/300\n",
      "3997/3997 [==============================] - 140s 35ms/step - loss: 0.1731 - accuracy: 0.9409 - val_loss: 0.6375 - val_accuracy: 0.8328 - lr: 1.0000e-05\n",
      "Epoch 224/300\n",
      "3997/3997 [==============================] - 141s 35ms/step - loss: 0.1701 - accuracy: 0.9418 - val_loss: 0.6334 - val_accuracy: 0.8328 - lr: 1.0000e-05\n",
      "Epoch 225/300\n",
      "3997/3997 [==============================] - 147s 37ms/step - loss: 0.1704 - accuracy: 0.9420 - val_loss: 0.6299 - val_accuracy: 0.8345 - lr: 1.0000e-05\n",
      "Epoch 226/300\n",
      "3997/3997 [==============================] - 144s 36ms/step - loss: 0.1691 - accuracy: 0.9433 - val_loss: 0.6449 - val_accuracy: 0.8337 - lr: 1.0000e-05\n",
      "Epoch 227/300\n",
      "3997/3997 [==============================] - 143s 36ms/step - loss: 0.1709 - accuracy: 0.9419 - val_loss: 0.6415 - val_accuracy: 0.8313 - lr: 1.0000e-05\n",
      "Epoch 228/300\n",
      "3997/3997 [==============================] - 140s 35ms/step - loss: 0.1677 - accuracy: 0.9432 - val_loss: 0.6439 - val_accuracy: 0.8323 - lr: 1.0000e-05\n",
      "Epoch 229/300\n",
      "3997/3997 [==============================] - 141s 35ms/step - loss: 0.1716 - accuracy: 0.9411 - val_loss: 0.6432 - val_accuracy: 0.8315 - lr: 1.0000e-05\n",
      "Epoch 230/300\n",
      "3997/3997 [==============================] - 142s 35ms/step - loss: 0.1721 - accuracy: 0.9413 - val_loss: 0.6467 - val_accuracy: 0.8307 - lr: 1.0000e-05\n",
      "Epoch 231/300\n",
      "3997/3997 [==============================] - 140s 35ms/step - loss: 0.1717 - accuracy: 0.9421 - val_loss: 0.6506 - val_accuracy: 0.8299 - lr: 1.0000e-05\n",
      "Epoch 232/300\n",
      "3997/3997 [==============================] - 140s 35ms/step - loss: 0.1711 - accuracy: 0.9414 - val_loss: 0.6435 - val_accuracy: 0.8303 - lr: 1.0000e-05\n",
      "Epoch 233/300\n",
      "3997/3997 [==============================] - 141s 35ms/step - loss: 0.1739 - accuracy: 0.9404 - val_loss: 0.6418 - val_accuracy: 0.8329 - lr: 1.0000e-05\n",
      "Epoch 234/300\n",
      "3997/3997 [==============================] - 145s 36ms/step - loss: 0.1705 - accuracy: 0.9419 - val_loss: 0.6447 - val_accuracy: 0.8313 - lr: 1.0000e-05\n",
      "Epoch 235/300\n",
      "3997/3997 [==============================] - 148s 37ms/step - loss: 0.1713 - accuracy: 0.9423 - val_loss: 0.6506 - val_accuracy: 0.8302 - lr: 1.0000e-05\n",
      "Epoch 236/300\n",
      "3997/3997 [==============================] - 150s 37ms/step - loss: 0.1699 - accuracy: 0.9417 - val_loss: 0.6465 - val_accuracy: 0.8303 - lr: 1.0000e-05\n",
      "Epoch 237/300\n",
      "3997/3997 [==============================] - 147s 37ms/step - loss: 0.1671 - accuracy: 0.9431 - val_loss: 0.6398 - val_accuracy: 0.8308 - lr: 1.0000e-05\n",
      "Epoch 238/300\n",
      "3997/3997 [==============================] - 146s 36ms/step - loss: 0.1663 - accuracy: 0.9423 - val_loss: 0.6454 - val_accuracy: 0.8302 - lr: 1.0000e-05\n",
      "Epoch 239/300\n",
      "3997/3997 [==============================] - 142s 35ms/step - loss: 0.1698 - accuracy: 0.9420 - val_loss: 0.6485 - val_accuracy: 0.8306 - lr: 1.0000e-05\n",
      "Epoch 240/300\n",
      "3997/3997 [==============================] - 141s 35ms/step - loss: 0.1733 - accuracy: 0.9408 - val_loss: 0.6411 - val_accuracy: 0.8324 - lr: 1.0000e-05\n",
      "Epoch 241/300\n",
      "3997/3997 [==============================] - 140s 35ms/step - loss: 0.1703 - accuracy: 0.9423 - val_loss: 0.6489 - val_accuracy: 0.8310 - lr: 1.0000e-05\n",
      "Epoch 242/300\n",
      "3997/3997 [==============================] - 142s 36ms/step - loss: 0.1641 - accuracy: 0.9435 - val_loss: 0.6522 - val_accuracy: 0.8305 - lr: 1.0000e-05\n",
      "Epoch 243/300\n",
      "3997/3997 [==============================] - 143s 36ms/step - loss: 0.1686 - accuracy: 0.9434 - val_loss: 0.6533 - val_accuracy: 0.8297 - lr: 1.0000e-05\n",
      "Epoch 244/300\n",
      "3997/3997 [==============================] - 140s 35ms/step - loss: 0.1672 - accuracy: 0.9425 - val_loss: 0.6487 - val_accuracy: 0.8301 - lr: 1.0000e-05\n",
      "Epoch 245/300\n",
      "3997/3997 [==============================] - 141s 35ms/step - loss: 0.1702 - accuracy: 0.9418 - val_loss: 0.6494 - val_accuracy: 0.8302 - lr: 1.0000e-05\n",
      "Epoch 246/300\n",
      "3997/3997 [==============================] - 144s 36ms/step - loss: 0.1680 - accuracy: 0.9427 - val_loss: 0.6456 - val_accuracy: 0.8307 - lr: 1.0000e-05\n",
      "Epoch 247/300\n",
      "3997/3997 [==============================] - 146s 37ms/step - loss: 0.1705 - accuracy: 0.9417 - val_loss: 0.6529 - val_accuracy: 0.8296 - lr: 1.0000e-05\n",
      "Epoch 248/300\n",
      "3997/3997 [==============================] - 140s 35ms/step - loss: 0.1687 - accuracy: 0.9424 - val_loss: 0.6421 - val_accuracy: 0.8308 - lr: 1.0000e-05\n",
      "Epoch 249/300\n",
      "3997/3997 [==============================] - 139s 35ms/step - loss: 0.1680 - accuracy: 0.9423 - val_loss: 0.6441 - val_accuracy: 0.8313 - lr: 1.0000e-05\n",
      "Epoch 250/300\n",
      "3997/3997 [==============================] - 140s 35ms/step - loss: 0.1646 - accuracy: 0.9441 - val_loss: 0.6421 - val_accuracy: 0.8310 - lr: 1.0000e-05\n",
      "Epoch 251/300\n",
      "3997/3997 [==============================] - 141s 35ms/step - loss: 0.1684 - accuracy: 0.9436 - val_loss: 0.6590 - val_accuracy: 0.8276 - lr: 1.0000e-05\n",
      "Epoch 252/300\n",
      "3997/3997 [==============================] - 139s 35ms/step - loss: 0.1708 - accuracy: 0.9421 - val_loss: 0.6476 - val_accuracy: 0.8304 - lr: 1.0000e-05\n",
      "Epoch 253/300\n",
      "3997/3997 [==============================] - 142s 36ms/step - loss: 0.1692 - accuracy: 0.9427 - val_loss: 0.6532 - val_accuracy: 0.8303 - lr: 1.0000e-05\n",
      "Epoch 254/300\n",
      "3997/3997 [==============================] - 152s 38ms/step - loss: 0.1718 - accuracy: 0.9416 - val_loss: 0.6516 - val_accuracy: 0.8294 - lr: 1.0000e-05\n",
      "Epoch 255/300\n",
      "3997/3997 [==============================] - 151s 38ms/step - loss: 0.1646 - accuracy: 0.9433 - val_loss: 0.6430 - val_accuracy: 0.8313 - lr: 1.0000e-05\n",
      "Epoch 256/300\n",
      "3997/3997 [==============================] - 147s 37ms/step - loss: 0.1708 - accuracy: 0.9422 - val_loss: 0.6441 - val_accuracy: 0.8318 - lr: 1.0000e-05\n",
      "Epoch 257/300\n",
      "3997/3997 [==============================] - 147s 37ms/step - loss: 0.1671 - accuracy: 0.9419 - val_loss: 0.6406 - val_accuracy: 0.8311 - lr: 1.0000e-05\n",
      "Epoch 258/300\n",
      "3997/3997 [==============================] - 146s 37ms/step - loss: 0.1669 - accuracy: 0.9423 - val_loss: 0.6368 - val_accuracy: 0.8343 - lr: 1.0000e-05\n",
      "Epoch 259/300\n",
      "3997/3997 [==============================] - 147s 37ms/step - loss: 0.1662 - accuracy: 0.9439 - val_loss: 0.6431 - val_accuracy: 0.8313 - lr: 1.0000e-05\n",
      "Epoch 260/300\n",
      "3997/3997 [==============================] - 148s 37ms/step - loss: 0.1686 - accuracy: 0.9420 - val_loss: 0.6405 - val_accuracy: 0.8330 - lr: 1.0000e-05\n",
      "Epoch 261/300\n",
      "3997/3997 [==============================] - 144s 36ms/step - loss: 0.1669 - accuracy: 0.9434 - val_loss: 0.6459 - val_accuracy: 0.8313 - lr: 1.0000e-05\n",
      "Epoch 262/300\n",
      "3997/3997 [==============================] - 143s 36ms/step - loss: 0.1658 - accuracy: 0.9432 - val_loss: 0.6440 - val_accuracy: 0.8318 - lr: 1.0000e-05\n",
      "Epoch 263/300\n",
      "3997/3997 [==============================] - 144s 36ms/step - loss: 0.1676 - accuracy: 0.9425 - val_loss: 0.6406 - val_accuracy: 0.8334 - lr: 1.0000e-05\n",
      "Epoch 264/300\n",
      "3997/3997 [==============================] - 147s 37ms/step - loss: 0.1689 - accuracy: 0.9428 - val_loss: 0.6433 - val_accuracy: 0.8340 - lr: 1.0000e-05\n",
      "Epoch 265/300\n",
      "3997/3997 [==============================] - 146s 37ms/step - loss: 0.1644 - accuracy: 0.9436 - val_loss: 0.6519 - val_accuracy: 0.8313 - lr: 1.0000e-05\n",
      "Epoch 266/300\n",
      "3997/3997 [==============================] - 145s 36ms/step - loss: 0.1700 - accuracy: 0.9417 - val_loss: 0.6439 - val_accuracy: 0.8315 - lr: 1.0000e-05\n",
      "Epoch 267/300\n",
      "3997/3997 [==============================] - 146s 37ms/step - loss: 0.1637 - accuracy: 0.9440 - val_loss: 0.6586 - val_accuracy: 0.8299 - lr: 1.0000e-05\n",
      "Epoch 268/300\n",
      "3997/3997 [==============================] - 143s 36ms/step - loss: 0.1678 - accuracy: 0.9440 - val_loss: 0.6496 - val_accuracy: 0.8308 - lr: 1.0000e-05\n",
      "Epoch 269/300\n",
      "3997/3997 [==============================] - 144s 36ms/step - loss: 0.1718 - accuracy: 0.9421 - val_loss: 0.6470 - val_accuracy: 0.8304 - lr: 1.0000e-05\n",
      "Epoch 270/300\n",
      "3997/3997 [==============================] - 147s 37ms/step - loss: 0.1673 - accuracy: 0.9426 - val_loss: 0.6557 - val_accuracy: 0.8312 - lr: 1.0000e-05\n",
      "Epoch 271/300\n",
      "3997/3997 [==============================] - 149s 37ms/step - loss: 0.1675 - accuracy: 0.9432 - val_loss: 0.6379 - val_accuracy: 0.8327 - lr: 1.0000e-05\n",
      "Epoch 272/300\n",
      "3997/3997 [==============================] - 144s 36ms/step - loss: 0.1634 - accuracy: 0.9438 - val_loss: 0.6521 - val_accuracy: 0.8315 - lr: 1.0000e-05\n",
      "Epoch 273/300\n",
      "3997/3997 [==============================] - 141s 35ms/step - loss: 0.1672 - accuracy: 0.9432 - val_loss: 0.6476 - val_accuracy: 0.8315 - lr: 1.0000e-05\n",
      "Epoch 274/300\n",
      "3997/3997 [==============================] - 142s 36ms/step - loss: 0.1661 - accuracy: 0.9438 - val_loss: 0.6451 - val_accuracy: 0.8312 - lr: 1.0000e-05\n",
      "Epoch 275/300\n",
      "3997/3997 [==============================] - 143s 36ms/step - loss: 0.1661 - accuracy: 0.9425 - val_loss: 0.6404 - val_accuracy: 0.8325 - lr: 1.0000e-05\n",
      "Epoch 276/300\n",
      "3997/3997 [==============================] - 143s 36ms/step - loss: 0.1650 - accuracy: 0.9439 - val_loss: 0.6398 - val_accuracy: 0.8332 - lr: 1.0000e-05\n",
      "Epoch 277/300\n",
      "3997/3997 [==============================] - 140s 35ms/step - loss: 0.1627 - accuracy: 0.9448 - val_loss: 0.6454 - val_accuracy: 0.8314 - lr: 1.0000e-05\n",
      "Epoch 278/300\n",
      "3997/3997 [==============================] - 142s 36ms/step - loss: 0.1648 - accuracy: 0.9434 - val_loss: 0.6544 - val_accuracy: 0.8293 - lr: 1.0000e-05\n",
      "Epoch 279/300\n",
      "3997/3997 [==============================] - 143s 36ms/step - loss: 0.1646 - accuracy: 0.9444 - val_loss: 0.6485 - val_accuracy: 0.8317 - lr: 1.0000e-05\n",
      "Epoch 280/300\n",
      "3997/3997 [==============================] - 148s 37ms/step - loss: 0.1647 - accuracy: 0.9436 - val_loss: 0.6458 - val_accuracy: 0.8332 - lr: 1.0000e-05\n",
      "Epoch 281/300\n",
      "3997/3997 [==============================] - 151s 38ms/step - loss: 0.1672 - accuracy: 0.9428 - val_loss: 0.6447 - val_accuracy: 0.8326 - lr: 1.0000e-05\n",
      "Epoch 282/300\n",
      "3997/3997 [==============================] - 150s 38ms/step - loss: 0.1663 - accuracy: 0.9432 - val_loss: 0.6405 - val_accuracy: 0.8331 - lr: 1.0000e-05\n",
      "Epoch 283/300\n",
      "3997/3997 [==============================] - 146s 37ms/step - loss: 0.1662 - accuracy: 0.9435 - val_loss: 0.6486 - val_accuracy: 0.8316 - lr: 1.0000e-05\n",
      "Epoch 284/300\n",
      "3997/3997 [==============================] - 145s 36ms/step - loss: 0.1695 - accuracy: 0.9412 - val_loss: 0.6451 - val_accuracy: 0.8320 - lr: 1.0000e-05\n",
      "Epoch 285/300\n",
      "3997/3997 [==============================] - 141s 35ms/step - loss: 0.1663 - accuracy: 0.9424 - val_loss: 0.6460 - val_accuracy: 0.8321 - lr: 1.0000e-05\n",
      "Epoch 286/300\n",
      "3997/3997 [==============================] - 142s 36ms/step - loss: 0.1624 - accuracy: 0.9438 - val_loss: 0.6475 - val_accuracy: 0.8321 - lr: 1.0000e-05\n",
      "Epoch 287/300\n",
      "3997/3997 [==============================] - 142s 36ms/step - loss: 0.1631 - accuracy: 0.9449 - val_loss: 0.6524 - val_accuracy: 0.8298 - lr: 1.0000e-05\n",
      "Epoch 288/300\n",
      "3997/3997 [==============================] - 140s 35ms/step - loss: 0.1697 - accuracy: 0.9427 - val_loss: 0.6443 - val_accuracy: 0.8318 - lr: 1.0000e-05\n",
      "Epoch 289/300\n",
      "3997/3997 [==============================] - 140s 35ms/step - loss: 0.1656 - accuracy: 0.9434 - val_loss: 0.6503 - val_accuracy: 0.8323 - lr: 1.0000e-05\n",
      "Epoch 290/300\n",
      "3997/3997 [==============================] - 142s 35ms/step - loss: 0.1639 - accuracy: 0.9437 - val_loss: 0.6440 - val_accuracy: 0.8318 - lr: 1.0000e-05\n",
      "Epoch 291/300\n",
      "3997/3997 [==============================] - 143s 36ms/step - loss: 0.1682 - accuracy: 0.9433 - val_loss: 0.6485 - val_accuracy: 0.8305 - lr: 1.0000e-05\n",
      "Epoch 292/300\n",
      "3997/3997 [==============================] - 140s 35ms/step - loss: 0.1652 - accuracy: 0.9436 - val_loss: 0.6463 - val_accuracy: 0.8328 - lr: 1.0000e-05\n",
      "Epoch 293/300\n",
      "3997/3997 [==============================] - 140s 35ms/step - loss: 0.1612 - accuracy: 0.9444 - val_loss: 0.6439 - val_accuracy: 0.8333 - lr: 1.0000e-05\n",
      "Epoch 294/300\n",
      "3997/3997 [==============================] - 142s 36ms/step - loss: 0.1658 - accuracy: 0.9435 - val_loss: 0.6512 - val_accuracy: 0.8322 - lr: 1.0000e-05\n",
      "Epoch 295/300\n",
      "3997/3997 [==============================] - 142s 35ms/step - loss: 0.1639 - accuracy: 0.9451 - val_loss: 0.6502 - val_accuracy: 0.8326 - lr: 1.0000e-05\n",
      "Epoch 296/300\n",
      "3997/3997 [==============================] - 140s 35ms/step - loss: 0.1668 - accuracy: 0.9438 - val_loss: 0.6507 - val_accuracy: 0.8311 - lr: 1.0000e-05\n",
      "Epoch 297/300\n",
      "3997/3997 [==============================] - 142s 36ms/step - loss: 0.1651 - accuracy: 0.9440 - val_loss: 0.6358 - val_accuracy: 0.8342 - lr: 1.0000e-05\n",
      "Epoch 298/300\n",
      "3997/3997 [==============================] - 141s 35ms/step - loss: 0.1657 - accuracy: 0.9442 - val_loss: 0.6376 - val_accuracy: 0.8336 - lr: 1.0000e-05\n",
      "Epoch 299/300\n",
      "3997/3997 [==============================] - 142s 36ms/step - loss: 0.1634 - accuracy: 0.9452 - val_loss: 0.6408 - val_accuracy: 0.8336 - lr: 1.0000e-05\n",
      "Epoch 300/300\n",
      "3997/3997 [==============================] - 142s 35ms/step - loss: 0.1654 - accuracy: 0.9441 - val_loss: 0.6413 - val_accuracy: 0.8328 - lr: 1.0000e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x26ad194ba30>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1_best.fit(train_gen, validation_data=validation_gen, epochs = 300, callbacks = [reduce_lr, model_checkpoint, csv_logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9721c210-3892-4f0f-bcf9-cb268d0f6a72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorgpu",
   "language": "python",
   "name": "tensorgpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
